{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1b50b07f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user2/.conda/envs/vlm2vec/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "/home/user2/.conda/envs/vlm2vec/lib/python3.11/site-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'repr' attribute with value False was provided to the `Field()` function, which has no effect in the context it was used. 'repr' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.\n",
      "  warnings.warn(\n",
      "/home/user2/.conda/envs/vlm2vec/lib/python3.11/site-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'frozen' attribute with value True was provided to the `Field()` function, which has no effect in the context it was used. 'frozen' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.\n",
      "  warnings.warn(\n",
      "[2025-11-08 04:21:47,637] DEBUG [git.cmd:1270] Popen(['git', 'version'], cwd=/home/user2/dangnh/VLM_Embed, stdin=None, shell=False, universal_newlines=False)\n",
      "[2025-11-08 04:21:47,645] DEBUG [git.cmd:1270] Popen(['git', 'version'], cwd=/home/user2/dangnh/VLM_Embed, stdin=None, shell=False, universal_newlines=False)\n",
      "/home/user2/.conda/envs/vlm2vec/lib/python3.11/site-packages/timm/models/layers/__init__.py:48: FutureWarning: Importing from timm.models.layers is deprecated, please import via timm.layers\n",
      "  warnings.warn(f\"Importing from {__name__} is deprecated, please import via timm.layers\", FutureWarning)\n",
      "/home/user2/dangnh/VLM_Embed/src/model/vlm_backbone/internvideo2/modeling_internvideo2.py:539: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  @torch.cuda.amp.autocast(enabled=False)\n",
      "[2025-11-08 04:21:48,249] DEBUG [datasets:54] PyTorch version 2.8.0 available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DropoutAddRMSNorm of flash_attn is not installed!!!\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import sys\n",
    "from collections import OrderedDict\n",
    "from contextlib import contextmanager\n",
    "import time\n",
    "\n",
    "from src.arguments import ModelArguments, DataArguments, TrainingArguments\n",
    "from transformers import HfArgumentParser, AutoConfig\n",
    "\n",
    "from src.model.model import MMEBModel\n",
    "from src.data.dataset.mmeb_dataset import EvalDataset\n",
    "from src.data.collator.eval_collator import EvalCollator\n",
    "from torch.utils.data import DataLoader\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import pickle\n",
    "import os\n",
    "from datasets import load_dataset\n",
    "from evaluation.mmeb_baselines.eval_utils import get_pred\n",
    "from src.utils import print_rank\n",
    "from src.model.processor import get_backbone_name, load_processor, COLPALI\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "import shutil "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "361f6af5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2025-11-08 04:21:48,687] DEBUG [urllib3.connectionpool:1049] Starting new HTTPS connection (1): huggingface.co:443\n",
      "[2025-11-08 04:21:49,118] DEBUG [urllib3.connectionpool:544] https://huggingface.co:443 \"HEAD /apple/FastVLM-0.5B/resolve/main/config.json HTTP/1.1\" 307 0\n",
      "[2025-11-08 04:21:49,431] DEBUG [urllib3.connectionpool:544] https://huggingface.co:443 \"HEAD /api/resolve-cache/models/apple/FastVLM-0.5B/16375720c2d673fa583e57e9876afde27549c7d0/config.json HTTP/1.1\" 200 0\n",
      "[2025-11-08 04:21:49,699] DEBUG [urllib3.connectionpool:544] https://huggingface.co:443 \"HEAD /apple/FastVLM-0.5B/resolve/main/llava_qwen.py HTTP/1.1\" 307 0\n",
      "[2025-11-08 04:21:50,003] DEBUG [urllib3.connectionpool:544] https://huggingface.co:443 \"HEAD /api/resolve-cache/models/apple/FastVLM-0.5B/16375720c2d673fa583e57e9876afde27549c7d0/llava_qwen.py HTTP/1.1\" 200 0\n",
      "/home/user2/.cache/huggingface/modules/transformers_modules/apple/FastVLM-0.5B/16375720c2d673fa583e57e9876afde27549c7d0/llava_qwen.py:1458: UserWarning: Overwriting fastvithd in registry with transformers_modules.apple.FastVLM-0.5B.16375720c2d673fa583e57e9876afde27549c7d0.llava_qwen.fastvithd. This is because the name being registered conflicts with an existing name. Please check if this is not expected.\n",
      "  @register_model\n",
      "[2025-11-08 04:21:50,313] DEBUG [urllib3.connectionpool:544] https://huggingface.co:443 \"HEAD /apple/FastVLM-0.5B/resolve/main/config.json HTTP/1.1\" 307 0\n",
      "[2025-11-08 04:21:50,391] DEBUG [urllib3.connectionpool:544] https://huggingface.co:443 \"HEAD /api/resolve-cache/models/apple/FastVLM-0.5B/16375720c2d673fa583e57e9876afde27549c7d0/config.json HTTP/1.1\" 200 0\n",
      "[2025-11-08 04:21:50,398] INFO [src.utils:12] model_backbone: llava_qwen2\n",
      "[2025-11-08 04:21:50,399] INFO [src.utils:21] Loading processor from: apple/FastVLM-0.5B\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected model type: llava_qwen2\n",
      "Determined model backbone: llava_qwen2\n",
      "Processor load here for LLAVA-QWEN2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2025-11-08 04:21:50,664] DEBUG [urllib3.connectionpool:544] https://huggingface.co:443 \"HEAD /apple/FastVLM-0.5B/resolve/main/tokenizer_config.json HTTP/1.1\" 307 0\n",
      "[2025-11-08 04:21:50,961] DEBUG [urllib3.connectionpool:544] https://huggingface.co:443 \"HEAD /api/resolve-cache/models/apple/FastVLM-0.5B/16375720c2d673fa583e57e9876afde27549c7d0/tokenizer_config.json HTTP/1.1\" 200 0\n",
      "[2025-11-08 04:21:51,235] DEBUG [urllib3.connectionpool:544] https://huggingface.co:443 \"GET /api/models/apple/FastVLM-0.5B/tree/main/additional_chat_templates?recursive=False&expand=False HTTP/1.1\" 404 64\n",
      "[2025-11-08 04:21:51,921] DEBUG [urllib3.connectionpool:544] https://huggingface.co:443 \"HEAD /apple/FastVLM-0.5B/resolve/main/config.json HTTP/1.1\" 307 0\n",
      "[2025-11-08 04:21:51,956] DEBUG [urllib3.connectionpool:544] https://huggingface.co:443 \"HEAD /api/resolve-cache/models/apple/FastVLM-0.5B/16375720c2d673fa583e57e9876afde27549c7d0/config.json HTTP/1.1\" 200 0\n",
      "[2025-11-08 04:21:52,216] DEBUG [urllib3.connectionpool:544] https://huggingface.co:443 \"HEAD /apple/FastVLM-0.5B/resolve/main/llava_qwen.py HTTP/1.1\" 307 0\n",
      "[2025-11-08 04:21:52,283] DEBUG [urllib3.connectionpool:544] https://huggingface.co:443 \"HEAD /api/resolve-cache/models/apple/FastVLM-0.5B/16375720c2d673fa583e57e9876afde27549c7d0/llava_qwen.py HTTP/1.1\" 200 0\n",
      "[2025-11-08 04:21:52,588] DEBUG [urllib3.connectionpool:544] https://huggingface.co:443 \"HEAD /apple/FastVLM-0.5B/resolve/main/config.json HTTP/1.1\" 307 0\n",
      "[2025-11-08 04:21:52,622] DEBUG [urllib3.connectionpool:544] https://huggingface.co:443 \"HEAD /api/resolve-cache/models/apple/FastVLM-0.5B/16375720c2d673fa583e57e9876afde27549c7d0/config.json HTTP/1.1\" 200 0\n",
      "[2025-11-08 04:21:52,627] INFO [src.utils:21] Loading backbone [llava_qwen2] from apple/FastVLM-0.5B\n",
      "`torch_dtype` is deprecated! Use `dtype` instead!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected model type: llava_qwen2\n",
      "Determined model backbone: llava_qwen2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2025-11-08 04:21:53,625] DEBUG [urllib3.connectionpool:544] https://huggingface.co:443 \"HEAD /apple/FastVLM-0.5B/resolve/main/generation_config.json HTTP/1.1\" 307 0\n",
      "[2025-11-08 04:21:53,922] DEBUG [urllib3.connectionpool:544] https://huggingface.co:443 \"HEAD /api/resolve-cache/models/apple/FastVLM-0.5B/16375720c2d673fa583e57e9876afde27549c7d0/generation_config.json HTTP/1.1\" 200 0\n",
      "[2025-11-08 04:21:54,191] DEBUG [urllib3.connectionpool:544] https://huggingface.co:443 \"HEAD /apple/FastVLM-0.5B/resolve/main/custom_generate/generate.py HTTP/1.1\" 404 0\n"
     ]
    }
   ],
   "source": [
    "model_args = ModelArguments(\n",
    "    model_name=\"apple/FastVLM-0.5B\",\n",
    "    # model_name=\"raghavlite/B3_Qwen2_2B\",\n",
    "    pooling=\"eos\",\n",
    "    normalize=True\n",
    ")\n",
    "\n",
    "data_args = DataArguments(\n",
    "    encode_output_path=\"encode_output_path\",\n",
    "    dataset_name=\"TIGER-Lab/MMEB-eval\",\n",
    "    subset_name=[\"HatefulMemes\"],\n",
    "    dataset_split=\"test\",\n",
    "    tgt_prefix_mod=True,\n",
    "    image_dir=\"../VLMEmbed/eval-data\",\n",
    ")\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    per_device_eval_batch_size=2,\n",
    ")\n",
    "\n",
    "os.makedirs(data_args.encode_output_path, exist_ok=True)\n",
    "\n",
    "hf_config = AutoConfig.from_pretrained(model_args.model_name, trust_remote_code=True)\n",
    "if not hasattr(model_args, \"model_backbone\") or not model_args.model_backbone:\n",
    "    model_backbone = get_backbone_name(hf_config=hf_config, model_type=model_args.model_type)\n",
    "    setattr(model_args, 'model_backbone', model_backbone)\n",
    "    setattr(training_args, 'model_backbone', model_backbone)\n",
    "print_rank(f'model_backbone: {model_args.model_backbone}')\n",
    "processor = load_processor(model_args, data_args)\n",
    "model = MMEBModel.build(model_args)\n",
    "model.eval()\n",
    "# model = model.to(training_args.device, dtype=torch.bfloat16)\n",
    "model = model.to(training_args.device)\n",
    "\n",
    "eval_collator = EvalCollator(\n",
    "    data_args=data_args,\n",
    "    model_args=model_args,\n",
    "    processor=processor,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "ab23072b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2025-11-07 10:23:10,162] DEBUG [urllib3.connectionpool:544] https://huggingface.co:443 \"HEAD /dangnguyens1/sft-fastvlm-1e/resolve/main/processor_config.json HTTP/1.1\" 404 0\n",
      "[2025-11-07 10:23:10,910] DEBUG [urllib3.connectionpool:544] https://huggingface.co:443 \"HEAD /dangnguyens1/sft-fastvlm-1e/resolve/main/preprocessor_config.json HTTP/1.1\" 307 0\n",
      "[2025-11-07 10:23:11,261] DEBUG [urllib3.connectionpool:544] https://huggingface.co:443 \"HEAD /api/resolve-cache/models/dangnguyens1/sft-fastvlm-1e/b86615061ab58ce1f1dca77d9f3be9f6a602bcfd/preprocessor_config.json HTTP/1.1\" 200 0\n",
      "[2025-11-07 10:23:11,264] DEBUG [filelock:331] Attempting to acquire lock 139639033796368 on /home/user2/.cache/huggingface/hub/.locks/models--dangnguyens1--sft-fastvlm-1e/ad62479fb0c4e341893be71df94f70e38e8c58a7.lock\n",
      "[2025-11-07 10:23:11,266] DEBUG [filelock:334] Lock 139639033796368 acquired on /home/user2/.cache/huggingface/hub/.locks/models--dangnguyens1--sft-fastvlm-1e/ad62479fb0c4e341893be71df94f70e38e8c58a7.lock\n",
      "[2025-11-07 10:23:11,595] DEBUG [urllib3.connectionpool:544] https://huggingface.co:443 \"GET /api/resolve-cache/models/dangnguyens1/sft-fastvlm-1e/b86615061ab58ce1f1dca77d9f3be9f6a602bcfd/preprocessor_config.json HTTP/1.1\" 200 570\n",
      "[2025-11-07 10:23:11,600] DEBUG [filelock:364] Attempting to release lock 139639033796368 on /home/user2/.cache/huggingface/hub/.locks/models--dangnguyens1--sft-fastvlm-1e/ad62479fb0c4e341893be71df94f70e38e8c58a7.lock\n",
      "[2025-11-07 10:23:11,601] DEBUG [filelock:367] Lock 139639033796368 released on /home/user2/.cache/huggingface/hub/.locks/models--dangnguyens1--sft-fastvlm-1e/ad62479fb0c4e341893be71df94f70e38e8c58a7.lock\n",
      "[2025-11-07 10:23:11,892] DEBUG [urllib3.connectionpool:544] https://huggingface.co:443 \"GET /api/models/dangnguyens1/sft-fastvlm-1e/revision/main HTTP/1.1\" 200 2006\n",
      "Fetching 1 files: 100%|██████████| 1/1 [00:00<00:00, 6700.17it/s]\n",
      "[2025-11-07 10:23:12,204] DEBUG [urllib3.connectionpool:544] https://huggingface.co:443 \"GET /api/models/dangnguyens1/sft-fastvlm-1e/revision/main HTTP/1.1\" 200 2006\n",
      "Fetching 1 files: 100%|██████████| 1/1 [00:00<00:00, 7145.32it/s]\n",
      "The image processor of type `Qwen2VLImageProcessor` is now loaded as a fast processor by default, even if the model checkpoint was saved with a slow processor. This is a breaking change and may produce slightly different outputs. To continue using the slow processor, instantiate this class with `use_fast=False`. Note that this behavior will be extended to all models in a future release.\n",
      "[2025-11-07 10:23:12,509] DEBUG [urllib3.connectionpool:544] https://huggingface.co:443 \"HEAD /dangnguyens1/sft-fastvlm-1e/resolve/main/tokenizer_config.json HTTP/1.1\" 307 0\n",
      "[2025-11-07 10:23:12,837] DEBUG [urllib3.connectionpool:544] https://huggingface.co:443 \"HEAD /api/resolve-cache/models/dangnguyens1/sft-fastvlm-1e/b86615061ab58ce1f1dca77d9f3be9f6a602bcfd/tokenizer_config.json HTTP/1.1\" 200 0\n",
      "[2025-11-07 10:23:12,840] DEBUG [filelock:331] Attempting to acquire lock 139639031588560 on /home/user2/.cache/huggingface/hub/.locks/models--dangnguyens1--sft-fastvlm-1e/8b0c601fb744f4e0d5a385090750f61cc901a47b.lock\n",
      "[2025-11-07 10:23:12,842] DEBUG [filelock:334] Lock 139639031588560 acquired on /home/user2/.cache/huggingface/hub/.locks/models--dangnguyens1--sft-fastvlm-1e/8b0c601fb744f4e0d5a385090750f61cc901a47b.lock\n",
      "[2025-11-07 10:23:13,179] DEBUG [urllib3.connectionpool:544] https://huggingface.co:443 \"GET /api/resolve-cache/models/dangnguyens1/sft-fastvlm-1e/b86615061ab58ce1f1dca77d9f3be9f6a602bcfd/tokenizer_config.json HTTP/1.1\" 200 None\n",
      "[2025-11-07 10:23:13,182] DEBUG [filelock:364] Attempting to release lock 139639031588560 on /home/user2/.cache/huggingface/hub/.locks/models--dangnguyens1--sft-fastvlm-1e/8b0c601fb744f4e0d5a385090750f61cc901a47b.lock\n",
      "[2025-11-07 10:23:13,183] DEBUG [filelock:367] Lock 139639031588560 released on /home/user2/.cache/huggingface/hub/.locks/models--dangnguyens1--sft-fastvlm-1e/8b0c601fb744f4e0d5a385090750f61cc901a47b.lock\n",
      "[2025-11-07 10:23:13,491] DEBUG [urllib3.connectionpool:544] https://huggingface.co:443 \"GET /api/models/dangnguyens1/sft-fastvlm-1e/tree/main/additional_chat_templates?recursive=False&expand=False HTTP/1.1\" 404 64\n",
      "[2025-11-07 10:23:13,788] DEBUG [urllib3.connectionpool:544] https://huggingface.co:443 \"HEAD /dangnguyens1/sft-fastvlm-1e/resolve/main/vocab.json HTTP/1.1\" 307 0\n",
      "[2025-11-07 10:23:14,283] DEBUG [urllib3.connectionpool:544] https://huggingface.co:443 \"HEAD /api/resolve-cache/models/dangnguyens1/sft-fastvlm-1e/b86615061ab58ce1f1dca77d9f3be9f6a602bcfd/vocab.json HTTP/1.1\" 200 0\n",
      "[2025-11-07 10:23:14,286] DEBUG [filelock:331] Attempting to acquire lock 139639031592528 on /home/user2/.cache/huggingface/hub/.locks/models--dangnguyens1--sft-fastvlm-1e/4783fe10ac3adce15ac8f358ef5462739852c569.lock\n",
      "[2025-11-07 10:23:14,288] DEBUG [filelock:334] Lock 139639031592528 acquired on /home/user2/.cache/huggingface/hub/.locks/models--dangnguyens1--sft-fastvlm-1e/4783fe10ac3adce15ac8f358ef5462739852c569.lock\n",
      "[2025-11-07 10:23:14,617] DEBUG [urllib3.connectionpool:544] https://huggingface.co:443 \"GET /api/resolve-cache/models/dangnguyens1/sft-fastvlm-1e/b86615061ab58ce1f1dca77d9f3be9f6a602bcfd/vocab.json HTTP/1.1\" 200 None\n",
      "[2025-11-07 10:23:15,144] DEBUG [filelock:364] Attempting to release lock 139639031592528 on /home/user2/.cache/huggingface/hub/.locks/models--dangnguyens1--sft-fastvlm-1e/4783fe10ac3adce15ac8f358ef5462739852c569.lock\n",
      "[2025-11-07 10:23:15,145] DEBUG [filelock:367] Lock 139639031592528 released on /home/user2/.cache/huggingface/hub/.locks/models--dangnguyens1--sft-fastvlm-1e/4783fe10ac3adce15ac8f358ef5462739852c569.lock\n",
      "[2025-11-07 10:23:15,437] DEBUG [urllib3.connectionpool:544] https://huggingface.co:443 \"HEAD /dangnguyens1/sft-fastvlm-1e/resolve/main/merges.txt HTTP/1.1\" 307 0\n",
      "[2025-11-07 10:23:15,780] DEBUG [urllib3.connectionpool:544] https://huggingface.co:443 \"HEAD /api/resolve-cache/models/dangnguyens1/sft-fastvlm-1e/b86615061ab58ce1f1dca77d9f3be9f6a602bcfd/merges.txt HTTP/1.1\" 200 0\n",
      "[2025-11-07 10:23:15,783] DEBUG [filelock:331] Attempting to acquire lock 139640199668048 on /home/user2/.cache/huggingface/hub/.locks/models--dangnguyens1--sft-fastvlm-1e/31349551d90c7606f325fe0f11bbb8bd5fa0d7c7.lock\n",
      "[2025-11-07 10:23:15,784] DEBUG [filelock:334] Lock 139640199668048 acquired on /home/user2/.cache/huggingface/hub/.locks/models--dangnguyens1--sft-fastvlm-1e/31349551d90c7606f325fe0f11bbb8bd5fa0d7c7.lock\n",
      "[2025-11-07 10:23:16,125] DEBUG [urllib3.connectionpool:544] https://huggingface.co:443 \"GET /api/resolve-cache/models/dangnguyens1/sft-fastvlm-1e/b86615061ab58ce1f1dca77d9f3be9f6a602bcfd/merges.txt HTTP/1.1\" 200 None\n",
      "[2025-11-07 10:23:16,405] DEBUG [filelock:364] Attempting to release lock 139640199668048 on /home/user2/.cache/huggingface/hub/.locks/models--dangnguyens1--sft-fastvlm-1e/31349551d90c7606f325fe0f11bbb8bd5fa0d7c7.lock\n",
      "[2025-11-07 10:23:16,406] DEBUG [filelock:367] Lock 139640199668048 released on /home/user2/.cache/huggingface/hub/.locks/models--dangnguyens1--sft-fastvlm-1e/31349551d90c7606f325fe0f11bbb8bd5fa0d7c7.lock\n",
      "[2025-11-07 10:23:16,698] DEBUG [urllib3.connectionpool:544] https://huggingface.co:443 \"HEAD /dangnguyens1/sft-fastvlm-1e/resolve/main/tokenizer.json HTTP/1.1\" 302 0\n",
      "[2025-11-07 10:23:16,703] DEBUG [filelock:331] Attempting to acquire lock 139640198414032 on /home/user2/.cache/huggingface/hub/.locks/models--dangnguyens1--sft-fastvlm-1e/f9f1b25be0b5a53ffc83ca52290a5ebcf3e45ce4ea9fd378dc6d9091bf111ac2.lock\n",
      "[2025-11-07 10:23:16,704] DEBUG [filelock:334] Lock 139640198414032 acquired on /home/user2/.cache/huggingface/hub/.locks/models--dangnguyens1--sft-fastvlm-1e/f9f1b25be0b5a53ffc83ca52290a5ebcf3e45ce4ea9fd378dc6d9091bf111ac2.lock\n",
      "[2025-11-07 10:23:17,032] DEBUG [urllib3.connectionpool:544] https://huggingface.co:443 \"GET /api/models/dangnguyens1/sft-fastvlm-1e/xet-read-token/b86615061ab58ce1f1dca77d9f3be9f6a602bcfd HTTP/1.1\" 200 417\n",
      "[2025-11-07 10:23:27,390] DEBUG [filelock:364] Attempting to release lock 139640198414032 on /home/user2/.cache/huggingface/hub/.locks/models--dangnguyens1--sft-fastvlm-1e/f9f1b25be0b5a53ffc83ca52290a5ebcf3e45ce4ea9fd378dc6d9091bf111ac2.lock\n",
      "[2025-11-07 10:23:27,391] DEBUG [filelock:367] Lock 139640198414032 released on /home/user2/.cache/huggingface/hub/.locks/models--dangnguyens1--sft-fastvlm-1e/f9f1b25be0b5a53ffc83ca52290a5ebcf3e45ce4ea9fd378dc6d9091bf111ac2.lock\n",
      "[2025-11-07 10:23:27,690] DEBUG [urllib3.connectionpool:544] https://huggingface.co:443 \"HEAD /dangnguyens1/sft-fastvlm-1e/resolve/main/added_tokens.json HTTP/1.1\" 307 0\n",
      "[2025-11-07 10:23:28,183] DEBUG [urllib3.connectionpool:544] https://huggingface.co:443 \"HEAD /api/resolve-cache/models/dangnguyens1/sft-fastvlm-1e/b86615061ab58ce1f1dca77d9f3be9f6a602bcfd/added_tokens.json HTTP/1.1\" 200 0\n",
      "[2025-11-07 10:23:28,186] DEBUG [filelock:331] Attempting to acquire lock 139639042736272 on /home/user2/.cache/huggingface/hub/.locks/models--dangnguyens1--sft-fastvlm-1e/caa81304af029feb531f1fe80a096dc539ea0153.lock\n",
      "[2025-11-07 10:23:28,188] DEBUG [filelock:334] Lock 139639042736272 acquired on /home/user2/.cache/huggingface/hub/.locks/models--dangnguyens1--sft-fastvlm-1e/caa81304af029feb531f1fe80a096dc539ea0153.lock\n",
      "[2025-11-07 10:23:28,522] DEBUG [urllib3.connectionpool:544] https://huggingface.co:443 \"GET /api/resolve-cache/models/dangnguyens1/sft-fastvlm-1e/b86615061ab58ce1f1dca77d9f3be9f6a602bcfd/added_tokens.json HTTP/1.1\" 200 392\n",
      "[2025-11-07 10:23:28,525] DEBUG [filelock:364] Attempting to release lock 139639042736272 on /home/user2/.cache/huggingface/hub/.locks/models--dangnguyens1--sft-fastvlm-1e/caa81304af029feb531f1fe80a096dc539ea0153.lock\n",
      "[2025-11-07 10:23:28,526] DEBUG [filelock:367] Lock 139639042736272 released on /home/user2/.cache/huggingface/hub/.locks/models--dangnguyens1--sft-fastvlm-1e/caa81304af029feb531f1fe80a096dc539ea0153.lock\n",
      "[2025-11-07 10:23:28,843] DEBUG [urllib3.connectionpool:544] https://huggingface.co:443 \"HEAD /dangnguyens1/sft-fastvlm-1e/resolve/main/special_tokens_map.json HTTP/1.1\" 307 0\n",
      "[2025-11-07 10:23:29,181] DEBUG [urllib3.connectionpool:544] https://huggingface.co:443 \"HEAD /api/resolve-cache/models/dangnguyens1/sft-fastvlm-1e/b86615061ab58ce1f1dca77d9f3be9f6a602bcfd/special_tokens_map.json HTTP/1.1\" 200 0\n",
      "[2025-11-07 10:23:29,183] DEBUG [filelock:331] Attempting to acquire lock 139640796850320 on /home/user2/.cache/huggingface/hub/.locks/models--dangnguyens1--sft-fastvlm-1e/ac23c0aaa2434523c494330aeb79c58395378103.lock\n",
      "[2025-11-07 10:23:29,185] DEBUG [filelock:334] Lock 139640796850320 acquired on /home/user2/.cache/huggingface/hub/.locks/models--dangnguyens1--sft-fastvlm-1e/ac23c0aaa2434523c494330aeb79c58395378103.lock\n",
      "[2025-11-07 10:23:29,509] DEBUG [urllib3.connectionpool:544] https://huggingface.co:443 \"GET /api/resolve-cache/models/dangnguyens1/sft-fastvlm-1e/b86615061ab58ce1f1dca77d9f3be9f6a602bcfd/special_tokens_map.json HTTP/1.1\" 200 613\n",
      "[2025-11-07 10:23:29,512] DEBUG [filelock:364] Attempting to release lock 139640796850320 on /home/user2/.cache/huggingface/hub/.locks/models--dangnguyens1--sft-fastvlm-1e/ac23c0aaa2434523c494330aeb79c58395378103.lock\n",
      "[2025-11-07 10:23:29,513] DEBUG [filelock:367] Lock 139640796850320 released on /home/user2/.cache/huggingface/hub/.locks/models--dangnguyens1--sft-fastvlm-1e/ac23c0aaa2434523c494330aeb79c58395378103.lock\n",
      "[2025-11-07 10:23:29,820] DEBUG [urllib3.connectionpool:544] https://huggingface.co:443 \"HEAD /dangnguyens1/sft-fastvlm-1e/resolve/main/chat_template.jinja HTTP/1.1\" 307 0\n",
      "[2025-11-07 10:23:30,158] DEBUG [urllib3.connectionpool:544] https://huggingface.co:443 \"HEAD /api/resolve-cache/models/dangnguyens1/sft-fastvlm-1e/b86615061ab58ce1f1dca77d9f3be9f6a602bcfd/chat_template.jinja HTTP/1.1\" 200 0\n",
      "[2025-11-07 10:23:30,161] DEBUG [filelock:331] Attempting to acquire lock 139639033347280 on /home/user2/.cache/huggingface/hub/.locks/models--dangnguyens1--sft-fastvlm-1e/6c226632394ae7474b0d4b13e15793eac2e21ee9.lock\n",
      "[2025-11-07 10:23:30,163] DEBUG [filelock:334] Lock 139639033347280 acquired on /home/user2/.cache/huggingface/hub/.locks/models--dangnguyens1--sft-fastvlm-1e/6c226632394ae7474b0d4b13e15793eac2e21ee9.lock\n",
      "[2025-11-07 10:23:30,497] DEBUG [urllib3.connectionpool:544] https://huggingface.co:443 \"GET /api/resolve-cache/models/dangnguyens1/sft-fastvlm-1e/b86615061ab58ce1f1dca77d9f3be9f6a602bcfd/chat_template.jinja HTTP/1.1\" 200 None\n",
      "[2025-11-07 10:23:30,500] DEBUG [filelock:364] Attempting to release lock 139639033347280 on /home/user2/.cache/huggingface/hub/.locks/models--dangnguyens1--sft-fastvlm-1e/6c226632394ae7474b0d4b13e15793eac2e21ee9.lock\n",
      "[2025-11-07 10:23:30,501] DEBUG [filelock:367] Lock 139639033347280 released on /home/user2/.cache/huggingface/hub/.locks/models--dangnguyens1--sft-fastvlm-1e/6c226632394ae7474b0d4b13e15793eac2e21ee9.lock\n",
      "[2025-11-07 10:23:31,178] DEBUG [urllib3.connectionpool:544] https://huggingface.co:443 \"GET /api/models/dangnguyens1/sft-fastvlm-1e/revision/main HTTP/1.1\" 200 2006\n",
      "Fetching 1 files: 100%|██████████| 1/1 [00:00<00:00, 6533.18it/s]\n",
      "[2025-11-07 10:23:31,498] DEBUG [urllib3.connectionpool:544] https://huggingface.co:443 \"GET /api/models/dangnguyens1/sft-fastvlm-1e/tree/main/additional_chat_templates?recursive=False&expand=False HTTP/1.1\" 404 64\n",
      "[2025-11-07 10:23:31,797] DEBUG [urllib3.connectionpool:544] https://huggingface.co:443 \"HEAD /dangnguyens1/sft-fastvlm-1e/resolve/main/processor_config.json HTTP/1.1\" 404 0\n",
      "[2025-11-07 10:23:32,102] DEBUG [urllib3.connectionpool:544] https://huggingface.co:443 \"HEAD /dangnguyens1/sft-fastvlm-1e/resolve/main/chat_template.json HTTP/1.1\" 404 0\n",
      "[2025-11-07 10:23:32,423] DEBUG [urllib3.connectionpool:544] https://huggingface.co:443 \"HEAD /dangnguyens1/sft-fastvlm-1e/resolve/main/chat_template.jinja HTTP/1.1\" 307 0\n",
      "[2025-11-07 10:23:32,530] DEBUG [urllib3.connectionpool:544] https://huggingface.co:443 \"HEAD /api/resolve-cache/models/dangnguyens1/sft-fastvlm-1e/b86615061ab58ce1f1dca77d9f3be9f6a602bcfd/chat_template.jinja HTTP/1.1\" 200 0\n",
      "[2025-11-07 10:23:32,865] DEBUG [urllib3.connectionpool:544] https://huggingface.co:443 \"HEAD /dangnguyens1/sft-fastvlm-1e/resolve/main/audio_tokenizer_config.json HTTP/1.1\" 404 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processor loaded from dangnguyens1/sft-fastvlm-1e\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoProcessor\n",
    "\n",
    "repo_id = \"dangnguyens1/sft-fastvlm-1e\" \n",
    "processor = AutoProcessor.from_pretrained(repo_id)\n",
    "\n",
    "print(f\"Processor loaded from {repo_id}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "7458b5cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2025-11-07 10:20:30,781] DEBUG [urllib3.connectionpool:289] Resetting dropped connection: huggingface.co\n",
      "[2025-11-07 10:20:31,273] DEBUG [urllib3.connectionpool:544] https://huggingface.co:443 \"GET /api/whoami-v2 HTTP/1.1\" 200 712\n",
      "[2025-11-07 10:20:32,202] DEBUG [urllib3.connectionpool:544] https://huggingface.co:443 \"HEAD /Qwen/Qwen2-VL-2B-Instruct/resolve/main/config.json HTTP/1.1\" 307 0\n",
      "[2025-11-07 10:20:32,552] DEBUG [urllib3.connectionpool:544] https://huggingface.co:443 \"HEAD /api/resolve-cache/models/Qwen/Qwen2-VL-2B-Instruct/895c3a49bc3fa70a340399125c650a463535e71c/config.json HTTP/1.1\" 200 0\n",
      "[2025-11-07 10:20:32,857] DEBUG [urllib3.connectionpool:544] https://huggingface.co:443 \"HEAD /Qwen/Qwen2-VL-2B-Instruct/resolve/main/config.json HTTP/1.1\" 307 0\n",
      "[2025-11-07 10:20:32,964] DEBUG [urllib3.connectionpool:544] https://huggingface.co:443 \"HEAD /api/resolve-cache/models/Qwen/Qwen2-VL-2B-Instruct/895c3a49bc3fa70a340399125c650a463535e71c/config.json HTTP/1.1\" 200 0\n"
     ]
    }
   ],
   "source": [
    "from huggingface_hub import login\n",
    "token=\"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\"\n",
    "login(token=token)\n",
    "\n",
    "ckpt_dir = \"test-save\"\n",
    "# processor.tokenizer.save_pretrained(ckpt_dir)\n",
    "processor.save_pretrained(ckpt_dir)\n",
    "model.encoder.save_pretrained(ckpt_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "74adfe88",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from huggingface_hub import HfApi, HfFolder, Repository, create_repo\n",
    "\n",
    "def push_to_hub(repo_name=None, token=None, commit_message=\"Upload model\", \n",
    "                local_dir=\"./temp_model\", private=False):\n",
    "    try:\n",
    "        if not repo_name:\n",
    "            raise ValueError(\"must specify a repo name to push to hub\")\n",
    "        \n",
    "        if not os.path.exists(local_dir):\n",
    "            raise ValueError(f\"local_dir {local_dir} does not exist\")\n",
    "        \n",
    "        print_rank(f\"Pushing model to the hub at {repo_name}...\")\n",
    "        api = HfApi()\n",
    "        create_repo(repo_name, token=token, private=private, exist_ok=True)\n",
    "        api.upload_folder(\n",
    "            folder_path=local_dir,\n",
    "            repo_id=repo_name, \n",
    "            token=token, \n",
    "            commit_message=commit_message\n",
    "        )\n",
    "\n",
    "        print_rank(f\"Model has been pushed to the hub at: {repo_name}\")\n",
    "        return True\n",
    "        \n",
    "    except Exception as e:\n",
    "        print_rank(f\"Error pushing to hub: {str(e)}\")\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "fbfda101",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2025-11-07 10:55:20,306] INFO [src.utils:12] Pushing model to the hub at dangnguyens1/sft-fastvlm-kd_final_e...\n",
      "[2025-11-07 10:55:20,310] DEBUG [urllib3.connectionpool:289] Resetting dropped connection: huggingface.co\n",
      "[2025-11-07 10:55:23,132] DEBUG [urllib3.connectionpool:544] https://huggingface.co:443 \"POST /api/repos/create HTTP/1.1\" 200 145\n",
      "[2025-11-07 10:55:23,562] DEBUG [urllib3.connectionpool:544] https://huggingface.co:443 \"POST /api/models/dangnguyens1/sft-fastvlm-kd_final_e/preupload/main HTTP/1.1\" 200 878\n",
      "[2025-11-07 10:55:23,867] DEBUG [urllib3.connectionpool:544] https://huggingface.co:443 \"GET /api/models/dangnguyens1/sft-fastvlm-kd_final_e/revision/main?expand=xetEnabled HTTP/1.1\" 200 95\n",
      "[2025-11-07 10:55:24,162] DEBUG [urllib3.connectionpool:544] https://huggingface.co:443 \"GET /api/models/dangnguyens1/sft-fastvlm-kd_final_e/xet-write-token/main HTTP/1.1\" 200 418\n",
      "Processing Files (2 / 2): 100%|██████████| 20.8MB / 20.8MB,  0.00B/s  \n",
      "New Data Upload: |          |  0.00B /  0.00B,  0.00B/s  \n",
      "[2025-11-07 10:55:33,000] DEBUG [urllib3.connectionpool:544] https://huggingface.co:443 \"POST /api/models/dangnguyens1/sft-fastvlm-kd_final_e/commit/main HTTP/1.1\" 200 208\n",
      "[2025-11-07 10:55:33,002] INFO [src.utils:12] Model has been pushed to the hub at: dangnguyens1/sft-fastvlm-kd_final_e\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "push_to_hub(\n",
    "    repo_name=\"dangnguyens1/sft-fastvlm-kd_final_e\",\n",
    "    token=token,\n",
    "    local_dir=\"test-save\",\n",
    "    \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bf8010bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2025-11-07 15:27:47,382] DEBUG [urllib3.connectionpool:544] https://huggingface.co:443 \"HEAD /datasets/TIGER-Lab/MMEB-eval/resolve/main/README.md HTTP/1.1\" 307 0\n",
      "[2025-11-07 15:27:47,621] DEBUG [urllib3.connectionpool:544] https://huggingface.co:443 \"HEAD /api/resolve-cache/datasets/TIGER-Lab/MMEB-eval/2f069730be515ea60778413777816b53e2d2a697/README.md HTTP/1.1\" 200 0\n",
      "[2025-11-07 15:27:48,394] DEBUG [urllib3.connectionpool:544] https://huggingface.co:443 \"HEAD /datasets/TIGER-Lab/MMEB-eval/resolve/2f069730be515ea60778413777816b53e2d2a697/MMEB-eval.py HTTP/1.1\" 404 0\n",
      "[2025-11-07 15:27:48,400] DEBUG [urllib3.connectionpool:1049] Starting new HTTPS connection (1): s3.amazonaws.com:443\n",
      "[2025-11-07 15:27:49,529] DEBUG [urllib3.connectionpool:544] https://s3.amazonaws.com:443 \"HEAD /datasets.huggingface.co/datasets/datasets/TIGER-Lab/MMEB-eval/TIGER-Lab/MMEB-eval.py HTTP/1.1\" 404 0\n",
      "[2025-11-07 15:27:49,963] DEBUG [urllib3.connectionpool:544] https://huggingface.co:443 \"GET /api/datasets/TIGER-Lab/MMEB-eval/revision/2f069730be515ea60778413777816b53e2d2a697 HTTP/1.1\" 200 18440\n",
      "[2025-11-07 15:27:50,297] DEBUG [urllib3.connectionpool:544] https://huggingface.co:443 \"HEAD /datasets/TIGER-Lab/MMEB-eval/resolve/2f069730be515ea60778413777816b53e2d2a697/.huggingface.yaml HTTP/1.1\" 404 0\n",
      "[2025-11-07 15:27:50,317] DEBUG [urllib3.connectionpool:1049] Starting new HTTPS connection (1): datasets-server.huggingface.co:443\n",
      "[2025-11-07 15:27:52,746] DEBUG [urllib3.connectionpool:544] https://datasets-server.huggingface.co:443 \"GET /info?dataset=TIGER-Lab/MMEB-eval HTTP/1.1\" 200 None\n",
      "[2025-11-07 15:27:53,059] DEBUG [urllib3.connectionpool:544] https://huggingface.co:443 \"GET /api/datasets/TIGER-Lab/MMEB-eval/revision/2f069730be515ea60778413777816b53e2d2a697 HTTP/1.1\" 200 18456\n",
      "[2025-11-07 15:27:53,384] DEBUG [urllib3.connectionpool:544] https://huggingface.co:443 \"GET /api/datasets/TIGER-Lab/MMEB-eval/tree/2f069730be515ea60778413777816b53e2d2a697/A-OKVQA?recursive=True&expand=False HTTP/1.1\" 200 317\n",
      "[2025-11-07 15:27:53,704] DEBUG [urllib3.connectionpool:544] https://huggingface.co:443 \"GET /api/datasets/TIGER-Lab/MMEB-eval/tree/2f069730be515ea60778413777816b53e2d2a697?recursive=False&expand=False HTTP/1.1\" 200 4692\n",
      "[2025-11-07 15:27:54,026] DEBUG [urllib3.connectionpool:544] https://huggingface.co:443 \"HEAD /datasets/TIGER-Lab/MMEB-eval/resolve/2f069730be515ea60778413777816b53e2d2a697/dataset_infos.json HTTP/1.1\" 404 0\n",
      "[2025-11-07 15:27:54,461] DEBUG [urllib3.connectionpool:544] https://huggingface.co:443 \"GET /api/datasets/TIGER-Lab/MMEB-eval/tree/2f069730be515ea60778413777816b53e2d2a697/HatefulMemes?recursive=True&expand=False HTTP/1.1\" 200 316\n",
      "[2025-11-07 15:27:54,466] DEBUG [filelock:331] Attempting to acquire lock 140218554524048 on /home/user2/.cache/huggingface/datasets/_home_user2_.cache_huggingface_datasets_TIGER-Lab___mmeb-eval_HatefulMemes_0.0.0_2f069730be515ea60778413777816b53e2d2a697.lock\n",
      "[2025-11-07 15:27:54,467] DEBUG [filelock:334] Lock 140218554524048 acquired on /home/user2/.cache/huggingface/datasets/_home_user2_.cache_huggingface_datasets_TIGER-Lab___mmeb-eval_HatefulMemes_0.0.0_2f069730be515ea60778413777816b53e2d2a697.lock\n",
      "[2025-11-07 15:27:54,469] DEBUG [fsspec.local:379] open file: /home/user2/.cache/huggingface/datasets/TIGER-Lab___mmeb-eval/HatefulMemes/0.0.0/2f069730be515ea60778413777816b53e2d2a697/dataset_info.json\n",
      "[2025-11-07 15:27:54,471] DEBUG [filelock:364] Attempting to release lock 140218554524048 on /home/user2/.cache/huggingface/datasets/_home_user2_.cache_huggingface_datasets_TIGER-Lab___mmeb-eval_HatefulMemes_0.0.0_2f069730be515ea60778413777816b53e2d2a697.lock\n",
      "[2025-11-07 15:27:54,472] DEBUG [filelock:367] Lock 140218554524048 released on /home/user2/.cache/huggingface/datasets/_home_user2_.cache_huggingface_datasets_TIGER-Lab___mmeb-eval_HatefulMemes_0.0.0_2f069730be515ea60778413777816b53e2d2a697.lock\n",
      "[2025-11-07 15:27:54,501] DEBUG [filelock:331] Attempting to acquire lock 140219131963216 on /home/user2/.cache/huggingface/datasets/TIGER-Lab___mmeb-eval/HatefulMemes/0.0.0/2f069730be515ea60778413777816b53e2d2a697_builder.lock\n",
      "[2025-11-07 15:27:54,502] DEBUG [filelock:334] Lock 140219131963216 acquired on /home/user2/.cache/huggingface/datasets/TIGER-Lab___mmeb-eval/HatefulMemes/0.0.0/2f069730be515ea60778413777816b53e2d2a697_builder.lock\n",
      "[2025-11-07 15:27:54,503] DEBUG [fsspec.local:379] open file: /home/user2/.cache/huggingface/datasets/TIGER-Lab___mmeb-eval/HatefulMemes/0.0.0/2f069730be515ea60778413777816b53e2d2a697/dataset_info.json\n",
      "[2025-11-07 15:27:54,505] DEBUG [filelock:364] Attempting to release lock 140219131963216 on /home/user2/.cache/huggingface/datasets/TIGER-Lab___mmeb-eval/HatefulMemes/0.0.0/2f069730be515ea60778413777816b53e2d2a697_builder.lock\n",
      "[2025-11-07 15:27:54,505] DEBUG [filelock:367] Lock 140219131963216 released on /home/user2/.cache/huggingface/datasets/TIGER-Lab___mmeb-eval/HatefulMemes/0.0.0/2f069730be515ea60778413777816b53e2d2a697_builder.lock\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Not using TGT mod None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2025-11-07 15:27:54,860] DEBUG [urllib3.connectionpool:544] https://huggingface.co:443 \"HEAD /datasets/TIGER-Lab/MMEB-eval/resolve/main/README.md HTTP/1.1\" 307 0\n",
      "[2025-11-07 15:27:54,959] DEBUG [urllib3.connectionpool:544] https://huggingface.co:443 \"HEAD /api/resolve-cache/datasets/TIGER-Lab/MMEB-eval/2f069730be515ea60778413777816b53e2d2a697/README.md HTTP/1.1\" 200 0\n",
      "[2025-11-07 15:27:55,264] DEBUG [urllib3.connectionpool:544] https://huggingface.co:443 \"HEAD /datasets/TIGER-Lab/MMEB-eval/resolve/2f069730be515ea60778413777816b53e2d2a697/MMEB-eval.py HTTP/1.1\" 404 0\n",
      "[2025-11-07 15:27:55,909] DEBUG [urllib3.connectionpool:544] https://huggingface.co:443 \"HEAD /datasets/TIGER-Lab/MMEB-eval/resolve/2f069730be515ea60778413777816b53e2d2a697/.huggingface.yaml HTTP/1.1\" 404 0\n",
      "[2025-11-07 15:27:56,201] DEBUG [urllib3.connectionpool:544] https://datasets-server.huggingface.co:443 \"GET /info?dataset=TIGER-Lab/MMEB-eval HTTP/1.1\" 200 None\n",
      "[2025-11-07 15:27:56,507] DEBUG [urllib3.connectionpool:544] https://huggingface.co:443 \"HEAD /datasets/TIGER-Lab/MMEB-eval/resolve/2f069730be515ea60778413777816b53e2d2a697/dataset_infos.json HTTP/1.1\" 404 0\n",
      "[2025-11-07 15:27:56,512] DEBUG [filelock:331] Attempting to acquire lock 140218568646928 on /home/user2/.cache/huggingface/datasets/_home_user2_.cache_huggingface_datasets_TIGER-Lab___mmeb-eval_HatefulMemes_0.0.0_2f069730be515ea60778413777816b53e2d2a697.lock\n",
      "[2025-11-07 15:27:56,514] DEBUG [filelock:334] Lock 140218568646928 acquired on /home/user2/.cache/huggingface/datasets/_home_user2_.cache_huggingface_datasets_TIGER-Lab___mmeb-eval_HatefulMemes_0.0.0_2f069730be515ea60778413777816b53e2d2a697.lock\n",
      "[2025-11-07 15:27:56,515] DEBUG [fsspec.local:379] open file: /home/user2/.cache/huggingface/datasets/TIGER-Lab___mmeb-eval/HatefulMemes/0.0.0/2f069730be515ea60778413777816b53e2d2a697/dataset_info.json\n",
      "[2025-11-07 15:27:56,517] DEBUG [filelock:364] Attempting to release lock 140218568646928 on /home/user2/.cache/huggingface/datasets/_home_user2_.cache_huggingface_datasets_TIGER-Lab___mmeb-eval_HatefulMemes_0.0.0_2f069730be515ea60778413777816b53e2d2a697.lock\n",
      "[2025-11-07 15:27:56,518] DEBUG [filelock:367] Lock 140218568646928 released on /home/user2/.cache/huggingface/datasets/_home_user2_.cache_huggingface_datasets_TIGER-Lab___mmeb-eval_HatefulMemes_0.0.0_2f069730be515ea60778413777816b53e2d2a697.lock\n",
      "[2025-11-07 15:27:56,521] DEBUG [filelock:331] Attempting to acquire lock 140219132126800 on /home/user2/.cache/huggingface/datasets/TIGER-Lab___mmeb-eval/HatefulMemes/0.0.0/2f069730be515ea60778413777816b53e2d2a697_builder.lock\n",
      "[2025-11-07 15:27:56,523] DEBUG [filelock:334] Lock 140219132126800 acquired on /home/user2/.cache/huggingface/datasets/TIGER-Lab___mmeb-eval/HatefulMemes/0.0.0/2f069730be515ea60778413777816b53e2d2a697_builder.lock\n",
      "[2025-11-07 15:27:56,524] DEBUG [fsspec.local:379] open file: /home/user2/.cache/huggingface/datasets/TIGER-Lab___mmeb-eval/HatefulMemes/0.0.0/2f069730be515ea60778413777816b53e2d2a697/dataset_info.json\n",
      "[2025-11-07 15:27:56,526] DEBUG [filelock:364] Attempting to release lock 140219132126800 on /home/user2/.cache/huggingface/datasets/TIGER-Lab___mmeb-eval/HatefulMemes/0.0.0/2f069730be515ea60778413777816b53e2d2a697_builder.lock\n",
      "[2025-11-07 15:27:56,527] DEBUG [filelock:367] Lock 140219132126800 released on /home/user2/.cache/huggingface/datasets/TIGER-Lab___mmeb-eval/HatefulMemes/0.0.0/2f069730be515ea60778413777816b53e2d2a697_builder.lock\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using TGT mod Represent the class label: \n",
      ">>>>>>>>>>>>>inside tgt_mod_txt\n"
     ]
    }
   ],
   "source": [
    "POS_MOD_CLASS_LABEL = \"Represent the class label: \"\n",
    "POS_MOD_IMAGE_CAPTION = \"Represent the image caption: \"\n",
    "POS_MOD_ANSWER = \"Represent the answer: \"\n",
    "\n",
    "POS_MOD_DICT = {\n",
    "                \"ImageNet-1K\": POS_MOD_CLASS_LABEL,\"HatefulMemes\":POS_MOD_CLASS_LABEL,\"SUN397\":POS_MOD_CLASS_LABEL,\"N24News\":POS_MOD_CLASS_LABEL,\"VOC2007\":POS_MOD_CLASS_LABEL, \"Place365\":POS_MOD_CLASS_LABEL,\"ImageNet-A\":POS_MOD_CLASS_LABEL,\"ImageNet-R\":POS_MOD_CLASS_LABEL,\"ObjectNet\":POS_MOD_CLASS_LABEL,\"Country211\":POS_MOD_CLASS_LABEL,\n",
    "                \n",
    "                \"OK-VQA\":POS_MOD_ANSWER, \"A-OKVQA\":POS_MOD_ANSWER, \"DocVQA\":POS_MOD_ANSWER, \"InfographicsVQA\":POS_MOD_ANSWER, \"ChartQA\":POS_MOD_ANSWER, \"Visual7W\":POS_MOD_ANSWER,\"ScienceQA\":POS_MOD_ANSWER, \"GQA\":POS_MOD_ANSWER, \"TextVQA\":POS_MOD_ANSWER, \"VizWiz\":POS_MOD_ANSWER,\n",
    "                \n",
    "                \"MSCOCO_i2t\":POS_MOD_IMAGE_CAPTION, \"VisualNews_i2t\":POS_MOD_IMAGE_CAPTION,\n",
    "                }\n",
    "\n",
    "eval_qry_dataset = EvalDataset(\n",
    "    data_args=data_args,\n",
    "    model_args=model_args,\n",
    "    subset=data_args.subset_name[0],\n",
    "    text_field=\"qry_text\",\n",
    "    img_path_field=\"qry_img_path\",\n",
    ")\n",
    "eval_tgt_dataset = EvalDataset(\n",
    "    data_args=data_args,\n",
    "    model_args=model_args,\n",
    "    subset=data_args.subset_name[0],\n",
    "    text_field=\"tgt_text\",\n",
    "    img_path_field=\"tgt_img_path\",\n",
    "    mod_instruction=POS_MOD_DICT.get(data_args.subset_name[0], None) if data_args.tgt_prefix_mod else None\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d278d46e",
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_qry_loader = DataLoader(\n",
    "    eval_qry_dataset,\n",
    "    batch_size=training_args.per_device_eval_batch_size,\n",
    "    collate_fn=eval_collator,\n",
    "    shuffle=False,\n",
    "    drop_last=False,\n",
    "    num_workers=0,\n",
    ")\n",
    "eval_tgt_loader = DataLoader(\n",
    "    eval_tgt_dataset,\n",
    "    batch_size=training_args.per_device_eval_batch_size,\n",
    "    collate_fn=eval_collator,\n",
    "    shuffle=False,\n",
    "    drop_last=False,\n",
    "    num_workers=0,\n",
    ")\n",
    "\n",
    "def batch_to_device(batch, device):\n",
    "    _batch = {}\n",
    "    for key, value in batch.items():\n",
    "        if isinstance(value, torch.Tensor):\n",
    "            _batch[key] = value.to(device)\n",
    "        else:\n",
    "            _batch[key] = value\n",
    "    return _batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "438338c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You're using a Qwen2TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    }
   ],
   "source": [
    "for batch in eval_qry_loader:\n",
    "    batch = batch_to_device(batch, training_args.device)\n",
    "    with torch.autocast(enabled=True, dtype=torch.bfloat16, device_type=\"cuda\"):\n",
    "    # batch[\"pixel_values\"] = batch[\"pixel_values\"].to(torch.bfloat16)\n",
    "    \n",
    "        pooled_output, hidden_states, image_features, all_layers_embeds, attention_matrix = model.encode_input(batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "89c123ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(\"test\", \"output_t_qry.pkl\"), \"wb\") as f:\n",
    "    pickle.dump({\n",
    "        \"pooled_output\": pooled_output,\n",
    "        \"hidden_states\": hidden_states,\n",
    "        \"image_features\": image_features,\n",
    "        \"all_layers_embeds\": all_layers_embeds,\n",
    "        \"attention_matrix\": attention_matrix,\n",
    "        \"input_data\": batch,\n",
    "    }, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d31685f2",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'os' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(\u001b[43mos\u001b[49m.path.join(\u001b[33m\"\u001b[39m\u001b[33mtest\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33moutput_s_qry.pkl\u001b[39m\u001b[33m\"\u001b[39m), \u001b[33m\"\u001b[39m\u001b[33mrb\u001b[39m\u001b[33m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[32m      2\u001b[39m     x = pickle.load(f)\n",
      "\u001b[31mNameError\u001b[39m: name 'os' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "with open(os.path.join(\"test\", \"output_s_qry.pkl\"), \"rb\") as f:\n",
    "    x = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2e79ac91",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(\"test\", \"output_t_qry.pkl\"), \"rb\") as f:\n",
    "    y = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c0ac4f99",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 12, 278, 278])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y['attention_matrix'][0].size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "891c8f26",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(x['image_features'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f58f5f7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(\"test\", \"output_s_qry.pkl\"), \"wb\") as f:\n",
    "    pickle.dump({\n",
    "        \"pooled_output\": pooled_output,\n",
    "        \"hidden_states\": hidden_states,\n",
    "        \"image_features\": image_features,\n",
    "        \"all_layers_embeds\": all_layers_embeds,\n",
    "        \"attention_matrix\": attention_matrix,\n",
    "        \"input_data\": batch,\n",
    "    }, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "8d8e41ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "allocated: 3770242560 cached: 6836715520\n"
     ]
    }
   ],
   "source": [
    "import gc, torch\n",
    "\n",
    "# delete references to large tensors/models you created\n",
    "for name in (\"batch\", \"pooled_output\", \"image_features\", \"attention_matrix\", \"model\"):\n",
    "    if name in globals():\n",
    "        try:\n",
    "            del globals()[name]\n",
    "        except Exception:\n",
    "            pass\n",
    "\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()\n",
    "torch.cuda.synchronize()\n",
    "\n",
    "# optional: reset tracking and print status\n",
    "for i in range(torch.cuda.device_count()):\n",
    "    torch.cuda.reset_peak_memory_stats(i)\n",
    "print(\"allocated:\", torch.cuda.memory_allocated(), \"cached:\", torch.cuda.memory_reserved())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "bb4bcb57",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"/home/user2/dangnh/VLM_Embed/test/output_t_qry.pkl\", 'rb') as file:\n",
    "    # Use pickle.load() to read the byte stream and deserialize the object\n",
    "    loaded_object = pickle.load(file)\n",
    "    # load to cuda\n",
    "    loaded_object = {k: v.to(\"cuda\") if isinstance(v, torch.Tensor) else v for k, v in loaded_object.items()}\n",
    "    t_qry_reps, t_qry_hidden_states, t_qry_img_feats, t_qry_layers_embeds, t_qry_attention, t_qry_input_data = \\\n",
    "                                                                                loaded_object.values()\n",
    "    t_pos_reps, t_pos_hidden_states, t_pos_img_feats, t_pos_layers_embeds, t_pos_attention, t_pos_input_data = \\\n",
    "                                                                                loaded_object.values()\n",
    "    \n",
    "with open(\"/home/user2/dangnh/VLM_Embed/test/output_s_qry.pkl\", 'rb') as file:\n",
    "    # Use pickle.load() to read the byte stream and deserialize the object\n",
    "    loaded_object = pickle.load(file)\n",
    "    loaded_object = {k: v.to(\"cuda\") if isinstance(v, torch.Tensor) else v for k, v in loaded_object.items()}\n",
    "\n",
    "    s_qry_reps, s_qry_hidden_states, s_qry_img_feats, s_qry_layers_embeds, s_qry_attention, s_qry_input_data = \\\n",
    "                                                                loaded_object.values()\n",
    "    s_pos_reps, s_pos_hidden_states, s_pos_img_feats, s_pos_layers_embeds, s_pos_attention, s_pos_input_data = \\\n",
    "                                                                loaded_object.values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1de947de",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[106]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43mmodel\u001b[49m\n",
      "\u001b[31mNameError\u001b[39m: name 'model' is not defined"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8ad7532a",
   "metadata": {},
   "source": [
    "# Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "f3c2f13f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn \n",
    "import torch.distributed as dist\n",
    "import torch.nn.functional as F\n",
    "from src.criterions.soft_DTW import SoftDTW\n",
    "import ot\n",
    "# ot.backend.get_backend('pytorch')\n",
    "\n",
    "def create_semi_orthogonal_matrix(tensor):\n",
    "    rows, cols = tensor.shape\n",
    "    if rows >= cols:\n",
    "        # QR trực tiếp\n",
    "        a = torch.randn(rows, cols, device=tensor.device, dtype=tensor.dtype)\n",
    "        q, _ = torch.linalg.qr(a, mode='reduced')\n",
    "        tensor.data[:] = q[:, :cols]\n",
    "    else:\n",
    "        # QR trên ma trận transpose để đảm bảo W W^T = I\n",
    "        a = torch.randn(cols, rows, device=tensor.device, dtype=tensor.dtype)\n",
    "        q, _ = torch.linalg.qr(a, mode='reduced')\n",
    "        tensor.data[:] = q.T[:rows, :]\n",
    "    return tensor\n",
    "\n",
    "class Distiller(nn.Module):\n",
    "    def __init__(self, model_args, training_args, device):\n",
    "        super(Distiller, self).__init__()\n",
    "        self.model_args = model_args\n",
    "        self.training_args = training_args\n",
    "        self.device = device\n",
    "\n",
    "        self.student_hidden_dim = 896\n",
    "        self.teacher_hidden_dim = 1536\n",
    "        self.temperature = 0.02\n",
    "        self.set_projector()\n",
    "        print(\"Projectors set.\")\n",
    "\n",
    "        self.t2s_img_align = nn.Sequential(\n",
    "            nn.Linear(self.teacher_hidden_dim, self.student_hidden_dim),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        self.t2s_img_align.to(device=\"cuda\")\n",
    "\n",
    "        # for simple kd\n",
    "        self.last_layer_projector = nn.Sequential(\n",
    "            nn.Linear(self.teacher_hidden_dim, self.student_hidden_dim),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        self.last_layer_projector.to(device=\"cuda\")\n",
    "\n",
    "        # for Soft-DTW\n",
    "        self.num_chosen_hidden_states = 3\n",
    "        self.t2s = nn.ModuleList([\n",
    "            nn.Sequential(\n",
    "                nn.Linear(self.teacher_hidden_dim, self.student_hidden_dim),\n",
    "                nn.ReLU()\n",
    "            )       \n",
    "        ] * self.num_chosen_hidden_states)\n",
    "\n",
    "        self.t2s.to(device=\"cuda\")\n",
    "        \n",
    "    def set_projector(self):\n",
    "        self.projectors = nn.ModuleDict()\n",
    "        projector_config = json.load(open(\"/home/user2/dangnh/VLM_Embed/config/projector_config.json\", 'r'))\n",
    "        \n",
    "        name_dict = {\n",
    "            \"s\": self.student_hidden_dim,\n",
    "            \"t\": self.teacher_hidden_dim,\n",
    "            \"relu\": nn.ReLU()\n",
    "        }\n",
    "        \n",
    "        for name, cfg in projector_config.items():\n",
    "            if not cfg.get(\"enabled\", False):\n",
    "                continue\n",
    "            seq = nn.Sequential()\n",
    "            parts = cfg[\"structure\"].split(\"-\")\n",
    "            parsed = []\n",
    "            \n",
    "            for p in parts:\n",
    "                if p == \"relu\":\n",
    "                    parsed.append(\"relu\")\n",
    "                else:\n",
    "                    coef = int(p[:-1]) if len(p) > 1 and p[:-1].isdigit() else 1\n",
    "                    parsed.append(coef * name_dict[p[-1]])\n",
    "            for i in range(len(parsed) -1):\n",
    "                a, b = parsed[i], parsed[i+1]\n",
    "                if isinstance(a, int) and isinstance(b, int):\n",
    "                    layer = nn.Linear(a, b)\n",
    "                    create_semi_orthogonal_matrix(layer.weight)\n",
    "                    seq.append(layer)\n",
    "                elif b == \"relu\":\n",
    "                    seq.append(name_dict[b])\n",
    "                elif a ==\"relu\" and isinstance(b, int):\n",
    "                    prev_out = parsed[i-1] if isinstance(parsed[i-1], int) else None\n",
    "                    layer = nn.Linear(prev_out, b)\n",
    "                    create_semi_orthogonal_matrix(layer.weight)\n",
    "                    seq.append(layer)\n",
    "            self.projectors[name] = seq\n",
    "            print(f\"Projector {name} created with structure: {seq}\")\n",
    "    \n",
    "    def add_optimizer_param_group(self, optimizer):\n",
    "        if hasattr(self, 'projectors'):\n",
    "            lr = 0.001\n",
    "            optimizer.add_param_group({\n",
    "                \"params\": [p for proj in self.projectors.values() for p in proj.parameters()],\n",
    "                \"lr\": lr\n",
    "            })\n",
    "        print(\"Projector parameters added to optimizer.\")\n",
    "        return optimizer\n",
    "\n",
    "class StrongerKD(nn.Module):\n",
    "    def __init__(self, args):\n",
    "        super(StrongerKD, self).__init__()\n",
    "        self.args = args\n",
    "        self.rkd_loss_weight = 0.5\n",
    "        self.simple_kd_weight = 0.5\n",
    "        self.intra_rkd_weight = 0.5\n",
    "        self.cross_modal_kd_weight = 0.01\n",
    "        self.ot_loss_weight = 0.5\n",
    "        self.num_chosen_hidden_states = 3\n",
    "\n",
    "        self.cross_entropy_loss = nn.CrossEntropyLoss()\n",
    "        self.sdtw = SoftDTW(use_cuda=True, gamma=0.001)\n",
    "        self.mse_loss = nn.MSELoss(reduction=\"mean\")\n",
    "\n",
    "\n",
    "    def forward(self, distiller, input_data):\n",
    "        self.distiller = Distiller(model_args, training_args, \"cuda\")\n",
    "        # student_model = distiller.student\n",
    "        # teacher_model = distiller.teacher\n",
    "        \n",
    "        with open(\"/home/user2/dangnh/VLM_Embed/test/output_t_qry.pkl\", 'rb') as file:\n",
    "            # Use pickle.load() to read the byte stream and deserialize the object\n",
    "            loaded_object = pickle.load(file)\n",
    "            # load to cuda\n",
    "            loaded_object = {k: v.to(\"cuda\") if isinstance(v, torch.Tensor) else v for k, v in loaded_object.items()}\n",
    "            t_qry_reps, t_qry_hidden_states, t_qry_img_feats, t_qry_layers_embeds, t_qry_attention, t_qry_input_data = \\\n",
    "                                                                                        loaded_object.values()\n",
    "            t_pos_reps, t_pos_hidden_states, t_pos_img_feats, t_pos_layers_embeds, t_pos_attention, t_pos_input_data = \\\n",
    "                                                                                        loaded_object.values()\n",
    "            \n",
    "            # t_qry_hidden_states, t_qry_img_feats = torch.stack(t_qry_hidden_states, dim=0), torch.stack(t_qry_img_feats, dim=0)\n",
    "            # t_pos_hidden_states, t_pos_img_feats = torch.stack(t_pos_hidden_states, dim=0), torch.stack(t_pos_img_feats, dim=0)\n",
    "        with open(\"/home/user2/dangnh/VLM_Embed/test/output_s_qry.pkl\", 'rb') as file:\n",
    "            # Use pickle.load() to read the byte stream and deserialize the object\n",
    "            loaded_object = pickle.load(file)\n",
    "            loaded_object = {k: v.to(\"cuda\") if isinstance(v, torch.Tensor) else v for k, v in loaded_object.items()}\n",
    "\n",
    "            s_qry_reps, s_qry_hidden_states, s_qry_img_feats, s_qry_layers_embeds, s_qry_attention, s_qry_input_data = \\\n",
    "                                                                        loaded_object.values()\n",
    "            s_pos_reps, s_pos_hidden_states, s_pos_img_feats, s_pos_layers_embeds, s_pos_attention, s_pos_input_data = \\\n",
    "                                                                        loaded_object.values()\n",
    "            # s_qry_hidden_states, s_qry_img_feats = torch.stack(s_qry_hidden_states, dim=0), torch.stack(s_qry_img_feats, dim=0)\n",
    "            # s_pos_hidden_states, s_pos_img_feats = torch.stack(s_pos_hidden_states, dim=0), torch.stack(s_pos_img_feats, dim=0)\n",
    "\n",
    "        ## contrastive\n",
    "        # scores = student_model.compute_similarity(s_qry_reps, s_pos_reps)\n",
    "        # scores = scores.view(s_qry_reps.size(0), -1)\n",
    "        # target = torch.arange(scores.size(0), device=scores.device, dtype=torch.long)\n",
    "        # target = target * (s_qry_reps.size(0) // s_pos_reps.size(0))\n",
    "        # contrastive_loss = self.cross_entropy_loss(scores / self.distiller.temperature, target)\n",
    "        contrastive_loss = torch.tensor(0.0).to(\"cuda\")\n",
    "        ## image alignments\n",
    "        img_align_loss = 0.0\n",
    "        batch_size = s_qry_reps.size(0)\n",
    "\n",
    "        for i in range(batch_size):\n",
    "            if s_qry_img_feats is not None and t_qry_img_feats is not None:\n",
    "                if s_qry_img_feats[i] is not None and t_qry_img_feats[i] is not None:\n",
    "                    tmp_s_qry_img_feats = F.normalize(s_qry_img_feats[i], p=2, dim=-1)\n",
    "                    tmp_t_qry_img_feats = self.distiller.t2s_img_align(t_qry_img_feats[i])\n",
    "\n",
    "                    tmp_t_qry_image_features = F.normalize(tmp_t_qry_img_feats, p=2, dim=-1)\n",
    "\n",
    "                    img_align_loss += self.alignment_loss_mmd(tmp_t_qry_image_features, tmp_s_qry_img_feats)\n",
    "\n",
    "            if s_pos_img_feats is not None and t_pos_img_feats is not None:\n",
    "                if s_pos_img_feats[i] is not None and t_pos_img_feats[i] is not None:\n",
    "                    tmp_s_pos_img_feats = F.normalize(s_pos_img_feats[i], p=2, dim=-1)\n",
    "                    tmp_t_pos_img_feats = self.distiller.t2s_img_align(t_pos_img_feats[i])\n",
    "                    \n",
    "                    tmp_t_pos_image_features = F.normalize(tmp_t_pos_img_feats, p=2, dim=-1)\n",
    "\n",
    "                    img_align_loss += self.alignment_loss_mmd(tmp_t_pos_image_features, tmp_s_pos_img_feats)\n",
    "\n",
    "        img_align_loss = img_align_loss / batch_size\n",
    "\n",
    "        ## data-points rkd \n",
    "        distance_loss = self.compute_distance_loss(s_qry_reps, s_pos_reps, t_qry_reps, t_pos_reps)\n",
    "        angle_loss = self.compute_angle_loss(s_qry_reps, s_pos_reps, t_qry_reps, t_pos_reps)\n",
    "\n",
    "        rkd_loss = (0.5 * distance_loss + 0.5 * angle_loss)\n",
    "\n",
    "        ## simple kd\n",
    "        simple_kd_loss = self.simple_kd_logit_loss(s_qry_reps, s_pos_reps, t_qry_reps, t_pos_reps)\n",
    "\n",
    "        ## intra rkd\n",
    "        intra_rkd_loss = self.intra_rkd(t_qry_layers_embeds, t_pos_layers_embeds,\n",
    "                                        s_qry_layers_embeds, s_pos_layers_embeds)\n",
    "        \n",
    "        ## cross modal kd\n",
    "        # num_s_img_tokens, num_t_img_tokens = s_qry_img_feats.size(1), t_qry_img_feats.size(1)\n",
    "        qry_cross_modal_kd_loss = self.cross_modal_kd_loss(s_qry_hidden_states,\n",
    "                                                       t_qry_hidden_states,\n",
    "                                                       s_qry_img_feats,\n",
    "                                                       t_qry_img_feats)\n",
    "\n",
    "        # num_s_img_tokens, num_t_img_tokens = s_pos_img_feats.size(1), t_pos_img_feats.size(1)\n",
    "        pos_cross_modal_kd_loss = self.cross_modal_kd_loss(s_pos_hidden_states,\n",
    "                                                       t_pos_hidden_states,\n",
    "                                                       s_pos_img_feats,\n",
    "                                                       t_pos_img_feats)\n",
    "        \n",
    "        cross_modal_kd_loss = 0.5 * qry_cross_modal_kd_loss + 0.5 * pos_cross_modal_kd_loss\n",
    "\n",
    "        ## optimal transport loss\n",
    "        ot_loss = self.compute_ot(s_qry_hidden_states, s_qry_attention,\n",
    "                                  t_qry_hidden_states, t_qry_attention)\n",
    "        ot_loss += self.compute_ot(s_pos_hidden_states, s_pos_attention,\n",
    "                                  t_pos_hidden_states, t_pos_attention)\n",
    "        ot_loss = ot_loss / 2.0\n",
    "\n",
    "        total_loss = contrastive_loss + \\\n",
    "                     self.rkd_loss_weight * rkd_loss + \\\n",
    "                     self.simple_kd_weight * simple_kd_loss + \\\n",
    "                     self.intra_rkd_weight * intra_rkd_loss + \\\n",
    "                     self.cross_modal_kd_weight * cross_modal_kd_loss + \\\n",
    "                     self.ot_loss_weight * ot_loss\n",
    "        \n",
    "        return {\n",
    "            \"total_loss\": total_loss,\n",
    "            \"contrastive_loss\": contrastive_loss,\n",
    "            \"rkd_loss\": rkd_loss,\n",
    "            \"simple_kd_loss\": simple_kd_loss,\n",
    "            \"intra_rkd_loss\": intra_rkd_loss,\n",
    "            \"cross_modal_kd_loss\": cross_modal_kd_loss,\n",
    "            \"ot_loss\": ot_loss,\n",
    "            \"img_align_loss\": img_align_loss\n",
    "        }\n",
    "\n",
    "    def gaussian_kernel(self, x, y, sigma=2.0):\n",
    "        \"\"\"\n",
    "        Computes the RBF (Gaussian) kernel between two sets of vectors.\n",
    "        k(x, y) = exp(-||x - y||^2 / (2 * sigma^2))\n",
    "        \n",
    "        Args:\n",
    "            x (torch.Tensor): Shape (n, dim)\n",
    "            y (torch.Tensor): Shape (m, dim)\n",
    "            sigma (float): Kernel bandwidth.\n",
    "        \"\"\"\n",
    "        beta = 1.0 / (2.0 * (sigma ** 2))\n",
    "        # (n, m) matrix of squared pairwise distances\n",
    "        dist_sq = torch.cdist(x.unsqueeze(0), y.unsqueeze(0), p=2).pow(2)\n",
    "        return torch.exp(-beta * dist_sq)\n",
    "\n",
    "    def alignment_loss_mmd(self, t_feats, s_feats, sigma=2.0):\n",
    "        \"\"\"\n",
    "        Computes the Maximum Mean Discrepancy (MMD) loss using a Gaussian kernel.\n",
    "\n",
    "        Args:\n",
    "            x_teacher (torch.Tensor): Teacher features, shape (n, dim)\n",
    "            x_student (torch.Tensor): Student features, shape (m, dim)\n",
    "            sigma (float): Kernel bandwidth.\n",
    "        \"\"\"\n",
    "        \n",
    "        # Compute kernel matrices\n",
    "        k_tt = self.gaussian_kernel(t_feats, t_feats, sigma) # (n, n)\n",
    "        k_ss = self.gaussian_kernel(s_feats, s_feats, sigma) # (m, m)\n",
    "        k_ts = self.gaussian_kernel(t_feats, s_feats, sigma) # (n, m)\n",
    "        \n",
    "        # This is the (biased) MMD^2 statistic\n",
    "        # E[k(t, t')] + E[k(s, s')] - 2 * E[k(t, s)]\n",
    "        mmd_loss = k_tt.mean() + k_ss.mean() - 2 * k_ts.mean()\n",
    "        \n",
    "        return mmd_loss\n",
    "    \n",
    "    def compute_ot(self, s_hidden_states, s_attn, t_hidden_states, t_attn):\n",
    "        \n",
    "        loss = 0.0\n",
    "        num_student_layers = len(s_hidden_states)\n",
    "        num_teacher_layers = len(t_hidden_states)\n",
    "        scale = num_teacher_layers // num_student_layers\n",
    "        start_layer = num_student_layers - self.distiller.num_chosen_hidden_states\n",
    "\n",
    "        for l in range(start_layer, num_student_layers):\n",
    "            s_dist = F.softmax(s_attn[l - 1].mean(dim=1)[:, -1], dim=-1) # (b, n)\n",
    "            t_dist = F.softmax(t_attn[l - 1].mean(dim=1)[:, -1], dim=-1) # (b, m)\n",
    "\n",
    "            s_hidden_state = s_hidden_states[l] # (b, n, emb_dim)\n",
    "            proj_t_hidden_state = self.distiller.t2s[l - start_layer](t_hidden_states[scale * l]) # (b, m, emb_dim)\n",
    "\n",
    "            for b in range(s_dist.size(0)):\n",
    "                cost_matrix = torch.cdist(s_hidden_state[b].unsqueeze(0), \n",
    "                                          proj_t_hidden_state[b].unsqueeze(0)).squeeze(0)\n",
    "\n",
    "                transport = self.sinkhorn(s_dist[b], t_dist[b], cost_matrix) \n",
    "                loss += torch.sum(transport * cost_matrix)\n",
    "\n",
    "        return loss / s_dist.size(0)\n",
    "    \n",
    "    def sinkhorn(self, a, b, cost_matrix, reg=0.1, num_iters=100, eps=1e-9, stopThr = 1e-7):\n",
    "        \"\"\"\n",
    "        a: (m,) or (m,1) torch tensor (source weights)\n",
    "        b: (n,) or (n,1) torch tensor (target weights)\n",
    "        cost_matrix: (m, n) torch tensor\n",
    "        reg: regularization (>=0) -- larger reg -> smoother K = exp(-C/reg)\n",
    "        num_iters: number of Sinkhorn iterations\n",
    "        \"\"\"\n",
    "        device = cost_matrix.device\n",
    "        # use float32 for numeric stability\n",
    "        dtype = torch.float32\n",
    "        a = a.detach().to(device=device, dtype=dtype).view(-1, 1)\n",
    "        b = b.detach().to(device=device, dtype=dtype).view(-1, 1)\n",
    "        C = cost_matrix.detach().to(device=device, dtype=dtype)\n",
    "\n",
    "        m, n = C.shape\n",
    "        if m == 0 or n == 0:\n",
    "            return torch.zeros((m, n), device=device, dtype=dtype)\n",
    "\n",
    "        # ensure shapes\n",
    "        if a.shape[0] != m:\n",
    "            a = torch.ones((m, 1), device=device, dtype=dtype) / m\n",
    "        if b.shape[0] != n:\n",
    "            b = torch.ones((n, 1), device=device, dtype=dtype) / n\n",
    "\n",
    "        suma = a.sum()\n",
    "        sumb = b.sum()\n",
    "        if suma <= eps or sumb <= eps:\n",
    "            a = torch.ones((m, 1), device=device, dtype=dtype) / m\n",
    "            b = torch.ones((n, 1), device=device, dtype=dtype) / n\n",
    "        else:\n",
    "            a = a / suma\n",
    "            b = b / sumb\n",
    "\n",
    "        K = torch.exp(-C / (reg + 1e-12))\n",
    "        K = torch.clamp(K, min=1e-200)\n",
    "\n",
    "        u = torch.ones((m, 1), device=device, dtype=dtype)\n",
    "        v = torch.ones((n, 1), device=device, dtype=dtype)\n",
    "\n",
    "        for i in range(num_iters):\n",
    "            u_prev = u.clone()\n",
    "            KTv = (K.t() @ u)  # shape (n,1)\n",
    "            v = b / (KTv + eps)\n",
    "            Kv = (K @ v)       # shape (m,1)\n",
    "            u = a / (Kv + eps)\n",
    "\n",
    "            err = torch.max(torch.abs(u - u_prev))\n",
    "            if err.item() < stopThr:\n",
    "                break\n",
    "\n",
    "        # transport plan\n",
    "        U = torch.diag_embed(u.squeeze())   # (m,m) diag(u)\n",
    "        V = torch.diag_embed(v.squeeze())   # (n,n) diag(v)\n",
    "        P = U @ K @ V                       # (m,n)\n",
    "        return P\n",
    "    \n",
    "    def cross_modal_kd_loss(self, s_hidden_states, t_hidden_states, s_img_feats, t_img_feats):\n",
    "        \"\"\"\n",
    "            hidden_states: list of (n_layers, b, n, dim)\n",
    "            img_feats: (b, n_img_tokens, dim)\n",
    "        \"\"\"\n",
    "\n",
    "        loss = 0.0\n",
    "        num_student_layers = len(s_hidden_states)\n",
    "        num_teacher_layers = len(t_hidden_states)\n",
    "        scale = num_teacher_layers // num_student_layers\n",
    "        batch_size = s_hidden_states[0].size(0)\n",
    "        start_layer = num_student_layers - self.distiller.num_chosen_hidden_states\n",
    "\n",
    "        if s_img_feats is None or t_img_feats is None:\n",
    "            return loss\n",
    "        \n",
    "        for b in range(batch_size):\n",
    "            if s_img_feats[b] is not None and t_img_feats[b] is not None:\n",
    "\n",
    "                for l in range(start_layer, num_student_layers):\n",
    "\n",
    "                    num_s_img_tokens = s_img_feats[b].size(0)\n",
    "                    num_t_img_tokens = t_img_feats[b].size(0)\n",
    "\n",
    "                    s_img_hidden_states = F.normalize(s_hidden_states[l][b][:num_s_img_tokens])\n",
    "                    s_text_hidden_states = F.normalize(s_hidden_states[l][b][num_s_img_tokens:])\n",
    "\n",
    "                    proj_t_img_hidden_states = F.normalize(self.distiller.t2s[l - start_layer](t_hidden_states[scale * l][b][:num_t_img_tokens]))\n",
    "                    proj_t_text_hidden_states = F.normalize(self.distiller.t2s[l - start_layer](t_hidden_states[scale * l][b][num_t_img_tokens:]))\n",
    "                    print(f\"s_img_hidden_states shape: {s_img_hidden_states.shape}\")\n",
    "                    print(f\"t_img_hs shape: {proj_t_img_hidden_states.shape}\")\n",
    "                    \n",
    "                    loss += 0.5 * self.sdtw(s_img_hidden_states.unsqueeze(0), proj_t_text_hidden_states.unsqueeze(0)).mean()\n",
    "                    loss += 0.5 * self.sdtw(s_text_hidden_states.unsqueeze(0), proj_t_img_hidden_states.unsqueeze(0)).mean()\n",
    "\n",
    "        return loss / (batch_size * self.distiller.num_chosen_hidden_states)\n",
    "    \n",
    "    def simple_kd_logit_loss(self, student_qry_reps, student_pos_reps, teacher_qry_reps, teacher_pos_reps):\n",
    "            projector_teacher_qry_reps = self.distiller.last_layer_projector(teacher_qry_reps)\n",
    "            projector_teacher_qry_reps = F.normalize(projector_teacher_qry_reps, p=2, dim=-1)\n",
    "\n",
    "            projector_teacher_pos_reps = self.distiller.last_layer_projector(teacher_pos_reps)\n",
    "            projector_teacher_pos_reps = F.normalize(projector_teacher_qry_reps, p=2, dim=-1)\n",
    "\n",
    "\n",
    "            loss = (\n",
    "                    self.mse_loss(student_qry_reps, projector_teacher_qry_reps) +  \n",
    "                    self.mse_loss(student_pos_reps, projector_teacher_pos_reps)\n",
    "                   ) / 2.0\n",
    "            return loss\n",
    "    \n",
    "    def intra_rkd(self, \n",
    "                  teacher_qry_layers_embeds, # (b, n_layers, dim), \n",
    "                  teacher_pos_layers_embeds,\n",
    "                  student_qry_layers_embeds,\n",
    "                  student_pos_layers_embeds):\n",
    "        \n",
    "        loss = 0.0\n",
    "        batch_size = student_pos_layers_embeds.size(0)\n",
    "\n",
    "        for b in range(batch_size):\n",
    "\n",
    "            dist_loss = self.compute_distance_loss(student_qry_layers_embeds[b], student_pos_layers_embeds[b], \n",
    "                                                   teacher_qry_layers_embeds[b], teacher_pos_layers_embeds[b])\n",
    "            \n",
    "            angle_loss = self.compute_angle_loss(student_qry_layers_embeds[b], student_pos_layers_embeds[b], \n",
    "                                                    teacher_qry_layers_embeds[b], teacher_pos_layers_embeds[b])\n",
    "            loss += 0.5 * dist_loss + 0.5 * angle_loss\n",
    "\n",
    "        return loss / batch_size\n",
    "\n",
    "    def pairwise_distance(self, x):\n",
    "        norm = (x**2).sum(dim=1, keepdim=True)\n",
    "        dist = norm + norm.t() - 2.0 * torch.mm(x, x.t())\n",
    "        return dist\n",
    "    \n",
    "    def compute_distance_loss(self, student_qry, student_pos, teacher_qry, teacher_pos):\n",
    "        \n",
    "        num_student_layers = student_qry.size(0)\n",
    "        num_teacher_layers = teacher_qry.size(0)\n",
    "        scale = num_teacher_layers // num_student_layers\n",
    "\n",
    "        student_repr = torch.cat([student_qry, student_pos], dim=1)\n",
    "        teacher_repr = torch.cat([teacher_qry, teacher_pos], dim=1)[\n",
    "            torch.tensor([i * scale for i in range(num_student_layers)], device=teacher_qry.device)\n",
    "        ]\n",
    "\n",
    "        dist_student = self.pairwise_distance(student_repr)\n",
    "        dist_teacher = self.pairwise_distance(teacher_repr)\n",
    "        \n",
    "        mask = torch.triu(torch.ones_like(dist_student), diagonal=1).bool()\n",
    "        dist_student = dist_student[mask]\n",
    "        dist_teacher = dist_teacher[mask]\n",
    "        \n",
    "        mean_td = dist_teacher.mean().detach() + 1e-8\n",
    "        mean_sd = dist_student.mean().detach() + 1e-8\n",
    "        \n",
    "        dist_student = dist_student / mean_sd\n",
    "        dist_teacher = dist_teacher / mean_td\n",
    "        \n",
    "        diff = dist_student - dist_teacher\n",
    "        abs_diff = torch.abs(diff)\n",
    "        quadratic = 0.5 * (abs_diff ** 2)\n",
    "        linear = abs_diff - 0.5\n",
    "        \n",
    "        loss = torch.where(abs_diff < 1.0, quadratic, linear)\n",
    "        loss = loss.mean()\n",
    "        return loss\n",
    "    \n",
    "    def angle_potentials(self, x):\n",
    "        n = x.size(0)\n",
    "        diffs = x.unsqueeze(0) - x.unsqueeze(1)\n",
    "        norms = torch.norm(diffs, dim=-1, keepdim=True) + 1e-8\n",
    "        e = diffs / norms\n",
    "        \n",
    "        cos_angles = torch.einsum('ijd,kjd->ijk', e, e)\n",
    "        return cos_angles\n",
    "    \n",
    "    def compute_angle_loss(self, student_qry, student_pos, teacher_qry, teacher_pos):\n",
    "        \n",
    "        num_student_layers = student_qry.size(0)\n",
    "        num_teacher_layers = teacher_qry.size(0)\n",
    "        scale = num_teacher_layers // num_student_layers\n",
    "    \n",
    "        student_repr = torch.cat([student_qry, student_pos], dim=1)\n",
    "        teacher_repr = torch.cat([teacher_qry, teacher_pos], dim=1)[\n",
    "            torch.tensor([i * scale for i in range(num_student_layers)], device=teacher_qry.device)\n",
    "        ]\n",
    "\n",
    "        psi_student = self.angle_potentials(student_repr)\n",
    "        psi_teacher = self.angle_potentials(teacher_repr)\n",
    "        \n",
    "        n = psi_student.size(0)\n",
    "        mask = torch.ones((n, n, n), dtype=torch.bool, device=psi_student.device)\n",
    "        idx = torch.arange(n, device=psi_student.device)\n",
    "        mask[idx, idx, :] = 0\n",
    "        mask[idx, :, idx] = 0\n",
    "        mask[:, idx, idx] = 0\n",
    "        \n",
    "        psi_teacher = psi_teacher[mask]\n",
    "        psi_student = psi_student[mask]\n",
    "        \n",
    "        diff = psi_student - psi_teacher\n",
    "        abs_diff = torch.abs(diff)\n",
    "        quadratic = 0.5 * (abs_diff ** 2)\n",
    "        linear = abs_diff - 0.5\n",
    "        loss = torch.where(abs_diff < 1.0, quadratic, linear)\n",
    "        loss = loss.mean()\n",
    "        return loss\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "fbe499be",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = StrongerKD(training_args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "63f09590",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Projector t2s_img created with structure: Sequential(\n",
      "  (0): Linear(in_features=1536, out_features=896, bias=True)\n",
      ")\n",
      "Projector t2s_txt created with structure: Sequential(\n",
      "  (0): Linear(in_features=1536, out_features=896, bias=True)\n",
      ")\n",
      "Projectors set.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2025-11-08 05:00:53,548] DEBUG [numba.cuda.cudadrv.driver:325] call driver api: cuCtxGetCurrent\n",
      "[2025-11-08 05:00:53,549] DEBUG [numba.cuda.cudadrv.driver:325] call driver api: cuCtxGetDevice\n",
      "[2025-11-08 05:00:53,549] DEBUG [numba.cuda.cudadrv.driver:325] call driver api: cuPointerGetAttribute\n",
      "[2025-11-08 05:00:53,550] DEBUG [numba.cuda.cudadrv.driver:325] call driver api: cuCtxGetCurrent\n",
      "[2025-11-08 05:00:53,551] DEBUG [numba.cuda.cudadrv.driver:325] call driver api: cuCtxGetDevice\n",
      "[2025-11-08 05:00:53,552] DEBUG [numba.cuda.cudadrv.driver:325] call driver api: cuPointerGetAttribute\n",
      "[2025-11-08 05:00:53,552] DEBUG [numba.cuda.cudadrv.driver:325] call driver api: cuCtxGetCurrent\n",
      "[2025-11-08 05:00:53,553] DEBUG [numba.cuda.cudadrv.driver:325] call driver api: cuCtxGetDevice\n",
      "[2025-11-08 05:00:53,554] DEBUG [numba.cuda.cudadrv.driver:325] call driver api: cuLaunchKernel\n",
      "[2025-11-08 05:00:53,557] DEBUG [numba.cuda.cudadrv.driver:325] call driver api: cuCtxGetCurrent\n",
      "[2025-11-08 05:00:53,557] DEBUG [numba.cuda.cudadrv.driver:325] call driver api: cuCtxGetDevice\n",
      "[2025-11-08 05:00:53,558] DEBUG [numba.cuda.cudadrv.driver:325] call driver api: cuPointerGetAttribute\n",
      "[2025-11-08 05:00:53,559] DEBUG [numba.cuda.cudadrv.driver:325] call driver api: cuCtxGetCurrent\n",
      "[2025-11-08 05:00:53,560] DEBUG [numba.cuda.cudadrv.driver:325] call driver api: cuCtxGetDevice\n",
      "[2025-11-08 05:00:53,561] DEBUG [numba.cuda.cudadrv.driver:325] call driver api: cuPointerGetAttribute\n",
      "[2025-11-08 05:00:53,561] DEBUG [numba.cuda.cudadrv.driver:325] call driver api: cuCtxGetCurrent\n",
      "[2025-11-08 05:00:53,562] DEBUG [numba.cuda.cudadrv.driver:325] call driver api: cuCtxGetDevice\n",
      "[2025-11-08 05:00:53,562] DEBUG [numba.cuda.cudadrv.driver:325] call driver api: cuLaunchKernel\n",
      "[2025-11-08 05:00:53,566] DEBUG [numba.cuda.cudadrv.driver:325] call driver api: cuCtxGetCurrent\n",
      "[2025-11-08 05:00:53,567] DEBUG [numba.cuda.cudadrv.driver:325] call driver api: cuCtxGetDevice\n",
      "[2025-11-08 05:00:53,568] DEBUG [numba.cuda.cudadrv.driver:325] call driver api: cuPointerGetAttribute\n",
      "[2025-11-08 05:00:53,569] DEBUG [numba.cuda.cudadrv.driver:325] call driver api: cuCtxGetCurrent\n",
      "[2025-11-08 05:00:53,569] DEBUG [numba.cuda.cudadrv.driver:325] call driver api: cuCtxGetDevice\n",
      "[2025-11-08 05:00:53,570] DEBUG [numba.cuda.cudadrv.driver:325] call driver api: cuPointerGetAttribute\n",
      "[2025-11-08 05:00:53,571] DEBUG [numba.cuda.cudadrv.driver:325] call driver api: cuCtxGetCurrent\n",
      "[2025-11-08 05:00:53,571] DEBUG [numba.cuda.cudadrv.driver:325] call driver api: cuCtxGetDevice\n",
      "[2025-11-08 05:00:53,572] DEBUG [numba.cuda.cudadrv.driver:325] call driver api: cuLaunchKernel\n",
      "[2025-11-08 05:00:53,574] DEBUG [numba.cuda.cudadrv.driver:325] call driver api: cuCtxGetCurrent\n",
      "[2025-11-08 05:00:53,575] DEBUG [numba.cuda.cudadrv.driver:325] call driver api: cuCtxGetDevice\n",
      "[2025-11-08 05:00:53,575] DEBUG [numba.cuda.cudadrv.driver:325] call driver api: cuPointerGetAttribute\n",
      "[2025-11-08 05:00:53,577] DEBUG [numba.cuda.cudadrv.driver:325] call driver api: cuCtxGetCurrent\n",
      "[2025-11-08 05:00:53,577] DEBUG [numba.cuda.cudadrv.driver:325] call driver api: cuCtxGetDevice\n",
      "[2025-11-08 05:00:53,578] DEBUG [numba.cuda.cudadrv.driver:325] call driver api: cuPointerGetAttribute\n",
      "[2025-11-08 05:00:53,578] DEBUG [numba.cuda.cudadrv.driver:325] call driver api: cuCtxGetCurrent\n",
      "[2025-11-08 05:00:53,579] DEBUG [numba.cuda.cudadrv.driver:325] call driver api: cuCtxGetDevice\n",
      "[2025-11-08 05:00:53,580] DEBUG [numba.cuda.cudadrv.driver:325] call driver api: cuLaunchKernel\n",
      "[2025-11-08 05:00:53,587] DEBUG [numba.cuda.cudadrv.driver:325] call driver api: cuCtxGetCurrent\n",
      "[2025-11-08 05:00:53,587] DEBUG [numba.cuda.cudadrv.driver:325] call driver api: cuCtxGetDevice\n",
      "[2025-11-08 05:00:53,588] DEBUG [numba.cuda.cudadrv.driver:325] call driver api: cuPointerGetAttribute\n",
      "[2025-11-08 05:00:53,589] DEBUG [numba.cuda.cudadrv.driver:325] call driver api: cuCtxGetCurrent\n",
      "[2025-11-08 05:00:53,590] DEBUG [numba.cuda.cudadrv.driver:325] call driver api: cuCtxGetDevice\n",
      "[2025-11-08 05:00:53,591] DEBUG [numba.cuda.cudadrv.driver:325] call driver api: cuPointerGetAttribute\n",
      "[2025-11-08 05:00:53,591] DEBUG [numba.cuda.cudadrv.driver:325] call driver api: cuCtxGetCurrent\n",
      "[2025-11-08 05:00:53,592] DEBUG [numba.cuda.cudadrv.driver:325] call driver api: cuCtxGetDevice\n",
      "[2025-11-08 05:00:53,593] DEBUG [numba.cuda.cudadrv.driver:325] call driver api: cuLaunchKernel\n",
      "[2025-11-08 05:00:53,597] DEBUG [numba.cuda.cudadrv.driver:325] call driver api: cuCtxGetCurrent\n",
      "[2025-11-08 05:00:53,597] DEBUG [numba.cuda.cudadrv.driver:325] call driver api: cuCtxGetDevice\n",
      "[2025-11-08 05:00:53,598] DEBUG [numba.cuda.cudadrv.driver:325] call driver api: cuPointerGetAttribute\n",
      "[2025-11-08 05:00:53,599] DEBUG [numba.cuda.cudadrv.driver:325] call driver api: cuCtxGetCurrent\n",
      "[2025-11-08 05:00:53,600] DEBUG [numba.cuda.cudadrv.driver:325] call driver api: cuCtxGetDevice\n",
      "[2025-11-08 05:00:53,600] DEBUG [numba.cuda.cudadrv.driver:325] call driver api: cuPointerGetAttribute\n",
      "[2025-11-08 05:00:53,601] DEBUG [numba.cuda.cudadrv.driver:325] call driver api: cuCtxGetCurrent\n",
      "[2025-11-08 05:00:53,601] DEBUG [numba.cuda.cudadrv.driver:325] call driver api: cuCtxGetDevice\n",
      "[2025-11-08 05:00:53,602] DEBUG [numba.cuda.cudadrv.driver:325] call driver api: cuLaunchKernel\n",
      "[2025-11-08 05:00:53,605] DEBUG [numba.cuda.cudadrv.driver:325] call driver api: cuCtxGetCurrent\n",
      "[2025-11-08 05:00:53,605] DEBUG [numba.cuda.cudadrv.driver:325] call driver api: cuCtxGetDevice\n",
      "[2025-11-08 05:00:53,606] DEBUG [numba.cuda.cudadrv.driver:325] call driver api: cuPointerGetAttribute\n",
      "[2025-11-08 05:00:53,607] DEBUG [numba.cuda.cudadrv.driver:325] call driver api: cuCtxGetCurrent\n",
      "[2025-11-08 05:00:53,607] DEBUG [numba.cuda.cudadrv.driver:325] call driver api: cuCtxGetDevice\n",
      "[2025-11-08 05:00:53,608] DEBUG [numba.cuda.cudadrv.driver:325] call driver api: cuPointerGetAttribute\n",
      "[2025-11-08 05:00:53,608] DEBUG [numba.cuda.cudadrv.driver:325] call driver api: cuCtxGetCurrent\n",
      "[2025-11-08 05:00:53,609] DEBUG [numba.cuda.cudadrv.driver:325] call driver api: cuCtxGetDevice\n",
      "[2025-11-08 05:00:53,609] DEBUG [numba.cuda.cudadrv.driver:325] call driver api: cuLaunchKernel\n",
      "[2025-11-08 05:00:53,611] DEBUG [numba.cuda.cudadrv.driver:325] call driver api: cuCtxGetCurrent\n",
      "[2025-11-08 05:00:53,611] DEBUG [numba.cuda.cudadrv.driver:325] call driver api: cuCtxGetDevice\n",
      "[2025-11-08 05:00:53,612] DEBUG [numba.cuda.cudadrv.driver:325] call driver api: cuPointerGetAttribute\n",
      "[2025-11-08 05:00:53,612] DEBUG [numba.cuda.cudadrv.driver:325] call driver api: cuCtxGetCurrent\n",
      "[2025-11-08 05:00:53,613] DEBUG [numba.cuda.cudadrv.driver:325] call driver api: cuCtxGetDevice\n",
      "[2025-11-08 05:00:53,613] DEBUG [numba.cuda.cudadrv.driver:325] call driver api: cuPointerGetAttribute\n",
      "[2025-11-08 05:00:53,614] DEBUG [numba.cuda.cudadrv.driver:325] call driver api: cuCtxGetCurrent\n",
      "[2025-11-08 05:00:53,614] DEBUG [numba.cuda.cudadrv.driver:325] call driver api: cuCtxGetDevice\n",
      "[2025-11-08 05:00:53,614] DEBUG [numba.cuda.cudadrv.driver:325] call driver api: cuLaunchKernel\n",
      "[2025-11-08 05:00:53,617] DEBUG [numba.cuda.cudadrv.driver:325] call driver api: cuCtxGetCurrent\n",
      "[2025-11-08 05:00:53,617] DEBUG [numba.cuda.cudadrv.driver:325] call driver api: cuCtxGetDevice\n",
      "[2025-11-08 05:00:53,617] DEBUG [numba.cuda.cudadrv.driver:325] call driver api: cuPointerGetAttribute\n",
      "[2025-11-08 05:00:53,618] DEBUG [numba.cuda.cudadrv.driver:325] call driver api: cuCtxGetCurrent\n",
      "[2025-11-08 05:00:53,618] DEBUG [numba.cuda.cudadrv.driver:325] call driver api: cuCtxGetDevice\n",
      "[2025-11-08 05:00:53,619] DEBUG [numba.cuda.cudadrv.driver:325] call driver api: cuPointerGetAttribute\n",
      "[2025-11-08 05:00:53,619] DEBUG [numba.cuda.cudadrv.driver:325] call driver api: cuCtxGetCurrent\n",
      "[2025-11-08 05:00:53,619] DEBUG [numba.cuda.cudadrv.driver:325] call driver api: cuCtxGetDevice\n",
      "[2025-11-08 05:00:53,620] DEBUG [numba.cuda.cudadrv.driver:325] call driver api: cuLaunchKernel\n",
      "[2025-11-08 05:00:53,621] DEBUG [numba.cuda.cudadrv.driver:325] call driver api: cuCtxGetCurrent\n",
      "[2025-11-08 05:00:53,622] DEBUG [numba.cuda.cudadrv.driver:325] call driver api: cuCtxGetDevice\n",
      "[2025-11-08 05:00:53,622] DEBUG [numba.cuda.cudadrv.driver:325] call driver api: cuPointerGetAttribute\n",
      "[2025-11-08 05:00:53,623] DEBUG [numba.cuda.cudadrv.driver:325] call driver api: cuCtxGetCurrent\n",
      "[2025-11-08 05:00:53,623] DEBUG [numba.cuda.cudadrv.driver:325] call driver api: cuCtxGetDevice\n",
      "[2025-11-08 05:00:53,623] DEBUG [numba.cuda.cudadrv.driver:325] call driver api: cuPointerGetAttribute\n",
      "[2025-11-08 05:00:53,624] DEBUG [numba.cuda.cudadrv.driver:325] call driver api: cuCtxGetCurrent\n",
      "[2025-11-08 05:00:53,624] DEBUG [numba.cuda.cudadrv.driver:325] call driver api: cuCtxGetDevice\n",
      "[2025-11-08 05:00:53,624] DEBUG [numba.cuda.cudadrv.driver:325] call driver api: cuLaunchKernel\n",
      "[2025-11-08 05:00:53,627] DEBUG [numba.cuda.cudadrv.driver:325] call driver api: cuCtxGetCurrent\n",
      "[2025-11-08 05:00:53,627] DEBUG [numba.cuda.cudadrv.driver:325] call driver api: cuCtxGetDevice\n",
      "[2025-11-08 05:00:53,627] DEBUG [numba.cuda.cudadrv.driver:325] call driver api: cuPointerGetAttribute\n",
      "[2025-11-08 05:00:53,628] DEBUG [numba.cuda.cudadrv.driver:325] call driver api: cuCtxGetCurrent\n",
      "[2025-11-08 05:00:53,628] DEBUG [numba.cuda.cudadrv.driver:325] call driver api: cuCtxGetDevice\n",
      "[2025-11-08 05:00:53,629] DEBUG [numba.cuda.cudadrv.driver:325] call driver api: cuPointerGetAttribute\n",
      "[2025-11-08 05:00:53,629] DEBUG [numba.cuda.cudadrv.driver:325] call driver api: cuCtxGetCurrent\n",
      "[2025-11-08 05:00:53,630] DEBUG [numba.cuda.cudadrv.driver:325] call driver api: cuCtxGetDevice\n",
      "[2025-11-08 05:00:53,630] DEBUG [numba.cuda.cudadrv.driver:325] call driver api: cuLaunchKernel\n",
      "[2025-11-08 05:00:53,633] DEBUG [numba.cuda.cudadrv.driver:325] call driver api: cuCtxGetCurrent\n",
      "[2025-11-08 05:00:53,633] DEBUG [numba.cuda.cudadrv.driver:325] call driver api: cuCtxGetDevice\n",
      "[2025-11-08 05:00:53,634] DEBUG [numba.cuda.cudadrv.driver:325] call driver api: cuPointerGetAttribute\n",
      "[2025-11-08 05:00:53,634] DEBUG [numba.cuda.cudadrv.driver:325] call driver api: cuCtxGetCurrent\n",
      "[2025-11-08 05:00:53,635] DEBUG [numba.cuda.cudadrv.driver:325] call driver api: cuCtxGetDevice\n",
      "[2025-11-08 05:00:53,635] DEBUG [numba.cuda.cudadrv.driver:325] call driver api: cuPointerGetAttribute\n",
      "[2025-11-08 05:00:53,636] DEBUG [numba.cuda.cudadrv.driver:325] call driver api: cuCtxGetCurrent\n",
      "[2025-11-08 05:00:53,636] DEBUG [numba.cuda.cudadrv.driver:325] call driver api: cuCtxGetDevice\n",
      "[2025-11-08 05:00:53,637] DEBUG [numba.cuda.cudadrv.driver:325] call driver api: cuLaunchKernel\n",
      "[2025-11-08 05:00:53,641] DEBUG [numba.cuda.cudadrv.driver:325] call driver api: cuCtxGetCurrent\n",
      "[2025-11-08 05:00:53,641] DEBUG [numba.cuda.cudadrv.driver:325] call driver api: cuCtxGetDevice\n",
      "[2025-11-08 05:00:53,641] DEBUG [numba.cuda.cudadrv.driver:325] call driver api: cuPointerGetAttribute\n",
      "[2025-11-08 05:00:53,642] DEBUG [numba.cuda.cudadrv.driver:325] call driver api: cuCtxGetCurrent\n",
      "[2025-11-08 05:00:53,643] DEBUG [numba.cuda.cudadrv.driver:325] call driver api: cuCtxGetDevice\n",
      "[2025-11-08 05:00:53,643] DEBUG [numba.cuda.cudadrv.driver:325] call driver api: cuPointerGetAttribute\n",
      "[2025-11-08 05:00:53,643] DEBUG [numba.cuda.cudadrv.driver:325] call driver api: cuCtxGetCurrent\n",
      "[2025-11-08 05:00:53,644] DEBUG [numba.cuda.cudadrv.driver:325] call driver api: cuCtxGetDevice\n",
      "[2025-11-08 05:00:53,645] DEBUG [numba.cuda.cudadrv.driver:325] call driver api: cuLaunchKernel\n",
      "[2025-11-08 05:00:53,648] DEBUG [numba.cuda.cudadrv.driver:325] call driver api: cuCtxGetCurrent\n",
      "[2025-11-08 05:00:53,648] DEBUG [numba.cuda.cudadrv.driver:325] call driver api: cuCtxGetDevice\n",
      "[2025-11-08 05:00:53,649] DEBUG [numba.cuda.cudadrv.driver:325] call driver api: cuPointerGetAttribute\n",
      "[2025-11-08 05:00:53,650] DEBUG [numba.cuda.cudadrv.driver:325] call driver api: cuCtxGetCurrent\n",
      "[2025-11-08 05:00:53,650] DEBUG [numba.cuda.cudadrv.driver:325] call driver api: cuCtxGetDevice\n",
      "[2025-11-08 05:00:53,651] DEBUG [numba.cuda.cudadrv.driver:325] call driver api: cuPointerGetAttribute\n",
      "[2025-11-08 05:00:53,651] DEBUG [numba.cuda.cudadrv.driver:325] call driver api: cuCtxGetCurrent\n",
      "[2025-11-08 05:00:53,652] DEBUG [numba.cuda.cudadrv.driver:325] call driver api: cuCtxGetDevice\n",
      "[2025-11-08 05:00:53,653] DEBUG [numba.cuda.cudadrv.driver:325] call driver api: cuLaunchKernel\n",
      "[2025-11-08 05:00:53,658] DEBUG [numba.cuda.cudadrv.driver:325] call driver api: cuCtxGetCurrent\n",
      "[2025-11-08 05:00:53,658] DEBUG [numba.cuda.cudadrv.driver:325] call driver api: cuCtxGetDevice\n",
      "[2025-11-08 05:00:53,659] DEBUG [numba.cuda.cudadrv.driver:325] call driver api: cuPointerGetAttribute\n",
      "[2025-11-08 05:00:53,660] DEBUG [numba.cuda.cudadrv.driver:325] call driver api: cuCtxGetCurrent\n",
      "[2025-11-08 05:00:53,660] DEBUG [numba.cuda.cudadrv.driver:325] call driver api: cuCtxGetDevice\n",
      "[2025-11-08 05:00:53,661] DEBUG [numba.cuda.cudadrv.driver:325] call driver api: cuPointerGetAttribute\n",
      "[2025-11-08 05:00:53,662] DEBUG [numba.cuda.cudadrv.driver:325] call driver api: cuCtxGetCurrent\n",
      "[2025-11-08 05:00:53,662] DEBUG [numba.cuda.cudadrv.driver:325] call driver api: cuCtxGetDevice\n",
      "[2025-11-08 05:00:53,663] DEBUG [numba.cuda.cudadrv.driver:325] call driver api: cuLaunchKernel\n",
      "[2025-11-08 05:00:53,667] DEBUG [numba.cuda.cudadrv.driver:325] call driver api: cuCtxGetCurrent\n",
      "[2025-11-08 05:00:53,668] DEBUG [numba.cuda.cudadrv.driver:325] call driver api: cuCtxGetDevice\n",
      "[2025-11-08 05:00:53,668] DEBUG [numba.cuda.cudadrv.driver:325] call driver api: cuPointerGetAttribute\n",
      "[2025-11-08 05:00:53,670] DEBUG [numba.cuda.cudadrv.driver:325] call driver api: cuCtxGetCurrent\n",
      "[2025-11-08 05:00:53,670] DEBUG [numba.cuda.cudadrv.driver:325] call driver api: cuCtxGetDevice\n",
      "[2025-11-08 05:00:53,671] DEBUG [numba.cuda.cudadrv.driver:325] call driver api: cuPointerGetAttribute\n",
      "[2025-11-08 05:00:53,672] DEBUG [numba.cuda.cudadrv.driver:325] call driver api: cuCtxGetCurrent\n",
      "[2025-11-08 05:00:53,672] DEBUG [numba.cuda.cudadrv.driver:325] call driver api: cuCtxGetDevice\n",
      "[2025-11-08 05:00:53,673] DEBUG [numba.cuda.cudadrv.driver:325] call driver api: cuLaunchKernel\n",
      "[2025-11-08 05:00:53,677] DEBUG [numba.cuda.cudadrv.driver:325] call driver api: cuCtxGetCurrent\n",
      "[2025-11-08 05:00:53,677] DEBUG [numba.cuda.cudadrv.driver:325] call driver api: cuCtxGetDevice\n",
      "[2025-11-08 05:00:53,678] DEBUG [numba.cuda.cudadrv.driver:325] call driver api: cuPointerGetAttribute\n",
      "[2025-11-08 05:00:53,679] DEBUG [numba.cuda.cudadrv.driver:325] call driver api: cuCtxGetCurrent\n",
      "[2025-11-08 05:00:53,680] DEBUG [numba.cuda.cudadrv.driver:325] call driver api: cuCtxGetDevice\n",
      "[2025-11-08 05:00:53,680] DEBUG [numba.cuda.cudadrv.driver:325] call driver api: cuPointerGetAttribute\n",
      "[2025-11-08 05:00:53,681] DEBUG [numba.cuda.cudadrv.driver:325] call driver api: cuCtxGetCurrent\n",
      "[2025-11-08 05:00:53,681] DEBUG [numba.cuda.cudadrv.driver:325] call driver api: cuCtxGetDevice\n",
      "[2025-11-08 05:00:53,682] DEBUG [numba.cuda.cudadrv.driver:325] call driver api: cuLaunchKernel\n",
      "[2025-11-08 05:00:53,686] DEBUG [numba.cuda.cudadrv.driver:325] call driver api: cuCtxGetCurrent\n",
      "[2025-11-08 05:00:53,687] DEBUG [numba.cuda.cudadrv.driver:325] call driver api: cuCtxGetDevice\n",
      "[2025-11-08 05:00:53,687] DEBUG [numba.cuda.cudadrv.driver:325] call driver api: cuPointerGetAttribute\n",
      "[2025-11-08 05:00:53,689] DEBUG [numba.cuda.cudadrv.driver:325] call driver api: cuCtxGetCurrent\n",
      "[2025-11-08 05:00:53,689] DEBUG [numba.cuda.cudadrv.driver:325] call driver api: cuCtxGetDevice\n",
      "[2025-11-08 05:00:53,690] DEBUG [numba.cuda.cudadrv.driver:325] call driver api: cuPointerGetAttribute\n",
      "[2025-11-08 05:00:53,690] DEBUG [numba.cuda.cudadrv.driver:325] call driver api: cuCtxGetCurrent\n",
      "[2025-11-08 05:00:53,691] DEBUG [numba.cuda.cudadrv.driver:325] call driver api: cuCtxGetDevice\n",
      "[2025-11-08 05:00:53,692] DEBUG [numba.cuda.cudadrv.driver:325] call driver api: cuLaunchKernel\n",
      "[2025-11-08 05:00:53,698] DEBUG [numba.cuda.cudadrv.driver:325] call driver api: cuCtxGetCurrent\n",
      "[2025-11-08 05:00:53,699] DEBUG [numba.cuda.cudadrv.driver:325] call driver api: cuCtxGetDevice\n",
      "[2025-11-08 05:00:53,700] DEBUG [numba.cuda.cudadrv.driver:325] call driver api: cuPointerGetAttribute\n",
      "[2025-11-08 05:00:53,701] DEBUG [numba.cuda.cudadrv.driver:325] call driver api: cuCtxGetCurrent\n",
      "[2025-11-08 05:00:53,702] DEBUG [numba.cuda.cudadrv.driver:325] call driver api: cuCtxGetDevice\n",
      "[2025-11-08 05:00:53,702] DEBUG [numba.cuda.cudadrv.driver:325] call driver api: cuPointerGetAttribute\n",
      "[2025-11-08 05:00:53,704] DEBUG [numba.cuda.cudadrv.driver:325] call driver api: cuCtxGetCurrent\n",
      "[2025-11-08 05:00:53,704] DEBUG [numba.cuda.cudadrv.driver:325] call driver api: cuCtxGetDevice\n",
      "[2025-11-08 05:00:53,705] DEBUG [numba.cuda.cudadrv.driver:325] call driver api: cuLaunchKernel\n",
      "[2025-11-08 05:00:53,708] DEBUG [numba.cuda.cudadrv.driver:325] call driver api: cuCtxGetCurrent\n",
      "[2025-11-08 05:00:53,708] DEBUG [numba.cuda.cudadrv.driver:325] call driver api: cuCtxGetDevice\n",
      "[2025-11-08 05:00:53,709] DEBUG [numba.cuda.cudadrv.driver:325] call driver api: cuPointerGetAttribute\n",
      "[2025-11-08 05:00:53,711] DEBUG [numba.cuda.cudadrv.driver:325] call driver api: cuCtxGetCurrent\n",
      "[2025-11-08 05:00:53,711] DEBUG [numba.cuda.cudadrv.driver:325] call driver api: cuCtxGetDevice\n",
      "[2025-11-08 05:00:53,712] DEBUG [numba.cuda.cudadrv.driver:325] call driver api: cuPointerGetAttribute\n",
      "[2025-11-08 05:00:53,713] DEBUG [numba.cuda.cudadrv.driver:325] call driver api: cuCtxGetCurrent\n",
      "[2025-11-08 05:00:53,713] DEBUG [numba.cuda.cudadrv.driver:325] call driver api: cuCtxGetDevice\n",
      "[2025-11-08 05:00:53,714] DEBUG [numba.cuda.cudadrv.driver:325] call driver api: cuLaunchKernel\n",
      "[2025-11-08 05:00:53,718] DEBUG [numba.cuda.cudadrv.driver:325] call driver api: cuCtxGetCurrent\n",
      "[2025-11-08 05:00:53,718] DEBUG [numba.cuda.cudadrv.driver:325] call driver api: cuCtxGetDevice\n",
      "[2025-11-08 05:00:53,719] DEBUG [numba.cuda.cudadrv.driver:325] call driver api: cuPointerGetAttribute\n",
      "[2025-11-08 05:00:53,720] DEBUG [numba.cuda.cudadrv.driver:325] call driver api: cuCtxGetCurrent\n",
      "[2025-11-08 05:00:53,721] DEBUG [numba.cuda.cudadrv.driver:325] call driver api: cuCtxGetDevice\n",
      "[2025-11-08 05:00:53,721] DEBUG [numba.cuda.cudadrv.driver:325] call driver api: cuPointerGetAttribute\n",
      "[2025-11-08 05:00:53,722] DEBUG [numba.cuda.cudadrv.driver:325] call driver api: cuCtxGetCurrent\n",
      "[2025-11-08 05:00:53,723] DEBUG [numba.cuda.cudadrv.driver:325] call driver api: cuCtxGetDevice\n",
      "[2025-11-08 05:00:53,723] DEBUG [numba.cuda.cudadrv.driver:325] call driver api: cuLaunchKernel\n",
      "[2025-11-08 05:00:53,726] DEBUG [numba.cuda.cudadrv.driver:325] call driver api: cuCtxGetCurrent\n",
      "[2025-11-08 05:00:53,726] DEBUG [numba.cuda.cudadrv.driver:325] call driver api: cuCtxGetDevice\n",
      "[2025-11-08 05:00:53,727] DEBUG [numba.cuda.cudadrv.driver:325] call driver api: cuPointerGetAttribute\n",
      "[2025-11-08 05:00:53,728] DEBUG [numba.cuda.cudadrv.driver:325] call driver api: cuCtxGetCurrent\n",
      "[2025-11-08 05:00:53,729] DEBUG [numba.cuda.cudadrv.driver:325] call driver api: cuCtxGetDevice\n",
      "[2025-11-08 05:00:53,729] DEBUG [numba.cuda.cudadrv.driver:325] call driver api: cuPointerGetAttribute\n",
      "[2025-11-08 05:00:53,730] DEBUG [numba.cuda.cudadrv.driver:325] call driver api: cuCtxGetCurrent\n",
      "[2025-11-08 05:00:53,731] DEBUG [numba.cuda.cudadrv.driver:325] call driver api: cuCtxGetDevice\n",
      "[2025-11-08 05:00:53,732] DEBUG [numba.cuda.cudadrv.driver:325] call driver api: cuLaunchKernel\n",
      "[2025-11-08 05:00:53,734] DEBUG [numba.cuda.cudadrv.driver:325] call driver api: cuCtxGetCurrent\n",
      "[2025-11-08 05:00:53,735] DEBUG [numba.cuda.cudadrv.driver:325] call driver api: cuCtxGetDevice\n",
      "[2025-11-08 05:00:53,735] DEBUG [numba.cuda.cudadrv.driver:325] call driver api: cuPointerGetAttribute\n",
      "[2025-11-08 05:00:53,736] DEBUG [numba.cuda.cudadrv.driver:325] call driver api: cuCtxGetCurrent\n",
      "[2025-11-08 05:00:53,737] DEBUG [numba.cuda.cudadrv.driver:325] call driver api: cuCtxGetDevice\n",
      "[2025-11-08 05:00:53,738] DEBUG [numba.cuda.cudadrv.driver:325] call driver api: cuPointerGetAttribute\n",
      "[2025-11-08 05:00:53,739] DEBUG [numba.cuda.cudadrv.driver:325] call driver api: cuCtxGetCurrent\n",
      "[2025-11-08 05:00:53,739] DEBUG [numba.cuda.cudadrv.driver:325] call driver api: cuCtxGetDevice\n",
      "[2025-11-08 05:00:53,740] DEBUG [numba.cuda.cudadrv.driver:325] call driver api: cuLaunchKernel\n",
      "[2025-11-08 05:00:53,742] DEBUG [numba.cuda.cudadrv.driver:325] call driver api: cuCtxGetCurrent\n",
      "[2025-11-08 05:00:53,742] DEBUG [numba.cuda.cudadrv.driver:325] call driver api: cuCtxGetDevice\n",
      "[2025-11-08 05:00:53,743] DEBUG [numba.cuda.cudadrv.driver:325] call driver api: cuPointerGetAttribute\n",
      "[2025-11-08 05:00:53,744] DEBUG [numba.cuda.cudadrv.driver:325] call driver api: cuCtxGetCurrent\n",
      "[2025-11-08 05:00:53,744] DEBUG [numba.cuda.cudadrv.driver:325] call driver api: cuCtxGetDevice\n",
      "[2025-11-08 05:00:53,745] DEBUG [numba.cuda.cudadrv.driver:325] call driver api: cuPointerGetAttribute\n",
      "[2025-11-08 05:00:53,746] DEBUG [numba.cuda.cudadrv.driver:325] call driver api: cuCtxGetCurrent\n",
      "[2025-11-08 05:00:53,746] DEBUG [numba.cuda.cudadrv.driver:325] call driver api: cuCtxGetDevice\n",
      "[2025-11-08 05:00:53,747] DEBUG [numba.cuda.cudadrv.driver:325] call driver api: cuLaunchKernel\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "s_img_hidden_states shape: torch.Size([256, 896])\n",
      "t_img_hs shape: torch.Size([260, 896])\n",
      "s_img_hidden_states shape: torch.Size([256, 896])\n",
      "t_img_hs shape: torch.Size([260, 896])\n",
      "s_img_hidden_states shape: torch.Size([256, 896])\n",
      "t_img_hs shape: torch.Size([260, 896])\n",
      "s_img_hidden_states shape: torch.Size([256, 896])\n",
      "t_img_hs shape: torch.Size([260, 896])\n",
      "s_img_hidden_states shape: torch.Size([256, 896])\n",
      "t_img_hs shape: torch.Size([260, 896])\n",
      "s_img_hidden_states shape: torch.Size([256, 896])\n",
      "t_img_hs shape: torch.Size([260, 896])\n",
      "s_img_hidden_states shape: torch.Size([256, 896])\n",
      "t_img_hs shape: torch.Size([260, 896])\n",
      "s_img_hidden_states shape: torch.Size([256, 896])\n",
      "t_img_hs shape: torch.Size([260, 896])\n",
      "s_img_hidden_states shape: torch.Size([256, 896])\n",
      "t_img_hs shape: torch.Size([260, 896])\n",
      "s_img_hidden_states shape: torch.Size([256, 896])\n",
      "t_img_hs shape: torch.Size([260, 896])\n",
      "s_img_hidden_states shape: torch.Size([256, 896])\n",
      "t_img_hs shape: torch.Size([260, 896])\n",
      "s_img_hidden_states shape: torch.Size([256, 896])\n",
      "t_img_hs shape: torch.Size([260, 896])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'total_loss': tensor(nan, device='cuda:0', grad_fn=<AddBackward0>),\n",
       " 'contrastive_loss': tensor(0., device='cuda:0'),\n",
       " 'rkd_loss': tensor(nan, device='cuda:0', grad_fn=<AddBackward0>),\n",
       " 'simple_kd_loss': tensor(0.0022, device='cuda:0', grad_fn=<DivBackward0>),\n",
       " 'intra_rkd_loss': tensor(0.0345, device='cuda:0', grad_fn=<DivBackward0>),\n",
       " 'cross_modal_kd_loss': tensor(497.8580, device='cuda:0', grad_fn=<AddBackward0>),\n",
       " 'ot_loss': tensor(0., device='cuda:0', grad_fn=<DivBackward0>),\n",
       " 'img_align_loss': tensor(0.3857, device='cuda:0', grad_fn=<DivBackward0>)}"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with torch.autocast(enabled=True, dtype=torch.bfloat16, device_type=\"cuda\"):\n",
    "    loss = criterion.forward(None, None)\n",
    "\n",
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "78130ff7",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"./test/output_t_qry.pkl\", 'rb') as file:\n",
    "    # Use pickle.load() to read the byte stream and deserialize the object\n",
    "    loaded_object = pickle.load(file)\n",
    "    # load to cuda\n",
    "    loaded_object = {k: v.to(\"cuda\") if isinstance(v, torch.Tensor) else v for k, v in loaded_object.items()}\n",
    "    t_qry_reps, t_qry_hidden_states, t_qry_img_feats, t_qry_layers_embeds, t_qry_attention, t_qry_input_data = \\\n",
    "                                                                                loaded_object.values()\n",
    "    t_pos_reps, t_pos_hidden_states, t_pos_img_feats, t_pos_layers_embeds, t_pos_attention, t_pos_input_data = \\\n",
    "                                                                                loaded_object.values()\n",
    "    \n",
    "with open(\"./test/output_s_qry.pkl\", 'rb') as file:\n",
    "    # Use pickle.load() to read the byte stream and deserialize the object\n",
    "    loaded_object = pickle.load(file)\n",
    "    loaded_object = {k: v.to(\"cuda\") if isinstance(v, torch.Tensor) else v for k, v in loaded_object.items()}\n",
    "\n",
    "    s_qry_reps, s_qry_hidden_states, s_qry_img_feats, s_qry_layers_embeds, s_qry_attention, s_qry_input_data = \\\n",
    "                                                                loaded_object.values()\n",
    "    s_pos_reps, s_pos_hidden_states, s_pos_img_feats, s_pos_layers_embeds, s_pos_attention, s_pos_input_data = \\\n",
    "                                                                loaded_object.values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d9159d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pairwise_distance(x):\n",
    "        norm = (x**2).sum(dim=1, keepdim=True)\n",
    "        dist = norm + norm.t() - 2.0 * torch.mm(x, x.t())\n",
    "        return dist\n",
    "    \n",
    "def compute_distance_loss(student_qry, student_pos, teacher_qry, teacher_pos):\n",
    "    \n",
    "    num_student_layers = student_qry.size(0)\n",
    "    num_teacher_layers = teacher_qry.size(0)\n",
    "    scale = num_teacher_layers // num_student_layers\n",
    "\n",
    "    student_repr = torch.cat([student_qry, student_pos], dim=1)\n",
    "    teacher_repr = torch.cat([teacher_qry, teacher_pos], dim=1)[\n",
    "        torch.tensor([i * scale for i in range(num_student_layers)], device=teacher_qry.device)\n",
    "    ]\n",
    "\n",
    "    dist_student = pairwise_distance(student_repr)\n",
    "    dist_teacher = pairwise_distance(teacher_repr)\n",
    "    \n",
    "    mask = torch.triu(torch.ones_like(dist_student), diagonal=1).bool()\n",
    "    dist_student = dist_student[mask]\n",
    "    dist_teacher = dist_teacher[mask]\n",
    "    \n",
    "    mean_td = dist_teacher.mean().detach() + 1e-8\n",
    "    mean_sd = dist_student.mean().detach() + 1e-8\n",
    "    \n",
    "    dist_student = dist_student / mean_sd\n",
    "    dist_teacher = dist_teacher / mean_td\n",
    "    \n",
    "    diff = dist_student - dist_teacher\n",
    "    abs_diff = torch.abs(diff)\n",
    "    quadratic = 0.5 * (abs_diff ** 2)\n",
    "    linear = abs_diff - 0.5\n",
    "    \n",
    "    loss = torch.where(abs_diff < 1.0, quadratic, linear)\n",
    "    loss = loss.mean()\n",
    "    return loss\n",
    "\n",
    "def angle_potentials(x):\n",
    "    x = torch.clamp(x, min=-1e10, max=1e10)\n",
    "\n",
    "    n = x.size(0)\n",
    "    diffs = x.unsqueeze(0) - x.unsqueeze(1)\n",
    "    norms = torch.norm(diffs, dim=-1, keepdim=True) + 1e-8\n",
    "\n",
    "    bfloat16_max_safe = 1e38 \n",
    "    \n",
    "    safe_norms = torch.where(torch.isinf(norms), \n",
    "                             torch.tensor(bfloat16_max_safe, dtype=x.dtype, device=x.device), \n",
    "                             norms)\n",
    "    e = diffs / safe_norms\n",
    "    \n",
    "    cos_angles = torch.einsum('ijd,kjd->ijk', e, e)\n",
    "    return cos_angles\n",
    "\n",
    "def compute_angle_loss(student_qry, student_pos, teacher_qry, teacher_pos):\n",
    "    \n",
    "    num_student_layers = student_qry.size(0)\n",
    "    num_teacher_layers = teacher_qry.size(0)\n",
    "    scale = num_teacher_layers // num_student_layers\n",
    "\n",
    "    student_repr = torch.cat([student_qry, student_pos], dim=1)\n",
    "    teacher_repr = torch.cat([teacher_qry, teacher_pos], dim=1)[\n",
    "        torch.tensor([i * scale for i in range(num_student_layers)], device=teacher_qry.device)\n",
    "    ]\n",
    "\n",
    "    psi_student = angle_potentials(student_repr)\n",
    "    psi_teacher = angle_potentials(teacher_repr)\n",
    "    \n",
    "    n = psi_student.size(0)\n",
    "    mask = torch.ones((n, n, n), dtype=torch.bool, device=psi_student.device)\n",
    "    idx = torch.arange(n, device=psi_student.device)\n",
    "    mask[idx, idx, :] = 0\n",
    "    mask[idx, :, idx] = 0\n",
    "    mask[:, idx, idx] = 0\n",
    "    \n",
    "    psi_teacher = psi_teacher[mask]\n",
    "    psi_student = psi_student[mask]\n",
    "    \n",
    "    diff = psi_student - psi_teacher\n",
    "    abs_diff = torch.abs(diff)\n",
    "    quadratic = 0.5 * (abs_diff ** 2)\n",
    "    linear = abs_diff - 0.5\n",
    "    loss = torch.where(abs_diff < 1.0, quadratic, linear)\n",
    "    loss = loss.mean()\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "c42d8a1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Projector t2s_img created with structure: Sequential(\n",
      "  (0): Linear(in_features=1536, out_features=896, bias=True)\n",
      ")\n",
      "Projector t2s_txt created with structure: Sequential(\n",
      "  (0): Linear(in_features=1536, out_features=896, bias=True)\n",
      ")\n",
      "Projectors set.\n"
     ]
    }
   ],
   "source": [
    "distiller  = Distiller(model_args, training_args, \"cuda\")\n",
    "\n",
    "def compute_ot(s_hidden_states, s_attn, t_hidden_states, t_attn):\n",
    "    \n",
    "    loss = 0.0\n",
    "    num_student_layers = len(s_hidden_states)\n",
    "    num_teacher_layers = len(t_hidden_states)\n",
    "    scale = num_teacher_layers // num_student_layers\n",
    "    start_layer = num_student_layers - 3\n",
    "\n",
    "    for l in range(start_layer, num_student_layers):\n",
    "        s_dist = F.softmax(s_attn[l - 1].mean(dim=1)[:, -1], dim=-1) # (b, n)\n",
    "        t_dist = F.softmax(t_attn[l - 1].mean(dim=1)[:, -1], dim=-1) # (b, m)\n",
    "\n",
    "        s_hidden_state = s_hidden_states[l] # (b, n, emb_dim)\n",
    "        proj_t_hidden_state = distiller.t2s[l - start_layer](t_hidden_states[scale * l]) # (b, m, emb_dim)\n",
    "\n",
    "        for b in range(s_dist.size(0)):\n",
    "            norm_s_hs = torch.norm(s_hidden_state[b], dim=-1, keepdim=True) + 1e-8\n",
    "            norm_t_hs = torch.norm(proj_t_hidden_state[b], dim=-1, keepdim=True) + 1e-8\n",
    "\n",
    "            cost_matrix = torch.cdist(norm_s_hs.unsqueeze(0), \n",
    "                                      norm_t_hs.unsqueeze(0)).squeeze(0)\n",
    "            cost_matrix /= cost_matrix.mean().item()\n",
    "\n",
    "            transport = sinkhorn(s_dist[b], t_dist[b], cost_matrix) \n",
    "            print(transport)\n",
    "            loss += torch.sum(transport * cost_matrix)\n",
    "\n",
    "            print(\"Cost mean:\", cost_matrix.mean().item())\n",
    "            print(\"s_dist sum:\", s_dist[b].sum().item())\n",
    "            print(\"t_dist sum:\", t_dist[b].sum().item())\n",
    "            print(\"Transport mean:\", transport.mean())\n",
    "            print(\"OT cost:\", torch.sum(transport * cost_matrix).item())\n",
    "    return loss / s_dist.size(0), cost_matrix\n",
    "\n",
    "epsilon = 1e-9\n",
    "stopThr = 1e-7\n",
    "sinkhorn_alpha = 0.1\n",
    "\n",
    "def sinkhorn(a, b, cost_matrix, reg=10, num_iters=100, eps=1e-9):\n",
    "    \"\"\"\n",
    "    a: (m,) or (m,1) torch tensor (source weights)\n",
    "    b: (n,) or (n,1) torch tensor (target weights)\n",
    "    cost_matrix: (m, n) torch tensor\n",
    "    reg: regularization (>=0) -- larger reg -> smoother K = exp(-C/reg)\n",
    "    num_iters: number of Sinkhorn iterations\n",
    "    \"\"\"\n",
    "    device = cost_matrix.device\n",
    "    # use float32 for numeric stability\n",
    "    dtype = torch.float32\n",
    "    a = a.detach().to(device=device, dtype=dtype).view(-1, 1)\n",
    "    b = b.detach().to(device=device, dtype=dtype).view(-1, 1)\n",
    "    C = cost_matrix.detach().to(device=device, dtype=dtype)\n",
    "\n",
    "    m, n = C.shape\n",
    "    if m == 0 or n == 0:\n",
    "        return torch.zeros((m, n), device=device, dtype=dtype)\n",
    "\n",
    "    # ensure shapes\n",
    "    if a.shape[0] != m:\n",
    "        a = torch.ones((m, 1), device=device, dtype=dtype) / m\n",
    "    if b.shape[0] != n:\n",
    "        b = torch.ones((n, 1), device=device, dtype=dtype) / n\n",
    "\n",
    "    suma = a.sum()\n",
    "    sumb = b.sum()\n",
    "    if suma <= eps or sumb <= eps:\n",
    "        a = torch.ones((m, 1), device=device, dtype=dtype) / m\n",
    "        b = torch.ones((n, 1), device=device, dtype=dtype) / n\n",
    "    else:\n",
    "        a = a / suma\n",
    "        b = b / sumb\n",
    "\n",
    "    K = torch.exp(-C / (reg + 1e-12))\n",
    "    K = torch.clamp(K, min=1e-10)\n",
    "\n",
    "    u = torch.ones((m, 1), device=device, dtype=dtype)\n",
    "    v = torch.ones((n, 1), device=device, dtype=dtype)\n",
    "\n",
    "    for i in range(num_iters):\n",
    "        u_prev = u.clone()\n",
    "        KTv = (K.t() @ u)  # shape (n,1)\n",
    "        v = b / (KTv + eps)\n",
    "        Kv = (K @ v)       # shape (m,1)\n",
    "        u = a / (Kv + eps)\n",
    "\n",
    "        err = torch.max(torch.abs(u - u_prev))\n",
    "        if err.item() < stopThr:\n",
    "            break\n",
    "\n",
    "    # transport plan\n",
    "    U = torch.diag_embed(u.squeeze())   # (m,m) diag(u)\n",
    "    V = torch.diag_embed(v.squeeze())   # (n,n) diag(v)\n",
    "    P = U @ K @ V                       # (m,n)\n",
    "    return P"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "42b55ea2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[2.1100e-05, 2.1100e-05, 2.1815e-05,  ..., 2.1100e-05, 2.2292e-05,\n",
      "         2.4676e-05],\n",
      "        [1.3292e-05, 1.3232e-05, 1.3828e-05,  ..., 1.3292e-05, 1.4067e-05,\n",
      "         1.5497e-05],\n",
      "        [1.3232e-05, 1.3232e-05, 1.3769e-05,  ..., 1.3232e-05, 1.4007e-05,\n",
      "         1.5497e-05],\n",
      "        ...,\n",
      "        [1.3292e-05, 1.3292e-05, 1.3769e-05,  ..., 1.3292e-05, 1.4007e-05,\n",
      "         1.5497e-05],\n",
      "        [1.3232e-05, 1.3232e-05, 1.3828e-05,  ..., 1.3292e-05, 1.4067e-05,\n",
      "         1.5497e-05],\n",
      "        [1.4186e-05, 1.4126e-05, 1.4663e-05,  ..., 1.4186e-05, 1.4901e-05,\n",
      "         1.6570e-05]], device='cuda:0', dtype=torch.bfloat16)\n",
      "Cost mean: 1.0\n",
      "s_dist sum: 0.9999999403953552\n",
      "t_dist sum: 1.0\n",
      "Transport mean: tensor(1.3113e-05, device='cuda:0', dtype=torch.bfloat16)\n",
      "OT cost: 1.0381078720092773\n",
      "tensor([[2.2411e-05, 2.2411e-05, 2.2173e-05,  ..., 2.2531e-05, 2.3246e-05,\n",
      "         2.6584e-05],\n",
      "        [1.3292e-05, 1.3232e-05, 1.3053e-05,  ..., 1.3292e-05, 1.3709e-05,\n",
      "         1.5616e-05],\n",
      "        [1.3113e-05, 1.3053e-05, 1.2934e-05,  ..., 1.3173e-05, 1.3590e-05,\n",
      "         1.5497e-05],\n",
      "        ...,\n",
      "        [1.3292e-05, 1.3232e-05, 1.3113e-05,  ..., 1.3351e-05, 1.3769e-05,\n",
      "         1.5736e-05],\n",
      "        [1.3292e-05, 1.3232e-05, 1.3113e-05,  ..., 1.3351e-05, 1.3769e-05,\n",
      "         1.5616e-05],\n",
      "        [1.3828e-05, 1.3769e-05, 1.3649e-05,  ..., 1.3888e-05, 1.4305e-05,\n",
      "         1.6332e-05]], device='cuda:0', dtype=torch.bfloat16)\n",
      "Cost mean: 1.0\n",
      "s_dist sum: 0.9999999403953552\n",
      "t_dist sum: 0.9999999403953552\n",
      "Transport mean: tensor(1.3113e-05, device='cuda:0', dtype=torch.bfloat16)\n",
      "OT cost: 1.0412834882736206\n",
      "tensor([[1.8597e-05, 1.8597e-05, 1.8716e-05,  ..., 1.8835e-05, 1.9431e-05,\n",
      "         1.9073e-05],\n",
      "        [1.3232e-05, 1.3292e-05, 1.3411e-05,  ..., 1.3471e-05, 1.3947e-05,\n",
      "         1.3649e-05],\n",
      "        [1.3173e-05, 1.3232e-05, 1.3351e-05,  ..., 1.3411e-05, 1.3888e-05,\n",
      "         1.3590e-05],\n",
      "        ...,\n",
      "        [1.3411e-05, 1.3471e-05, 1.3649e-05,  ..., 1.3649e-05, 1.4126e-05,\n",
      "         1.3828e-05],\n",
      "        [1.3471e-05, 1.3530e-05, 1.3649e-05,  ..., 1.3709e-05, 1.4186e-05,\n",
      "         1.3888e-05],\n",
      "        [1.4782e-05, 1.4842e-05, 1.4961e-05,  ..., 1.5020e-05, 1.5497e-05,\n",
      "         1.5199e-05]], device='cuda:0', dtype=torch.bfloat16)\n",
      "Cost mean: 1.0\n",
      "s_dist sum: 0.9999999403953552\n",
      "t_dist sum: 0.9999999403953552\n",
      "Transport mean: tensor(1.3113e-05, device='cuda:0', dtype=torch.bfloat16)\n",
      "OT cost: 1.0156306028366089\n",
      "tensor([[1.8835e-05, 1.8716e-05, 1.8477e-05,  ..., 1.8597e-05, 1.8835e-05,\n",
      "         1.8954e-05],\n",
      "        [1.3351e-05, 1.3351e-05, 1.3173e-05,  ..., 1.3351e-05, 1.3471e-05,\n",
      "         1.3530e-05],\n",
      "        [1.3292e-05, 1.3232e-05, 1.3113e-05,  ..., 1.3232e-05, 1.3411e-05,\n",
      "         1.3471e-05],\n",
      "        ...,\n",
      "        [1.3530e-05, 1.3530e-05, 1.3351e-05,  ..., 1.3530e-05, 1.3649e-05,\n",
      "         1.3709e-05],\n",
      "        [1.3530e-05, 1.3530e-05, 1.3351e-05,  ..., 1.3530e-05, 1.3649e-05,\n",
      "         1.3709e-05],\n",
      "        [1.4842e-05, 1.4722e-05, 1.4544e-05,  ..., 1.4722e-05, 1.4901e-05,\n",
      "         1.4961e-05]], device='cuda:0', dtype=torch.bfloat16)\n",
      "Cost mean: 1.0\n",
      "s_dist sum: 1.0\n",
      "t_dist sum: 0.9999998807907104\n",
      "Transport mean: tensor(1.3113e-05, device='cuda:0', dtype=torch.bfloat16)\n",
      "OT cost: 1.0148656368255615\n",
      "tensor([[1.3649e-05, 1.3590e-05, 1.3709e-05,  ..., 1.3769e-05, 1.4424e-05,\n",
      "         1.4603e-05],\n",
      "        [1.3471e-05, 1.3411e-05, 1.3530e-05,  ..., 1.3590e-05, 1.4186e-05,\n",
      "         1.4424e-05],\n",
      "        [1.3351e-05, 1.3292e-05, 1.3351e-05,  ..., 1.3471e-05, 1.4007e-05,\n",
      "         1.4305e-05],\n",
      "        ...,\n",
      "        [1.3888e-05, 1.3828e-05, 1.3888e-05,  ..., 1.3947e-05, 1.4544e-05,\n",
      "         1.4782e-05],\n",
      "        [1.4067e-05, 1.4007e-05, 1.4126e-05,  ..., 1.4246e-05, 1.4901e-05,\n",
      "         1.5199e-05],\n",
      "        [1.5974e-05, 1.5855e-05, 1.6093e-05,  ..., 1.6212e-05, 1.6928e-05,\n",
      "         1.7166e-05]], device='cuda:0', dtype=torch.bfloat16)\n",
      "Cost mean: 0.9999999403953552\n",
      "s_dist sum: 1.0\n",
      "t_dist sum: 0.9999999403953552\n",
      "Transport mean: tensor(1.3113e-05, device='cuda:0', dtype=torch.bfloat16)\n",
      "OT cost: 0.9993240833282471\n",
      "tensor([[1.3411e-05, 1.3292e-05, 1.3351e-05,  ..., 1.3590e-05, 1.3709e-05,\n",
      "         1.4365e-05],\n",
      "        [1.3232e-05, 1.3113e-05, 1.3173e-05,  ..., 1.3411e-05, 1.3590e-05,\n",
      "         1.4186e-05],\n",
      "        [1.3232e-05, 1.3113e-05, 1.3173e-05,  ..., 1.3471e-05, 1.3590e-05,\n",
      "         1.4246e-05],\n",
      "        ...,\n",
      "        [1.3769e-05, 1.3649e-05, 1.3709e-05,  ..., 1.3947e-05, 1.4126e-05,\n",
      "         1.4782e-05],\n",
      "        [1.3769e-05, 1.3649e-05, 1.3709e-05,  ..., 1.3947e-05, 1.4126e-05,\n",
      "         1.4842e-05],\n",
      "        [1.6570e-05, 1.6451e-05, 1.6570e-05,  ..., 1.6809e-05, 1.7047e-05,\n",
      "         1.7881e-05]], device='cuda:0', dtype=torch.bfloat16)\n",
      "Cost mean: 1.0\n",
      "s_dist sum: 1.0\n",
      "t_dist sum: 1.0\n",
      "Transport mean: tensor(1.3113e-05, device='cuda:0', dtype=torch.bfloat16)\n",
      "OT cost: 0.9992185831069946\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(tensor(3.0542, device='cuda:0', grad_fn=<DivBackward0>),\n",
       " tensor([[0.7022, 0.7447, 0.9193,  ..., 0.8969, 0.9255, 0.9026],\n",
       "         [0.9866, 1.0291, 1.2037,  ..., 1.1813, 1.2100, 1.1871],\n",
       "         [0.9766, 1.0191, 1.1937,  ..., 1.1713, 1.1999, 1.1770],\n",
       "         ...,\n",
       "         [1.0242, 1.0667, 1.2413,  ..., 1.2189, 1.2476, 1.2247],\n",
       "         [0.7187, 0.7611, 0.9358,  ..., 0.9134, 0.9420, 0.9191],\n",
       "         [1.3639, 1.4064, 1.5810,  ..., 1.5586, 1.5873, 1.5644]],\n",
       "        device='cuda:0', grad_fn=<AsStridedBackward0>))"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with torch.autocast(enabled=True, dtype=torch.bfloat16, device_type=\"cuda\"):\n",
    "    x = compute_ot(s_qry_hidden_states, s_qry_attention,\n",
    "                t_qry_hidden_states, t_qry_attention)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "74869b45",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 12, 278, 278])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s_qry_hidden_states[0].size()\n",
    "t_qry_hidden_states[0].size()\n",
    "s_qry_attention[0].size()\n",
    "t_qry_attention[0].size()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "vlm2vec",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
