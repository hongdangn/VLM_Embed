{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1b50b07f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user2/.conda/envs/vlm2vec/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user2/.conda/envs/vlm2vec/lib/python3.11/site-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'repr' attribute with value False was provided to the `Field()` function, which has no effect in the context it was used. 'repr' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.\n",
      "  warnings.warn(\n",
      "/home/user2/.conda/envs/vlm2vec/lib/python3.11/site-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'frozen' attribute with value True was provided to the `Field()` function, which has no effect in the context it was used. 'frozen' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.\n",
      "  warnings.warn(\n",
      "[2025-11-08 08:01:08,138] DEBUG [git.cmd:1270] Popen(['git', 'version'], cwd=/home/user2/dangnh/VLM_Embed, stdin=None, shell=False, universal_newlines=False)\n",
      "[2025-11-08 08:01:08,147] DEBUG [git.cmd:1270] Popen(['git', 'version'], cwd=/home/user2/dangnh/VLM_Embed, stdin=None, shell=False, universal_newlines=False)\n",
      "/home/user2/.conda/envs/vlm2vec/lib/python3.11/site-packages/timm/models/layers/__init__.py:48: FutureWarning: Importing from timm.models.layers is deprecated, please import via timm.layers\n",
      "  warnings.warn(f\"Importing from {__name__} is deprecated, please import via timm.layers\", FutureWarning)\n",
      "/home/user2/dangnh/VLM_Embed/src/model/vlm_backbone/internvideo2/modeling_internvideo2.py:539: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  @torch.cuda.amp.autocast(enabled=False)\n",
      "[2025-11-08 08:01:08,738] DEBUG [datasets:54] PyTorch version 2.8.0 available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DropoutAddRMSNorm of flash_attn is not installed!!!\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import sys\n",
    "from collections import OrderedDict\n",
    "from contextlib import contextmanager\n",
    "import time\n",
    "\n",
    "from src.arguments import ModelArguments, DataArguments, TrainingArguments\n",
    "from transformers import HfArgumentParser, AutoConfig\n",
    "\n",
    "from src.model.model import MMEBModel\n",
    "from src.data.dataset.mmeb_dataset import EvalDataset\n",
    "from src.data.collator.eval_collator import EvalCollator\n",
    "from torch.utils.data import DataLoader\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import pickle\n",
    "import os\n",
    "from datasets import load_dataset\n",
    "from evaluation.mmeb_baselines.eval_utils import get_pred\n",
    "from src.utils import print_rank\n",
    "from src.model.processor import get_backbone_name, load_processor, COLPALI\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "import shutil "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "361f6af5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2025-11-08 08:01:10,053] DEBUG [urllib3.connectionpool:1049] Starting new HTTPS connection (1): huggingface.co:443\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2025-11-08 08:01:11,967] DEBUG [urllib3.connectionpool:544] https://huggingface.co:443 \"HEAD /apple/FastVLM-0.5B/resolve/main/config.json HTTP/1.1\" 307 0\n",
      "[2025-11-08 08:01:12,200] DEBUG [urllib3.connectionpool:544] https://huggingface.co:443 \"HEAD /api/resolve-cache/models/apple/FastVLM-0.5B/16375720c2d673fa583e57e9876afde27549c7d0/config.json HTTP/1.1\" 200 0\n",
      "[2025-11-08 08:01:12,664] DEBUG [urllib3.connectionpool:544] https://huggingface.co:443 \"HEAD /apple/FastVLM-0.5B/resolve/main/llava_qwen.py HTTP/1.1\" 307 0\n",
      "[2025-11-08 08:01:12,899] DEBUG [urllib3.connectionpool:544] https://huggingface.co:443 \"HEAD /api/resolve-cache/models/apple/FastVLM-0.5B/16375720c2d673fa583e57e9876afde27549c7d0/llava_qwen.py HTTP/1.1\" 200 0\n",
      "/home/user2/.cache/huggingface/modules/transformers_modules/apple/FastVLM-0.5B/16375720c2d673fa583e57e9876afde27549c7d0/llava_qwen.py:1458: UserWarning: Overwriting fastvithd in registry with transformers_modules.apple.FastVLM-0.5B.16375720c2d673fa583e57e9876afde27549c7d0.llava_qwen.fastvithd. This is because the name being registered conflicts with an existing name. Please check if this is not expected.\n",
      "  @register_model\n",
      "[2025-11-08 08:01:13,493] DEBUG [urllib3.connectionpool:544] https://huggingface.co:443 \"HEAD /apple/FastVLM-0.5B/resolve/main/config.json HTTP/1.1\" 307 0\n",
      "[2025-11-08 08:01:13,810] DEBUG [urllib3.connectionpool:544] https://huggingface.co:443 \"HEAD /api/resolve-cache/models/apple/FastVLM-0.5B/16375720c2d673fa583e57e9876afde27549c7d0/config.json HTTP/1.1\" 200 0\n",
      "[2025-11-08 08:01:13,817] INFO [src.utils:12] model_backbone: llava_qwen2\n",
      "[2025-11-08 08:01:13,818] INFO [src.utils:21] Loading processor from: apple/FastVLM-0.5B\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected model type: llava_qwen2\n",
      "Determined model backbone: llava_qwen2\n",
      "Processor load here for LLAVA-QWEN2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2025-11-08 08:01:14,345] DEBUG [urllib3.connectionpool:544] https://huggingface.co:443 \"HEAD /apple/FastVLM-0.5B/resolve/main/tokenizer_config.json HTTP/1.1\" 307 0\n",
      "[2025-11-08 08:01:14,482] DEBUG [urllib3.connectionpool:544] https://huggingface.co:443 \"HEAD /api/resolve-cache/models/apple/FastVLM-0.5B/16375720c2d673fa583e57e9876afde27549c7d0/tokenizer_config.json HTTP/1.1\" 200 0\n",
      "[2025-11-08 08:01:14,862] DEBUG [urllib3.connectionpool:544] https://huggingface.co:443 \"GET /api/models/apple/FastVLM-0.5B/tree/main/additional_chat_templates?recursive=False&expand=False HTTP/1.1\" 404 64\n",
      "[2025-11-08 08:01:15,752] DEBUG [urllib3.connectionpool:544] https://huggingface.co:443 \"HEAD /apple/FastVLM-0.5B/resolve/main/config.json HTTP/1.1\" 307 0\n",
      "[2025-11-08 08:01:15,995] DEBUG [urllib3.connectionpool:544] https://huggingface.co:443 \"HEAD /api/resolve-cache/models/apple/FastVLM-0.5B/16375720c2d673fa583e57e9876afde27549c7d0/config.json HTTP/1.1\" 200 0\n",
      "[2025-11-08 08:01:16,418] DEBUG [urllib3.connectionpool:544] https://huggingface.co:443 \"HEAD /apple/FastVLM-0.5B/resolve/main/llava_qwen.py HTTP/1.1\" 307 0\n",
      "[2025-11-08 08:01:16,722] DEBUG [urllib3.connectionpool:544] https://huggingface.co:443 \"HEAD /api/resolve-cache/models/apple/FastVLM-0.5B/16375720c2d673fa583e57e9876afde27549c7d0/llava_qwen.py HTTP/1.1\" 200 0\n",
      "[2025-11-08 08:01:17,367] DEBUG [urllib3.connectionpool:544] https://huggingface.co:443 \"HEAD /apple/FastVLM-0.5B/resolve/main/config.json HTTP/1.1\" 307 0\n",
      "[2025-11-08 08:01:17,619] DEBUG [urllib3.connectionpool:544] https://huggingface.co:443 \"HEAD /api/resolve-cache/models/apple/FastVLM-0.5B/16375720c2d673fa583e57e9876afde27549c7d0/config.json HTTP/1.1\" 200 0\n",
      "[2025-11-08 08:01:17,626] INFO [src.utils:21] Loading backbone [llava_qwen2] from apple/FastVLM-0.5B\n",
      "`torch_dtype` is deprecated! Use `dtype` instead!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected model type: llava_qwen2\n",
      "Determined model backbone: llava_qwen2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2025-11-08 08:01:18,982] DEBUG [urllib3.connectionpool:544] https://huggingface.co:443 \"HEAD /apple/FastVLM-0.5B/resolve/main/generation_config.json HTTP/1.1\" 307 0\n",
      "[2025-11-08 08:01:19,380] DEBUG [urllib3.connectionpool:544] https://huggingface.co:443 \"HEAD /api/resolve-cache/models/apple/FastVLM-0.5B/16375720c2d673fa583e57e9876afde27549c7d0/generation_config.json HTTP/1.1\" 200 0\n",
      "[2025-11-08 08:01:20,000] DEBUG [urllib3.connectionpool:544] https://huggingface.co:443 \"HEAD /apple/FastVLM-0.5B/resolve/main/custom_generate/generate.py HTTP/1.1\" 404 0\n"
     ]
    }
   ],
   "source": [
    "model_args = ModelArguments(\n",
    "    model_name=\"apple/FastVLM-0.5B\",\n",
    "    # model_name=\"raghavlite/B3_Qwen2_2B\",\n",
    "    pooling=\"eos\",\n",
    "    normalize=True\n",
    ")\n",
    "\n",
    "data_args = DataArguments(\n",
    "    encode_output_path=\"encode_output_path\",\n",
    "    dataset_name=\"TIGER-Lab/MMEB-eval\",\n",
    "    subset_name=[\"WebQA\"],\n",
    "    dataset_split=\"test\",\n",
    "    tgt_prefix_mod=True,\n",
    "    image_dir=\"../VLMEmbed/eval-data\",\n",
    ")\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    per_device_eval_batch_size=2,\n",
    ")\n",
    "\n",
    "os.makedirs(data_args.encode_output_path, exist_ok=True)\n",
    "\n",
    "hf_config = AutoConfig.from_pretrained(model_args.model_name, trust_remote_code=True)\n",
    "if not hasattr(model_args, \"model_backbone\") or not model_args.model_backbone:\n",
    "    model_backbone = get_backbone_name(hf_config=hf_config, model_type=model_args.model_type)\n",
    "    setattr(model_args, 'model_backbone', model_backbone)\n",
    "    setattr(training_args, 'model_backbone', model_backbone)\n",
    "print_rank(f'model_backbone: {model_args.model_backbone}')\n",
    "processor = load_processor(model_args, data_args)\n",
    "model = MMEBModel.build(model_args)\n",
    "model.eval()\n",
    "# model = model.to(training_args.device, dtype=torch.bfloat16)\n",
    "model = model.to(training_args.device)\n",
    "\n",
    "eval_collator = EvalCollator(\n",
    "    data_args=data_args,\n",
    "    model_args=model_args,\n",
    "    processor=processor,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "ab23072b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2025-11-07 10:23:10,162] DEBUG [urllib3.connectionpool:544] https://huggingface.co:443 \"HEAD /dangnguyens1/sft-fastvlm-1e/resolve/main/processor_config.json HTTP/1.1\" 404 0\n",
      "[2025-11-07 10:23:10,910] DEBUG [urllib3.connectionpool:544] https://huggingface.co:443 \"HEAD /dangnguyens1/sft-fastvlm-1e/resolve/main/preprocessor_config.json HTTP/1.1\" 307 0\n",
      "[2025-11-07 10:23:11,261] DEBUG [urllib3.connectionpool:544] https://huggingface.co:443 \"HEAD /api/resolve-cache/models/dangnguyens1/sft-fastvlm-1e/b86615061ab58ce1f1dca77d9f3be9f6a602bcfd/preprocessor_config.json HTTP/1.1\" 200 0\n",
      "[2025-11-07 10:23:11,264] DEBUG [filelock:331] Attempting to acquire lock 139639033796368 on /home/user2/.cache/huggingface/hub/.locks/models--dangnguyens1--sft-fastvlm-1e/ad62479fb0c4e341893be71df94f70e38e8c58a7.lock\n",
      "[2025-11-07 10:23:11,266] DEBUG [filelock:334] Lock 139639033796368 acquired on /home/user2/.cache/huggingface/hub/.locks/models--dangnguyens1--sft-fastvlm-1e/ad62479fb0c4e341893be71df94f70e38e8c58a7.lock\n",
      "[2025-11-07 10:23:11,595] DEBUG [urllib3.connectionpool:544] https://huggingface.co:443 \"GET /api/resolve-cache/models/dangnguyens1/sft-fastvlm-1e/b86615061ab58ce1f1dca77d9f3be9f6a602bcfd/preprocessor_config.json HTTP/1.1\" 200 570\n",
      "[2025-11-07 10:23:11,600] DEBUG [filelock:364] Attempting to release lock 139639033796368 on /home/user2/.cache/huggingface/hub/.locks/models--dangnguyens1--sft-fastvlm-1e/ad62479fb0c4e341893be71df94f70e38e8c58a7.lock\n",
      "[2025-11-07 10:23:11,601] DEBUG [filelock:367] Lock 139639033796368 released on /home/user2/.cache/huggingface/hub/.locks/models--dangnguyens1--sft-fastvlm-1e/ad62479fb0c4e341893be71df94f70e38e8c58a7.lock\n",
      "[2025-11-07 10:23:11,892] DEBUG [urllib3.connectionpool:544] https://huggingface.co:443 \"GET /api/models/dangnguyens1/sft-fastvlm-1e/revision/main HTTP/1.1\" 200 2006\n",
      "Fetching 1 files: 100%|██████████| 1/1 [00:00<00:00, 6700.17it/s]\n",
      "[2025-11-07 10:23:12,204] DEBUG [urllib3.connectionpool:544] https://huggingface.co:443 \"GET /api/models/dangnguyens1/sft-fastvlm-1e/revision/main HTTP/1.1\" 200 2006\n",
      "Fetching 1 files: 100%|██████████| 1/1 [00:00<00:00, 7145.32it/s]\n",
      "The image processor of type `Qwen2VLImageProcessor` is now loaded as a fast processor by default, even if the model checkpoint was saved with a slow processor. This is a breaking change and may produce slightly different outputs. To continue using the slow processor, instantiate this class with `use_fast=False`. Note that this behavior will be extended to all models in a future release.\n",
      "[2025-11-07 10:23:12,509] DEBUG [urllib3.connectionpool:544] https://huggingface.co:443 \"HEAD /dangnguyens1/sft-fastvlm-1e/resolve/main/tokenizer_config.json HTTP/1.1\" 307 0\n",
      "[2025-11-07 10:23:12,837] DEBUG [urllib3.connectionpool:544] https://huggingface.co:443 \"HEAD /api/resolve-cache/models/dangnguyens1/sft-fastvlm-1e/b86615061ab58ce1f1dca77d9f3be9f6a602bcfd/tokenizer_config.json HTTP/1.1\" 200 0\n",
      "[2025-11-07 10:23:12,840] DEBUG [filelock:331] Attempting to acquire lock 139639031588560 on /home/user2/.cache/huggingface/hub/.locks/models--dangnguyens1--sft-fastvlm-1e/8b0c601fb744f4e0d5a385090750f61cc901a47b.lock\n",
      "[2025-11-07 10:23:12,842] DEBUG [filelock:334] Lock 139639031588560 acquired on /home/user2/.cache/huggingface/hub/.locks/models--dangnguyens1--sft-fastvlm-1e/8b0c601fb744f4e0d5a385090750f61cc901a47b.lock\n",
      "[2025-11-07 10:23:13,179] DEBUG [urllib3.connectionpool:544] https://huggingface.co:443 \"GET /api/resolve-cache/models/dangnguyens1/sft-fastvlm-1e/b86615061ab58ce1f1dca77d9f3be9f6a602bcfd/tokenizer_config.json HTTP/1.1\" 200 None\n",
      "[2025-11-07 10:23:13,182] DEBUG [filelock:364] Attempting to release lock 139639031588560 on /home/user2/.cache/huggingface/hub/.locks/models--dangnguyens1--sft-fastvlm-1e/8b0c601fb744f4e0d5a385090750f61cc901a47b.lock\n",
      "[2025-11-07 10:23:13,183] DEBUG [filelock:367] Lock 139639031588560 released on /home/user2/.cache/huggingface/hub/.locks/models--dangnguyens1--sft-fastvlm-1e/8b0c601fb744f4e0d5a385090750f61cc901a47b.lock\n",
      "[2025-11-07 10:23:13,491] DEBUG [urllib3.connectionpool:544] https://huggingface.co:443 \"GET /api/models/dangnguyens1/sft-fastvlm-1e/tree/main/additional_chat_templates?recursive=False&expand=False HTTP/1.1\" 404 64\n",
      "[2025-11-07 10:23:13,788] DEBUG [urllib3.connectionpool:544] https://huggingface.co:443 \"HEAD /dangnguyens1/sft-fastvlm-1e/resolve/main/vocab.json HTTP/1.1\" 307 0\n",
      "[2025-11-07 10:23:14,283] DEBUG [urllib3.connectionpool:544] https://huggingface.co:443 \"HEAD /api/resolve-cache/models/dangnguyens1/sft-fastvlm-1e/b86615061ab58ce1f1dca77d9f3be9f6a602bcfd/vocab.json HTTP/1.1\" 200 0\n",
      "[2025-11-07 10:23:14,286] DEBUG [filelock:331] Attempting to acquire lock 139639031592528 on /home/user2/.cache/huggingface/hub/.locks/models--dangnguyens1--sft-fastvlm-1e/4783fe10ac3adce15ac8f358ef5462739852c569.lock\n",
      "[2025-11-07 10:23:14,288] DEBUG [filelock:334] Lock 139639031592528 acquired on /home/user2/.cache/huggingface/hub/.locks/models--dangnguyens1--sft-fastvlm-1e/4783fe10ac3adce15ac8f358ef5462739852c569.lock\n",
      "[2025-11-07 10:23:14,617] DEBUG [urllib3.connectionpool:544] https://huggingface.co:443 \"GET /api/resolve-cache/models/dangnguyens1/sft-fastvlm-1e/b86615061ab58ce1f1dca77d9f3be9f6a602bcfd/vocab.json HTTP/1.1\" 200 None\n",
      "[2025-11-07 10:23:15,144] DEBUG [filelock:364] Attempting to release lock 139639031592528 on /home/user2/.cache/huggingface/hub/.locks/models--dangnguyens1--sft-fastvlm-1e/4783fe10ac3adce15ac8f358ef5462739852c569.lock\n",
      "[2025-11-07 10:23:15,145] DEBUG [filelock:367] Lock 139639031592528 released on /home/user2/.cache/huggingface/hub/.locks/models--dangnguyens1--sft-fastvlm-1e/4783fe10ac3adce15ac8f358ef5462739852c569.lock\n",
      "[2025-11-07 10:23:15,437] DEBUG [urllib3.connectionpool:544] https://huggingface.co:443 \"HEAD /dangnguyens1/sft-fastvlm-1e/resolve/main/merges.txt HTTP/1.1\" 307 0\n",
      "[2025-11-07 10:23:15,780] DEBUG [urllib3.connectionpool:544] https://huggingface.co:443 \"HEAD /api/resolve-cache/models/dangnguyens1/sft-fastvlm-1e/b86615061ab58ce1f1dca77d9f3be9f6a602bcfd/merges.txt HTTP/1.1\" 200 0\n",
      "[2025-11-07 10:23:15,783] DEBUG [filelock:331] Attempting to acquire lock 139640199668048 on /home/user2/.cache/huggingface/hub/.locks/models--dangnguyens1--sft-fastvlm-1e/31349551d90c7606f325fe0f11bbb8bd5fa0d7c7.lock\n",
      "[2025-11-07 10:23:15,784] DEBUG [filelock:334] Lock 139640199668048 acquired on /home/user2/.cache/huggingface/hub/.locks/models--dangnguyens1--sft-fastvlm-1e/31349551d90c7606f325fe0f11bbb8bd5fa0d7c7.lock\n",
      "[2025-11-07 10:23:16,125] DEBUG [urllib3.connectionpool:544] https://huggingface.co:443 \"GET /api/resolve-cache/models/dangnguyens1/sft-fastvlm-1e/b86615061ab58ce1f1dca77d9f3be9f6a602bcfd/merges.txt HTTP/1.1\" 200 None\n",
      "[2025-11-07 10:23:16,405] DEBUG [filelock:364] Attempting to release lock 139640199668048 on /home/user2/.cache/huggingface/hub/.locks/models--dangnguyens1--sft-fastvlm-1e/31349551d90c7606f325fe0f11bbb8bd5fa0d7c7.lock\n",
      "[2025-11-07 10:23:16,406] DEBUG [filelock:367] Lock 139640199668048 released on /home/user2/.cache/huggingface/hub/.locks/models--dangnguyens1--sft-fastvlm-1e/31349551d90c7606f325fe0f11bbb8bd5fa0d7c7.lock\n",
      "[2025-11-07 10:23:16,698] DEBUG [urllib3.connectionpool:544] https://huggingface.co:443 \"HEAD /dangnguyens1/sft-fastvlm-1e/resolve/main/tokenizer.json HTTP/1.1\" 302 0\n",
      "[2025-11-07 10:23:16,703] DEBUG [filelock:331] Attempting to acquire lock 139640198414032 on /home/user2/.cache/huggingface/hub/.locks/models--dangnguyens1--sft-fastvlm-1e/f9f1b25be0b5a53ffc83ca52290a5ebcf3e45ce4ea9fd378dc6d9091bf111ac2.lock\n",
      "[2025-11-07 10:23:16,704] DEBUG [filelock:334] Lock 139640198414032 acquired on /home/user2/.cache/huggingface/hub/.locks/models--dangnguyens1--sft-fastvlm-1e/f9f1b25be0b5a53ffc83ca52290a5ebcf3e45ce4ea9fd378dc6d9091bf111ac2.lock\n",
      "[2025-11-07 10:23:17,032] DEBUG [urllib3.connectionpool:544] https://huggingface.co:443 \"GET /api/models/dangnguyens1/sft-fastvlm-1e/xet-read-token/b86615061ab58ce1f1dca77d9f3be9f6a602bcfd HTTP/1.1\" 200 417\n",
      "[2025-11-07 10:23:27,390] DEBUG [filelock:364] Attempting to release lock 139640198414032 on /home/user2/.cache/huggingface/hub/.locks/models--dangnguyens1--sft-fastvlm-1e/f9f1b25be0b5a53ffc83ca52290a5ebcf3e45ce4ea9fd378dc6d9091bf111ac2.lock\n",
      "[2025-11-07 10:23:27,391] DEBUG [filelock:367] Lock 139640198414032 released on /home/user2/.cache/huggingface/hub/.locks/models--dangnguyens1--sft-fastvlm-1e/f9f1b25be0b5a53ffc83ca52290a5ebcf3e45ce4ea9fd378dc6d9091bf111ac2.lock\n",
      "[2025-11-07 10:23:27,690] DEBUG [urllib3.connectionpool:544] https://huggingface.co:443 \"HEAD /dangnguyens1/sft-fastvlm-1e/resolve/main/added_tokens.json HTTP/1.1\" 307 0\n",
      "[2025-11-07 10:23:28,183] DEBUG [urllib3.connectionpool:544] https://huggingface.co:443 \"HEAD /api/resolve-cache/models/dangnguyens1/sft-fastvlm-1e/b86615061ab58ce1f1dca77d9f3be9f6a602bcfd/added_tokens.json HTTP/1.1\" 200 0\n",
      "[2025-11-07 10:23:28,186] DEBUG [filelock:331] Attempting to acquire lock 139639042736272 on /home/user2/.cache/huggingface/hub/.locks/models--dangnguyens1--sft-fastvlm-1e/caa81304af029feb531f1fe80a096dc539ea0153.lock\n",
      "[2025-11-07 10:23:28,188] DEBUG [filelock:334] Lock 139639042736272 acquired on /home/user2/.cache/huggingface/hub/.locks/models--dangnguyens1--sft-fastvlm-1e/caa81304af029feb531f1fe80a096dc539ea0153.lock\n",
      "[2025-11-07 10:23:28,522] DEBUG [urllib3.connectionpool:544] https://huggingface.co:443 \"GET /api/resolve-cache/models/dangnguyens1/sft-fastvlm-1e/b86615061ab58ce1f1dca77d9f3be9f6a602bcfd/added_tokens.json HTTP/1.1\" 200 392\n",
      "[2025-11-07 10:23:28,525] DEBUG [filelock:364] Attempting to release lock 139639042736272 on /home/user2/.cache/huggingface/hub/.locks/models--dangnguyens1--sft-fastvlm-1e/caa81304af029feb531f1fe80a096dc539ea0153.lock\n",
      "[2025-11-07 10:23:28,526] DEBUG [filelock:367] Lock 139639042736272 released on /home/user2/.cache/huggingface/hub/.locks/models--dangnguyens1--sft-fastvlm-1e/caa81304af029feb531f1fe80a096dc539ea0153.lock\n",
      "[2025-11-07 10:23:28,843] DEBUG [urllib3.connectionpool:544] https://huggingface.co:443 \"HEAD /dangnguyens1/sft-fastvlm-1e/resolve/main/special_tokens_map.json HTTP/1.1\" 307 0\n",
      "[2025-11-07 10:23:29,181] DEBUG [urllib3.connectionpool:544] https://huggingface.co:443 \"HEAD /api/resolve-cache/models/dangnguyens1/sft-fastvlm-1e/b86615061ab58ce1f1dca77d9f3be9f6a602bcfd/special_tokens_map.json HTTP/1.1\" 200 0\n",
      "[2025-11-07 10:23:29,183] DEBUG [filelock:331] Attempting to acquire lock 139640796850320 on /home/user2/.cache/huggingface/hub/.locks/models--dangnguyens1--sft-fastvlm-1e/ac23c0aaa2434523c494330aeb79c58395378103.lock\n",
      "[2025-11-07 10:23:29,185] DEBUG [filelock:334] Lock 139640796850320 acquired on /home/user2/.cache/huggingface/hub/.locks/models--dangnguyens1--sft-fastvlm-1e/ac23c0aaa2434523c494330aeb79c58395378103.lock\n",
      "[2025-11-07 10:23:29,509] DEBUG [urllib3.connectionpool:544] https://huggingface.co:443 \"GET /api/resolve-cache/models/dangnguyens1/sft-fastvlm-1e/b86615061ab58ce1f1dca77d9f3be9f6a602bcfd/special_tokens_map.json HTTP/1.1\" 200 613\n",
      "[2025-11-07 10:23:29,512] DEBUG [filelock:364] Attempting to release lock 139640796850320 on /home/user2/.cache/huggingface/hub/.locks/models--dangnguyens1--sft-fastvlm-1e/ac23c0aaa2434523c494330aeb79c58395378103.lock\n",
      "[2025-11-07 10:23:29,513] DEBUG [filelock:367] Lock 139640796850320 released on /home/user2/.cache/huggingface/hub/.locks/models--dangnguyens1--sft-fastvlm-1e/ac23c0aaa2434523c494330aeb79c58395378103.lock\n",
      "[2025-11-07 10:23:29,820] DEBUG [urllib3.connectionpool:544] https://huggingface.co:443 \"HEAD /dangnguyens1/sft-fastvlm-1e/resolve/main/chat_template.jinja HTTP/1.1\" 307 0\n",
      "[2025-11-07 10:23:30,158] DEBUG [urllib3.connectionpool:544] https://huggingface.co:443 \"HEAD /api/resolve-cache/models/dangnguyens1/sft-fastvlm-1e/b86615061ab58ce1f1dca77d9f3be9f6a602bcfd/chat_template.jinja HTTP/1.1\" 200 0\n",
      "[2025-11-07 10:23:30,161] DEBUG [filelock:331] Attempting to acquire lock 139639033347280 on /home/user2/.cache/huggingface/hub/.locks/models--dangnguyens1--sft-fastvlm-1e/6c226632394ae7474b0d4b13e15793eac2e21ee9.lock\n",
      "[2025-11-07 10:23:30,163] DEBUG [filelock:334] Lock 139639033347280 acquired on /home/user2/.cache/huggingface/hub/.locks/models--dangnguyens1--sft-fastvlm-1e/6c226632394ae7474b0d4b13e15793eac2e21ee9.lock\n",
      "[2025-11-07 10:23:30,497] DEBUG [urllib3.connectionpool:544] https://huggingface.co:443 \"GET /api/resolve-cache/models/dangnguyens1/sft-fastvlm-1e/b86615061ab58ce1f1dca77d9f3be9f6a602bcfd/chat_template.jinja HTTP/1.1\" 200 None\n",
      "[2025-11-07 10:23:30,500] DEBUG [filelock:364] Attempting to release lock 139639033347280 on /home/user2/.cache/huggingface/hub/.locks/models--dangnguyens1--sft-fastvlm-1e/6c226632394ae7474b0d4b13e15793eac2e21ee9.lock\n",
      "[2025-11-07 10:23:30,501] DEBUG [filelock:367] Lock 139639033347280 released on /home/user2/.cache/huggingface/hub/.locks/models--dangnguyens1--sft-fastvlm-1e/6c226632394ae7474b0d4b13e15793eac2e21ee9.lock\n",
      "[2025-11-07 10:23:31,178] DEBUG [urllib3.connectionpool:544] https://huggingface.co:443 \"GET /api/models/dangnguyens1/sft-fastvlm-1e/revision/main HTTP/1.1\" 200 2006\n",
      "Fetching 1 files: 100%|██████████| 1/1 [00:00<00:00, 6533.18it/s]\n",
      "[2025-11-07 10:23:31,498] DEBUG [urllib3.connectionpool:544] https://huggingface.co:443 \"GET /api/models/dangnguyens1/sft-fastvlm-1e/tree/main/additional_chat_templates?recursive=False&expand=False HTTP/1.1\" 404 64\n",
      "[2025-11-07 10:23:31,797] DEBUG [urllib3.connectionpool:544] https://huggingface.co:443 \"HEAD /dangnguyens1/sft-fastvlm-1e/resolve/main/processor_config.json HTTP/1.1\" 404 0\n",
      "[2025-11-07 10:23:32,102] DEBUG [urllib3.connectionpool:544] https://huggingface.co:443 \"HEAD /dangnguyens1/sft-fastvlm-1e/resolve/main/chat_template.json HTTP/1.1\" 404 0\n",
      "[2025-11-07 10:23:32,423] DEBUG [urllib3.connectionpool:544] https://huggingface.co:443 \"HEAD /dangnguyens1/sft-fastvlm-1e/resolve/main/chat_template.jinja HTTP/1.1\" 307 0\n",
      "[2025-11-07 10:23:32,530] DEBUG [urllib3.connectionpool:544] https://huggingface.co:443 \"HEAD /api/resolve-cache/models/dangnguyens1/sft-fastvlm-1e/b86615061ab58ce1f1dca77d9f3be9f6a602bcfd/chat_template.jinja HTTP/1.1\" 200 0\n",
      "[2025-11-07 10:23:32,865] DEBUG [urllib3.connectionpool:544] https://huggingface.co:443 \"HEAD /dangnguyens1/sft-fastvlm-1e/resolve/main/audio_tokenizer_config.json HTTP/1.1\" 404 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processor loaded from dangnguyens1/sft-fastvlm-1e\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoProcessor\n",
    "\n",
    "repo_id = \"dangnguyens1/sft-fastvlm-1e\" \n",
    "processor = AutoProcessor.from_pretrained(repo_id)\n",
    "\n",
    "print(f\"Processor loaded from {repo_id}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "7458b5cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2025-11-07 10:20:30,781] DEBUG [urllib3.connectionpool:289] Resetting dropped connection: huggingface.co\n",
      "[2025-11-07 10:20:31,273] DEBUG [urllib3.connectionpool:544] https://huggingface.co:443 \"GET /api/whoami-v2 HTTP/1.1\" 200 712\n",
      "[2025-11-07 10:20:32,202] DEBUG [urllib3.connectionpool:544] https://huggingface.co:443 \"HEAD /Qwen/Qwen2-VL-2B-Instruct/resolve/main/config.json HTTP/1.1\" 307 0\n",
      "[2025-11-07 10:20:32,552] DEBUG [urllib3.connectionpool:544] https://huggingface.co:443 \"HEAD /api/resolve-cache/models/Qwen/Qwen2-VL-2B-Instruct/895c3a49bc3fa70a340399125c650a463535e71c/config.json HTTP/1.1\" 200 0\n",
      "[2025-11-07 10:20:32,857] DEBUG [urllib3.connectionpool:544] https://huggingface.co:443 \"HEAD /Qwen/Qwen2-VL-2B-Instruct/resolve/main/config.json HTTP/1.1\" 307 0\n",
      "[2025-11-07 10:20:32,964] DEBUG [urllib3.connectionpool:544] https://huggingface.co:443 \"HEAD /api/resolve-cache/models/Qwen/Qwen2-VL-2B-Instruct/895c3a49bc3fa70a340399125c650a463535e71c/config.json HTTP/1.1\" 200 0\n"
     ]
    }
   ],
   "source": [
    "from huggingface_hub import login\n",
    "token=\"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\"\n",
    "login(token=token)\n",
    "\n",
    "ckpt_dir = \"test-save\"\n",
    "# processor.tokenizer.save_pretrained(ckpt_dir)\n",
    "processor.save_pretrained(ckpt_dir)\n",
    "model.encoder.save_pretrained(ckpt_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "74adfe88",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from huggingface_hub import HfApi, HfFolder, Repository, create_repo\n",
    "\n",
    "def push_to_hub(repo_name=None, token=None, commit_message=\"Upload model\", \n",
    "                local_dir=\"./temp_model\", private=False):\n",
    "    try:\n",
    "        if not repo_name:\n",
    "            raise ValueError(\"must specify a repo name to push to hub\")\n",
    "        \n",
    "        if not os.path.exists(local_dir):\n",
    "            raise ValueError(f\"local_dir {local_dir} does not exist\")\n",
    "        \n",
    "        print_rank(f\"Pushing model to the hub at {repo_name}...\")\n",
    "        api = HfApi()\n",
    "        create_repo(repo_name, token=token, private=private, exist_ok=True)\n",
    "        api.upload_folder(\n",
    "            folder_path=local_dir,\n",
    "            repo_id=repo_name, \n",
    "            token=token, \n",
    "            commit_message=commit_message\n",
    "        )\n",
    "\n",
    "        print_rank(f\"Model has been pushed to the hub at: {repo_name}\")\n",
    "        return True\n",
    "        \n",
    "    except Exception as e:\n",
    "        print_rank(f\"Error pushing to hub: {str(e)}\")\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "fbfda101",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2025-11-07 10:55:20,306] INFO [src.utils:12] Pushing model to the hub at dangnguyens1/sft-fastvlm-kd_final_e...\n",
      "[2025-11-07 10:55:20,310] DEBUG [urllib3.connectionpool:289] Resetting dropped connection: huggingface.co\n",
      "[2025-11-07 10:55:23,132] DEBUG [urllib3.connectionpool:544] https://huggingface.co:443 \"POST /api/repos/create HTTP/1.1\" 200 145\n",
      "[2025-11-07 10:55:23,562] DEBUG [urllib3.connectionpool:544] https://huggingface.co:443 \"POST /api/models/dangnguyens1/sft-fastvlm-kd_final_e/preupload/main HTTP/1.1\" 200 878\n",
      "[2025-11-07 10:55:23,867] DEBUG [urllib3.connectionpool:544] https://huggingface.co:443 \"GET /api/models/dangnguyens1/sft-fastvlm-kd_final_e/revision/main?expand=xetEnabled HTTP/1.1\" 200 95\n",
      "[2025-11-07 10:55:24,162] DEBUG [urllib3.connectionpool:544] https://huggingface.co:443 \"GET /api/models/dangnguyens1/sft-fastvlm-kd_final_e/xet-write-token/main HTTP/1.1\" 200 418\n",
      "Processing Files (2 / 2): 100%|██████████| 20.8MB / 20.8MB,  0.00B/s  \n",
      "New Data Upload: |          |  0.00B /  0.00B,  0.00B/s  \n",
      "[2025-11-07 10:55:33,000] DEBUG [urllib3.connectionpool:544] https://huggingface.co:443 \"POST /api/models/dangnguyens1/sft-fastvlm-kd_final_e/commit/main HTTP/1.1\" 200 208\n",
      "[2025-11-07 10:55:33,002] INFO [src.utils:12] Model has been pushed to the hub at: dangnguyens1/sft-fastvlm-kd_final_e\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "push_to_hub(\n",
    "    repo_name=\"dangnguyens1/sft-fastvlm-kd_final_e\",\n",
    "    token=token,\n",
    "    local_dir=\"test-save\",\n",
    "    \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bf8010bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2025-11-08 08:01:20,780] DEBUG [urllib3.connectionpool:544] https://huggingface.co:443 \"HEAD /datasets/TIGER-Lab/MMEB-eval/resolve/main/README.md HTTP/1.1\" 307 0\n",
      "[2025-11-08 08:01:20,884] DEBUG [urllib3.connectionpool:544] https://huggingface.co:443 \"HEAD /api/resolve-cache/datasets/TIGER-Lab/MMEB-eval/2f069730be515ea60778413777816b53e2d2a697/README.md HTTP/1.1\" 200 0\n",
      "[2025-11-08 08:01:21,276] DEBUG [urllib3.connectionpool:544] https://huggingface.co:443 \"HEAD /datasets/TIGER-Lab/MMEB-eval/resolve/2f069730be515ea60778413777816b53e2d2a697/MMEB-eval.py HTTP/1.1\" 404 0\n",
      "[2025-11-08 08:01:21,282] DEBUG [urllib3.connectionpool:1049] Starting new HTTPS connection (1): s3.amazonaws.com:443\n",
      "[2025-11-08 08:01:22,841] DEBUG [urllib3.connectionpool:544] https://s3.amazonaws.com:443 \"HEAD /datasets.huggingface.co/datasets/datasets/TIGER-Lab/MMEB-eval/TIGER-Lab/MMEB-eval.py HTTP/1.1\" 404 0\n",
      "[2025-11-08 08:01:23,398] DEBUG [urllib3.connectionpool:544] https://huggingface.co:443 \"GET /api/datasets/TIGER-Lab/MMEB-eval/revision/2f069730be515ea60778413777816b53e2d2a697 HTTP/1.1\" 200 18456\n",
      "[2025-11-08 08:01:24,165] DEBUG [urllib3.connectionpool:544] https://huggingface.co:443 \"HEAD /datasets/TIGER-Lab/MMEB-eval/resolve/2f069730be515ea60778413777816b53e2d2a697/.huggingface.yaml HTTP/1.1\" 404 0\n",
      "[2025-11-08 08:01:24,184] DEBUG [urllib3.connectionpool:1049] Starting new HTTPS connection (1): datasets-server.huggingface.co:443\n",
      "[2025-11-08 08:01:29,676] DEBUG [urllib3.connectionpool:544] https://datasets-server.huggingface.co:443 \"GET /info?dataset=TIGER-Lab/MMEB-eval HTTP/1.1\" 200 None\n",
      "[2025-11-08 08:01:30,036] DEBUG [urllib3.connectionpool:544] https://huggingface.co:443 \"GET /api/datasets/TIGER-Lab/MMEB-eval/revision/2f069730be515ea60778413777816b53e2d2a697 HTTP/1.1\" 200 18456\n",
      "[2025-11-08 08:01:30,431] DEBUG [urllib3.connectionpool:544] https://huggingface.co:443 \"GET /api/datasets/TIGER-Lab/MMEB-eval/tree/2f069730be515ea60778413777816b53e2d2a697/A-OKVQA?recursive=True&expand=False HTTP/1.1\" 200 317\n",
      "[2025-11-08 08:01:30,828] DEBUG [urllib3.connectionpool:544] https://huggingface.co:443 \"GET /api/datasets/TIGER-Lab/MMEB-eval/tree/2f069730be515ea60778413777816b53e2d2a697?recursive=False&expand=False HTTP/1.1\" 200 4692\n",
      "[2025-11-08 08:01:31,194] DEBUG [urllib3.connectionpool:544] https://huggingface.co:443 \"HEAD /datasets/TIGER-Lab/MMEB-eval/resolve/2f069730be515ea60778413777816b53e2d2a697/dataset_infos.json HTTP/1.1\" 404 0\n",
      "[2025-11-08 08:01:31,545] DEBUG [urllib3.connectionpool:544] https://huggingface.co:443 \"GET /api/datasets/TIGER-Lab/MMEB-eval/tree/2f069730be515ea60778413777816b53e2d2a697/WebQA?recursive=True&expand=False HTTP/1.1\" 200 315\n",
      "[2025-11-08 08:01:31,550] DEBUG [filelock:331] Attempting to acquire lock 140572338759440 on /home/user2/.cache/huggingface/datasets/_home_user2_.cache_huggingface_datasets_TIGER-Lab___mmeb-eval_WebQA_0.0.0_2f069730be515ea60778413777816b53e2d2a697.lock\n",
      "[2025-11-08 08:01:31,551] DEBUG [filelock:334] Lock 140572338759440 acquired on /home/user2/.cache/huggingface/datasets/_home_user2_.cache_huggingface_datasets_TIGER-Lab___mmeb-eval_WebQA_0.0.0_2f069730be515ea60778413777816b53e2d2a697.lock\n",
      "[2025-11-08 08:01:31,553] DEBUG [fsspec.local:379] open file: /home/user2/.cache/huggingface/datasets/TIGER-Lab___mmeb-eval/WebQA/0.0.0/2f069730be515ea60778413777816b53e2d2a697/dataset_info.json\n",
      "[2025-11-08 08:01:31,555] DEBUG [filelock:364] Attempting to release lock 140572338759440 on /home/user2/.cache/huggingface/datasets/_home_user2_.cache_huggingface_datasets_TIGER-Lab___mmeb-eval_WebQA_0.0.0_2f069730be515ea60778413777816b53e2d2a697.lock\n",
      "[2025-11-08 08:01:31,556] DEBUG [filelock:367] Lock 140572338759440 released on /home/user2/.cache/huggingface/datasets/_home_user2_.cache_huggingface_datasets_TIGER-Lab___mmeb-eval_WebQA_0.0.0_2f069730be515ea60778413777816b53e2d2a697.lock\n",
      "[2025-11-08 08:01:31,585] DEBUG [filelock:331] Attempting to acquire lock 140559273383248 on /home/user2/.cache/huggingface/datasets/TIGER-Lab___mmeb-eval/WebQA/0.0.0/2f069730be515ea60778413777816b53e2d2a697_builder.lock\n",
      "[2025-11-08 08:01:31,587] DEBUG [filelock:334] Lock 140559273383248 acquired on /home/user2/.cache/huggingface/datasets/TIGER-Lab___mmeb-eval/WebQA/0.0.0/2f069730be515ea60778413777816b53e2d2a697_builder.lock\n",
      "[2025-11-08 08:01:31,589] DEBUG [fsspec.local:379] open file: /home/user2/.cache/huggingface/datasets/TIGER-Lab___mmeb-eval/WebQA/0.0.0/2f069730be515ea60778413777816b53e2d2a697/dataset_info.json\n",
      "[2025-11-08 08:01:31,591] DEBUG [filelock:364] Attempting to release lock 140559273383248 on /home/user2/.cache/huggingface/datasets/TIGER-Lab___mmeb-eval/WebQA/0.0.0/2f069730be515ea60778413777816b53e2d2a697_builder.lock\n",
      "[2025-11-08 08:01:31,592] DEBUG [filelock:367] Lock 140559273383248 released on /home/user2/.cache/huggingface/datasets/TIGER-Lab___mmeb-eval/WebQA/0.0.0/2f069730be515ea60778413777816b53e2d2a697_builder.lock\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Not using TGT mod None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2025-11-08 08:01:33,447] DEBUG [urllib3.connectionpool:544] https://huggingface.co:443 \"HEAD /datasets/TIGER-Lab/MMEB-eval/resolve/main/README.md HTTP/1.1\" 307 0\n",
      "[2025-11-08 08:01:33,543] DEBUG [urllib3.connectionpool:544] https://huggingface.co:443 \"HEAD /api/resolve-cache/datasets/TIGER-Lab/MMEB-eval/2f069730be515ea60778413777816b53e2d2a697/README.md HTTP/1.1\" 200 0\n",
      "[2025-11-08 08:01:33,889] DEBUG [urllib3.connectionpool:544] https://huggingface.co:443 \"HEAD /datasets/TIGER-Lab/MMEB-eval/resolve/2f069730be515ea60778413777816b53e2d2a697/MMEB-eval.py HTTP/1.1\" 404 0\n",
      "[2025-11-08 08:01:33,894] DEBUG [urllib3.connectionpool:289] Resetting dropped connection: s3.amazonaws.com\n",
      "[2025-11-08 08:01:34,892] DEBUG [urllib3.connectionpool:544] https://s3.amazonaws.com:443 \"HEAD /datasets.huggingface.co/datasets/datasets/TIGER-Lab/MMEB-eval/TIGER-Lab/MMEB-eval.py HTTP/1.1\" 404 0\n",
      "[2025-11-08 08:01:35,293] DEBUG [urllib3.connectionpool:544] https://huggingface.co:443 \"HEAD /datasets/TIGER-Lab/MMEB-eval/resolve/2f069730be515ea60778413777816b53e2d2a697/.huggingface.yaml HTTP/1.1\" 404 0\n",
      "[2025-11-08 08:01:35,640] DEBUG [urllib3.connectionpool:544] https://datasets-server.huggingface.co:443 \"GET /info?dataset=TIGER-Lab/MMEB-eval HTTP/1.1\" 200 None\n",
      "[2025-11-08 08:01:35,993] DEBUG [urllib3.connectionpool:544] https://huggingface.co:443 \"HEAD /datasets/TIGER-Lab/MMEB-eval/resolve/2f069730be515ea60778413777816b53e2d2a697/dataset_infos.json HTTP/1.1\" 404 0\n",
      "[2025-11-08 08:01:35,998] DEBUG [filelock:331] Attempting to acquire lock 140572338736336 on /home/user2/.cache/huggingface/datasets/_home_user2_.cache_huggingface_datasets_TIGER-Lab___mmeb-eval_WebQA_0.0.0_2f069730be515ea60778413777816b53e2d2a697.lock\n",
      "[2025-11-08 08:01:36,000] DEBUG [filelock:334] Lock 140572338736336 acquired on /home/user2/.cache/huggingface/datasets/_home_user2_.cache_huggingface_datasets_TIGER-Lab___mmeb-eval_WebQA_0.0.0_2f069730be515ea60778413777816b53e2d2a697.lock\n",
      "[2025-11-08 08:01:36,002] DEBUG [fsspec.local:379] open file: /home/user2/.cache/huggingface/datasets/TIGER-Lab___mmeb-eval/WebQA/0.0.0/2f069730be515ea60778413777816b53e2d2a697/dataset_info.json\n",
      "[2025-11-08 08:01:36,003] DEBUG [filelock:364] Attempting to release lock 140572338736336 on /home/user2/.cache/huggingface/datasets/_home_user2_.cache_huggingface_datasets_TIGER-Lab___mmeb-eval_WebQA_0.0.0_2f069730be515ea60778413777816b53e2d2a697.lock\n",
      "[2025-11-08 08:01:36,004] DEBUG [filelock:367] Lock 140572338736336 released on /home/user2/.cache/huggingface/datasets/_home_user2_.cache_huggingface_datasets_TIGER-Lab___mmeb-eval_WebQA_0.0.0_2f069730be515ea60778413777816b53e2d2a697.lock\n",
      "[2025-11-08 08:01:36,008] DEBUG [filelock:331] Attempting to acquire lock 140559273565968 on /home/user2/.cache/huggingface/datasets/TIGER-Lab___mmeb-eval/WebQA/0.0.0/2f069730be515ea60778413777816b53e2d2a697_builder.lock\n",
      "[2025-11-08 08:01:36,010] DEBUG [filelock:334] Lock 140559273565968 acquired on /home/user2/.cache/huggingface/datasets/TIGER-Lab___mmeb-eval/WebQA/0.0.0/2f069730be515ea60778413777816b53e2d2a697_builder.lock\n",
      "[2025-11-08 08:01:36,011] DEBUG [fsspec.local:379] open file: /home/user2/.cache/huggingface/datasets/TIGER-Lab___mmeb-eval/WebQA/0.0.0/2f069730be515ea60778413777816b53e2d2a697/dataset_info.json\n",
      "[2025-11-08 08:01:36,013] DEBUG [filelock:364] Attempting to release lock 140559273565968 on /home/user2/.cache/huggingface/datasets/TIGER-Lab___mmeb-eval/WebQA/0.0.0/2f069730be515ea60778413777816b53e2d2a697_builder.lock\n",
      "[2025-11-08 08:01:36,014] DEBUG [filelock:367] Lock 140559273565968 released on /home/user2/.cache/huggingface/datasets/TIGER-Lab___mmeb-eval/WebQA/0.0.0/2f069730be515ea60778413777816b53e2d2a697_builder.lock\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Not using TGT mod None\n"
     ]
    }
   ],
   "source": [
    "POS_MOD_CLASS_LABEL = \"Represent the class label: \"\n",
    "POS_MOD_IMAGE_CAPTION = \"Represent the image caption: \"\n",
    "POS_MOD_ANSWER = \"Represent the answer: \"\n",
    "\n",
    "POS_MOD_DICT = {\n",
    "                \"ImageNet-1K\": POS_MOD_CLASS_LABEL,\"HatefulMemes\":POS_MOD_CLASS_LABEL,\"SUN397\":POS_MOD_CLASS_LABEL,\"N24News\":POS_MOD_CLASS_LABEL,\"VOC2007\":POS_MOD_CLASS_LABEL, \"Place365\":POS_MOD_CLASS_LABEL,\"ImageNet-A\":POS_MOD_CLASS_LABEL,\"ImageNet-R\":POS_MOD_CLASS_LABEL,\"ObjectNet\":POS_MOD_CLASS_LABEL,\"Country211\":POS_MOD_CLASS_LABEL,\n",
    "                \n",
    "                \"OK-VQA\":POS_MOD_ANSWER, \"A-OKVQA\":POS_MOD_ANSWER, \"DocVQA\":POS_MOD_ANSWER, \"InfographicsVQA\":POS_MOD_ANSWER, \"ChartQA\":POS_MOD_ANSWER, \"Visual7W\":POS_MOD_ANSWER,\"ScienceQA\":POS_MOD_ANSWER, \"GQA\":POS_MOD_ANSWER, \"TextVQA\":POS_MOD_ANSWER, \"VizWiz\":POS_MOD_ANSWER,\n",
    "                \n",
    "                \"MSCOCO_i2t\":POS_MOD_IMAGE_CAPTION, \"VisualNews_i2t\":POS_MOD_IMAGE_CAPTION,\n",
    "                }\n",
    "\n",
    "eval_qry_dataset = EvalDataset(\n",
    "    data_args=data_args,\n",
    "    model_args=model_args,\n",
    "    subset=data_args.subset_name[0],\n",
    "    text_field=\"qry_text\",\n",
    "    img_path_field=\"qry_img_path\",\n",
    ")\n",
    "eval_tgt_dataset = EvalDataset(\n",
    "    data_args=data_args,\n",
    "    model_args=model_args,\n",
    "    subset=data_args.subset_name[0],\n",
    "    text_field=\"tgt_text\",\n",
    "    img_path_field=\"tgt_img_path\",\n",
    "    mod_instruction=POS_MOD_DICT.get(data_args.subset_name[0], None) if data_args.tgt_prefix_mod else None\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1ccfd02c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('<image>\\nFind a Wikipedia image that answers this question: What water-related object is sitting in front of the Torre del Reloj?\\n',\n",
       " None)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_qry_dataset[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d278d46e",
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_qry_loader = DataLoader(\n",
    "    eval_qry_dataset,\n",
    "    batch_size=training_args.per_device_eval_batch_size,\n",
    "    collate_fn=eval_collator,\n",
    "    shuffle=False,\n",
    "    drop_last=False,\n",
    "    num_workers=0,\n",
    ")\n",
    "eval_tgt_loader = DataLoader(\n",
    "    eval_tgt_dataset,\n",
    "    batch_size=training_args.per_device_eval_batch_size,\n",
    "    collate_fn=eval_collator,\n",
    "    shuffle=False,\n",
    "    drop_last=False,\n",
    "    num_workers=0,\n",
    ")\n",
    "\n",
    "def batch_to_device(batch, device):\n",
    "    _batch = {}\n",
    "    for key, value in batch.items():\n",
    "        if isinstance(value, torch.Tensor):\n",
    "            _batch[key] = value.to(device)\n",
    "        else:\n",
    "            _batch[key] = value\n",
    "    return _batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "021f1414",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch.utils.data.dataloader.DataLoader at 0x7fd681919fd0>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_qry_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "567d1e4a",
   "metadata": {},
   "outputs": [
    {
     "ename": "AcceleratorError",
     "evalue": "CUDA error: device-side assert triggered\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAcceleratorError\u001b[39m                          Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.conda/envs/vlm2vec/lib/python3.11/site-packages/IPython/core/formatters.py:770\u001b[39m, in \u001b[36mPlainTextFormatter.__call__\u001b[39m\u001b[34m(self, obj)\u001b[39m\n\u001b[32m    763\u001b[39m stream = StringIO()\n\u001b[32m    764\u001b[39m printer = pretty.RepresentationPrinter(stream, \u001b[38;5;28mself\u001b[39m.verbose,\n\u001b[32m    765\u001b[39m     \u001b[38;5;28mself\u001b[39m.max_width, \u001b[38;5;28mself\u001b[39m.newline,\n\u001b[32m    766\u001b[39m     max_seq_length=\u001b[38;5;28mself\u001b[39m.max_seq_length,\n\u001b[32m    767\u001b[39m     singleton_pprinters=\u001b[38;5;28mself\u001b[39m.singleton_printers,\n\u001b[32m    768\u001b[39m     type_pprinters=\u001b[38;5;28mself\u001b[39m.type_printers,\n\u001b[32m    769\u001b[39m     deferred_pprinters=\u001b[38;5;28mself\u001b[39m.deferred_printers)\n\u001b[32m--> \u001b[39m\u001b[32m770\u001b[39m \u001b[43mprinter\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpretty\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    771\u001b[39m printer.flush()\n\u001b[32m    772\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m stream.getvalue()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.conda/envs/vlm2vec/lib/python3.11/site-packages/IPython/lib/pretty.py:411\u001b[39m, in \u001b[36mRepresentationPrinter.pretty\u001b[39m\u001b[34m(self, obj)\u001b[39m\n\u001b[32m    400\u001b[39m                         \u001b[38;5;28;01mreturn\u001b[39;00m meth(obj, \u001b[38;5;28mself\u001b[39m, cycle)\n\u001b[32m    401\u001b[39m                 \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[32m    402\u001b[39m                     \u001b[38;5;28mcls\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mobject\u001b[39m\n\u001b[32m    403\u001b[39m                     \u001b[38;5;66;03m# check if cls defines __repr__\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    409\u001b[39m                     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mcallable\u001b[39m(_safe_getattr(\u001b[38;5;28mcls\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33m__repr__\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[32m    410\u001b[39m                 ):\n\u001b[32m--> \u001b[39m\u001b[32m411\u001b[39m                     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_repr_pprint\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcycle\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    413\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m _default_pprint(obj, \u001b[38;5;28mself\u001b[39m, cycle)\n\u001b[32m    414\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.conda/envs/vlm2vec/lib/python3.11/site-packages/IPython/lib/pretty.py:786\u001b[39m, in \u001b[36m_repr_pprint\u001b[39m\u001b[34m(obj, p, cycle)\u001b[39m\n\u001b[32m    784\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"A pprint that just redirects to the normal repr function.\"\"\"\u001b[39;00m\n\u001b[32m    785\u001b[39m \u001b[38;5;66;03m# Find newlines and replace them with p.break_()\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m786\u001b[39m output = \u001b[38;5;28;43mrepr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    787\u001b[39m lines = output.splitlines()\n\u001b[32m    788\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m p.group():\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.conda/envs/vlm2vec/lib/python3.11/site-packages/torch/_tensor.py:590\u001b[39m, in \u001b[36mTensor.__repr__\u001b[39m\u001b[34m(self, tensor_contents)\u001b[39m\n\u001b[32m    586\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[32m    587\u001b[39m         Tensor.\u001b[34m__repr__\u001b[39m, (\u001b[38;5;28mself\u001b[39m,), \u001b[38;5;28mself\u001b[39m, tensor_contents=tensor_contents\n\u001b[32m    588\u001b[39m     )\n\u001b[32m    589\u001b[39m \u001b[38;5;66;03m# All strings are unicode in Python 3.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m590\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_tensor_str\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_str\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtensor_contents\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtensor_contents\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.conda/envs/vlm2vec/lib/python3.11/site-packages/torch/_tensor_str.py:726\u001b[39m, in \u001b[36m_str\u001b[39m\u001b[34m(self, tensor_contents)\u001b[39m\n\u001b[32m    724\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m torch.no_grad(), torch.utils._python_dispatch._disable_current_modes():\n\u001b[32m    725\u001b[39m     guard = torch._C._DisableFuncTorch()  \u001b[38;5;66;03m# noqa: F841\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m726\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_str_intern\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtensor_contents\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtensor_contents\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.conda/envs/vlm2vec/lib/python3.11/site-packages/torch/_tensor_str.py:647\u001b[39m, in \u001b[36m_str_intern\u001b[39m\u001b[34m(inp, tensor_contents)\u001b[39m\n\u001b[32m    645\u001b[39m                     tensor_str = _tensor_str(\u001b[38;5;28mself\u001b[39m.to_dense(), indent)\n\u001b[32m    646\u001b[39m                 \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m647\u001b[39m                     tensor_str = \u001b[43m_tensor_str\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindent\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    649\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.layout != torch.strided:\n\u001b[32m    650\u001b[39m     suffixes.append(\u001b[33m\"\u001b[39m\u001b[33mlayout=\u001b[39m\u001b[33m\"\u001b[39m + \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mself\u001b[39m.layout))\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.conda/envs/vlm2vec/lib/python3.11/site-packages/torch/_tensor_str.py:379\u001b[39m, in \u001b[36m_tensor_str\u001b[39m\u001b[34m(self, indent)\u001b[39m\n\u001b[32m    375\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m _tensor_str_with_formatter(\n\u001b[32m    376\u001b[39m         \u001b[38;5;28mself\u001b[39m, indent, summarize, real_formatter, imag_formatter\n\u001b[32m    377\u001b[39m     )\n\u001b[32m    378\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m379\u001b[39m     formatter = \u001b[43m_Formatter\u001b[49m\u001b[43m(\u001b[49m\u001b[43mget_summarized_data\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43msummarize\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m    380\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m _tensor_str_with_formatter(\u001b[38;5;28mself\u001b[39m, indent, summarize, formatter)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.conda/envs/vlm2vec/lib/python3.11/site-packages/torch/_tensor_str.py:142\u001b[39m, in \u001b[36m_Formatter.__init__\u001b[39m\u001b[34m(self, tensor)\u001b[39m\n\u001b[32m    140\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m.floating_dtype:\n\u001b[32m    141\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m value \u001b[38;5;129;01min\u001b[39;00m tensor_view:\n\u001b[32m--> \u001b[39m\u001b[32m142\u001b[39m         value_str = \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mvalue\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    143\u001b[39m         \u001b[38;5;28mself\u001b[39m.max_width = \u001b[38;5;28mmax\u001b[39m(\u001b[38;5;28mself\u001b[39m.max_width, \u001b[38;5;28mlen\u001b[39m(value_str))\n\u001b[32m    145\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.conda/envs/vlm2vec/lib/python3.11/site-packages/torch/_tensor.py:1129\u001b[39m, in \u001b[36mTensor.__format__\u001b[39m\u001b[34m(self, format_spec)\u001b[39m\n\u001b[32m   1125\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(Tensor.\u001b[34m__format__\u001b[39m, (\u001b[38;5;28mself\u001b[39m,), \u001b[38;5;28mself\u001b[39m, format_spec)\n\u001b[32m   1126\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.dim() == \u001b[32m0\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m.is_meta \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;129;01mis\u001b[39;00m Tensor:\n\u001b[32m   1127\u001b[39m     \u001b[38;5;66;03m# Use detach() here to avoid the warning when converting a scalar Tensor that\u001b[39;00m\n\u001b[32m   1128\u001b[39m     \u001b[38;5;66;03m# requires gradients to a python number. It is ok for formatting.\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1129\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdetach\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mitem\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m.\u001b[34m__format__\u001b[39m(format_spec)\n\u001b[32m   1130\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mobject\u001b[39m.\u001b[34m__format__\u001b[39m(\u001b[38;5;28mself\u001b[39m, format_spec)\n",
      "\u001b[31mAcceleratorError\u001b[39m: CUDA error: device-side assert triggered\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n"
     ]
    }
   ],
   "source": [
    "batch['input_ids'].to('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "438338c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/pytorch/aten/src/ATen/native/cuda/IndexKernelUtils.cu:16: vectorized_gather_kernel: block: [30,0,0], thread: [0,0,0] Assertion `ind >=0 && ind < ind_dim_size && \"vectorized gather kernel index out of bounds\"` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/IndexKernelUtils.cu:16: vectorized_gather_kernel: block: [30,0,0], thread: [1,0,0] Assertion `ind >=0 && ind < ind_dim_size && \"vectorized gather kernel index out of bounds\"` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/IndexKernelUtils.cu:16: vectorized_gather_kernel: block: [30,0,0], thread: [2,0,0] Assertion `ind >=0 && ind < ind_dim_size && \"vectorized gather kernel index out of bounds\"` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/IndexKernelUtils.cu:16: vectorized_gather_kernel: block: [30,0,0], thread: [3,0,0] Assertion `ind >=0 && ind < ind_dim_size && \"vectorized gather kernel index out of bounds\"` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/IndexKernelUtils.cu:16: vectorized_gather_kernel: block: [30,0,0], thread: [4,0,0] Assertion `ind >=0 && ind < ind_dim_size && \"vectorized gather kernel index out of bounds\"` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/IndexKernelUtils.cu:16: vectorized_gather_kernel: block: [30,0,0], thread: [5,0,0] Assertion `ind >=0 && ind < ind_dim_size && \"vectorized gather kernel index out of bounds\"` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/IndexKernelUtils.cu:16: vectorized_gather_kernel: block: [30,0,0], thread: [6,0,0] Assertion `ind >=0 && ind < ind_dim_size && \"vectorized gather kernel index out of bounds\"` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/IndexKernelUtils.cu:16: vectorized_gather_kernel: block: [30,0,0], thread: [7,0,0] Assertion `ind >=0 && ind < ind_dim_size && \"vectorized gather kernel index out of bounds\"` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/IndexKernelUtils.cu:16: vectorized_gather_kernel: block: [30,0,0], thread: [8,0,0] Assertion `ind >=0 && ind < ind_dim_size && \"vectorized gather kernel index out of bounds\"` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/IndexKernelUtils.cu:16: vectorized_gather_kernel: block: [30,0,0], thread: [9,0,0] Assertion `ind >=0 && ind < ind_dim_size && \"vectorized gather kernel index out of bounds\"` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/IndexKernelUtils.cu:16: vectorized_gather_kernel: block: [30,0,0], thread: [10,0,0] Assertion `ind >=0 && ind < ind_dim_size && \"vectorized gather kernel index out of bounds\"` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/IndexKernelUtils.cu:16: vectorized_gather_kernel: block: [30,0,0], thread: [11,0,0] Assertion `ind >=0 && ind < ind_dim_size && \"vectorized gather kernel index out of bounds\"` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/IndexKernelUtils.cu:16: vectorized_gather_kernel: block: [30,0,0], thread: [12,0,0] Assertion `ind >=0 && ind < ind_dim_size && \"vectorized gather kernel index out of bounds\"` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/IndexKernelUtils.cu:16: vectorized_gather_kernel: block: [30,0,0], thread: [13,0,0] Assertion `ind >=0 && ind < ind_dim_size && \"vectorized gather kernel index out of bounds\"` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/IndexKernelUtils.cu:16: vectorized_gather_kernel: block: [30,0,0], thread: [14,0,0] Assertion `ind >=0 && ind < ind_dim_size && \"vectorized gather kernel index out of bounds\"` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/IndexKernelUtils.cu:16: vectorized_gather_kernel: block: [30,0,0], thread: [15,0,0] Assertion `ind >=0 && ind < ind_dim_size && \"vectorized gather kernel index out of bounds\"` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/IndexKernelUtils.cu:16: vectorized_gather_kernel: block: [30,0,0], thread: [16,0,0] Assertion `ind >=0 && ind < ind_dim_size && \"vectorized gather kernel index out of bounds\"` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/IndexKernelUtils.cu:16: vectorized_gather_kernel: block: [30,0,0], thread: [17,0,0] Assertion `ind >=0 && ind < ind_dim_size && \"vectorized gather kernel index out of bounds\"` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/IndexKernelUtils.cu:16: vectorized_gather_kernel: block: [30,0,0], thread: [18,0,0] Assertion `ind >=0 && ind < ind_dim_size && \"vectorized gather kernel index out of bounds\"` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/IndexKernelUtils.cu:16: vectorized_gather_kernel: block: [30,0,0], thread: [19,0,0] Assertion `ind >=0 && ind < ind_dim_size && \"vectorized gather kernel index out of bounds\"` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/IndexKernelUtils.cu:16: vectorized_gather_kernel: block: [30,0,0], thread: [20,0,0] Assertion `ind >=0 && ind < ind_dim_size && \"vectorized gather kernel index out of bounds\"` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/IndexKernelUtils.cu:16: vectorized_gather_kernel: block: [30,0,0], thread: [21,0,0] Assertion `ind >=0 && ind < ind_dim_size && \"vectorized gather kernel index out of bounds\"` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/IndexKernelUtils.cu:16: vectorized_gather_kernel: block: [30,0,0], thread: [22,0,0] Assertion `ind >=0 && ind < ind_dim_size && \"vectorized gather kernel index out of bounds\"` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/IndexKernelUtils.cu:16: vectorized_gather_kernel: block: [30,0,0], thread: [23,0,0] Assertion `ind >=0 && ind < ind_dim_size && \"vectorized gather kernel index out of bounds\"` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/IndexKernelUtils.cu:16: vectorized_gather_kernel: block: [30,0,0], thread: [24,0,0] Assertion `ind >=0 && ind < ind_dim_size && \"vectorized gather kernel index out of bounds\"` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/IndexKernelUtils.cu:16: vectorized_gather_kernel: block: [30,0,0], thread: [25,0,0] Assertion `ind >=0 && ind < ind_dim_size && \"vectorized gather kernel index out of bounds\"` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/IndexKernelUtils.cu:16: vectorized_gather_kernel: block: [30,0,0], thread: [26,0,0] Assertion `ind >=0 && ind < ind_dim_size && \"vectorized gather kernel index out of bounds\"` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/IndexKernelUtils.cu:16: vectorized_gather_kernel: block: [30,0,0], thread: [27,0,0] Assertion `ind >=0 && ind < ind_dim_size && \"vectorized gather kernel index out of bounds\"` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/IndexKernelUtils.cu:16: vectorized_gather_kernel: block: [30,0,0], thread: [28,0,0] Assertion `ind >=0 && ind < ind_dim_size && \"vectorized gather kernel index out of bounds\"` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/IndexKernelUtils.cu:16: vectorized_gather_kernel: block: [30,0,0], thread: [29,0,0] Assertion `ind >=0 && ind < ind_dim_size && \"vectorized gather kernel index out of bounds\"` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/IndexKernelUtils.cu:16: vectorized_gather_kernel: block: [30,0,0], thread: [30,0,0] Assertion `ind >=0 && ind < ind_dim_size && \"vectorized gather kernel index out of bounds\"` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/IndexKernelUtils.cu:16: vectorized_gather_kernel: block: [30,0,0], thread: [31,0,0] Assertion `ind >=0 && ind < ind_dim_size && \"vectorized gather kernel index out of bounds\"` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/IndexKernelUtils.cu:16: vectorized_gather_kernel: block: [30,0,0], thread: [64,0,0] Assertion `ind >=0 && ind < ind_dim_size && \"vectorized gather kernel index out of bounds\"` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/IndexKernelUtils.cu:16: vectorized_gather_kernel: block: [30,0,0], thread: [65,0,0] Assertion `ind >=0 && ind < ind_dim_size && \"vectorized gather kernel index out of bounds\"` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/IndexKernelUtils.cu:16: vectorized_gather_kernel: block: [30,0,0], thread: [66,0,0] Assertion `ind >=0 && ind < ind_dim_size && \"vectorized gather kernel index out of bounds\"` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/IndexKernelUtils.cu:16: vectorized_gather_kernel: block: [30,0,0], thread: [67,0,0] Assertion `ind >=0 && ind < ind_dim_size && \"vectorized gather kernel index out of bounds\"` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/IndexKernelUtils.cu:16: vectorized_gather_kernel: block: [30,0,0], thread: [68,0,0] Assertion `ind >=0 && ind < ind_dim_size && \"vectorized gather kernel index out of bounds\"` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/IndexKernelUtils.cu:16: vectorized_gather_kernel: block: [30,0,0], thread: [69,0,0] Assertion `ind >=0 && ind < ind_dim_size && \"vectorized gather kernel index out of bounds\"` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/IndexKernelUtils.cu:16: vectorized_gather_kernel: block: [30,0,0], thread: [70,0,0] Assertion `ind >=0 && ind < ind_dim_size && \"vectorized gather kernel index out of bounds\"` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/IndexKernelUtils.cu:16: vectorized_gather_kernel: block: [30,0,0], thread: [71,0,0] Assertion `ind >=0 && ind < ind_dim_size && \"vectorized gather kernel index out of bounds\"` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/IndexKernelUtils.cu:16: vectorized_gather_kernel: block: [30,0,0], thread: [72,0,0] Assertion `ind >=0 && ind < ind_dim_size && \"vectorized gather kernel index out of bounds\"` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/IndexKernelUtils.cu:16: vectorized_gather_kernel: block: [30,0,0], thread: [73,0,0] Assertion `ind >=0 && ind < ind_dim_size && \"vectorized gather kernel index out of bounds\"` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/IndexKernelUtils.cu:16: vectorized_gather_kernel: block: [30,0,0], thread: [74,0,0] Assertion `ind >=0 && ind < ind_dim_size && \"vectorized gather kernel index out of bounds\"` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/IndexKernelUtils.cu:16: vectorized_gather_kernel: block: [30,0,0], thread: [75,0,0] Assertion `ind >=0 && ind < ind_dim_size && \"vectorized gather kernel index out of bounds\"` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/IndexKernelUtils.cu:16: vectorized_gather_kernel: block: [30,0,0], thread: [76,0,0] Assertion `ind >=0 && ind < ind_dim_size && \"vectorized gather kernel index out of bounds\"` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/IndexKernelUtils.cu:16: vectorized_gather_kernel: block: [30,0,0], thread: [77,0,0] Assertion `ind >=0 && ind < ind_dim_size && \"vectorized gather kernel index out of bounds\"` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/IndexKernelUtils.cu:16: vectorized_gather_kernel: block: [30,0,0], thread: [78,0,0] Assertion `ind >=0 && ind < ind_dim_size && \"vectorized gather kernel index out of bounds\"` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/IndexKernelUtils.cu:16: vectorized_gather_kernel: block: [30,0,0], thread: [79,0,0] Assertion `ind >=0 && ind < ind_dim_size && \"vectorized gather kernel index out of bounds\"` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/IndexKernelUtils.cu:16: vectorized_gather_kernel: block: [30,0,0], thread: [80,0,0] Assertion `ind >=0 && ind < ind_dim_size && \"vectorized gather kernel index out of bounds\"` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/IndexKernelUtils.cu:16: vectorized_gather_kernel: block: [30,0,0], thread: [81,0,0] Assertion `ind >=0 && ind < ind_dim_size && \"vectorized gather kernel index out of bounds\"` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/IndexKernelUtils.cu:16: vectorized_gather_kernel: block: [30,0,0], thread: [82,0,0] Assertion `ind >=0 && ind < ind_dim_size && \"vectorized gather kernel index out of bounds\"` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/IndexKernelUtils.cu:16: vectorized_gather_kernel: block: [30,0,0], thread: [83,0,0] Assertion `ind >=0 && ind < ind_dim_size && \"vectorized gather kernel index out of bounds\"` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/IndexKernelUtils.cu:16: vectorized_gather_kernel: block: [30,0,0], thread: [84,0,0] Assertion `ind >=0 && ind < ind_dim_size && \"vectorized gather kernel index out of bounds\"` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/IndexKernelUtils.cu:16: vectorized_gather_kernel: block: [30,0,0], thread: [85,0,0] Assertion `ind >=0 && ind < ind_dim_size && \"vectorized gather kernel index out of bounds\"` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/IndexKernelUtils.cu:16: vectorized_gather_kernel: block: [30,0,0], thread: [86,0,0] Assertion `ind >=0 && ind < ind_dim_size && \"vectorized gather kernel index out of bounds\"` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/IndexKernelUtils.cu:16: vectorized_gather_kernel: block: [30,0,0], thread: [87,0,0] Assertion `ind >=0 && ind < ind_dim_size && \"vectorized gather kernel index out of bounds\"` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/IndexKernelUtils.cu:16: vectorized_gather_kernel: block: [30,0,0], thread: [88,0,0] Assertion `ind >=0 && ind < ind_dim_size && \"vectorized gather kernel index out of bounds\"` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/IndexKernelUtils.cu:16: vectorized_gather_kernel: block: [30,0,0], thread: [89,0,0] Assertion `ind >=0 && ind < ind_dim_size && \"vectorized gather kernel index out of bounds\"` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/IndexKernelUtils.cu:16: vectorized_gather_kernel: block: [30,0,0], thread: [90,0,0] Assertion `ind >=0 && ind < ind_dim_size && \"vectorized gather kernel index out of bounds\"` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/IndexKernelUtils.cu:16: vectorized_gather_kernel: block: [30,0,0], thread: [91,0,0] Assertion `ind >=0 && ind < ind_dim_size && \"vectorized gather kernel index out of bounds\"` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/IndexKernelUtils.cu:16: vectorized_gather_kernel: block: [30,0,0], thread: [92,0,0] Assertion `ind >=0 && ind < ind_dim_size && \"vectorized gather kernel index out of bounds\"` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/IndexKernelUtils.cu:16: vectorized_gather_kernel: block: [30,0,0], thread: [93,0,0] Assertion `ind >=0 && ind < ind_dim_size && \"vectorized gather kernel index out of bounds\"` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/IndexKernelUtils.cu:16: vectorized_gather_kernel: block: [30,0,0], thread: [94,0,0] Assertion `ind >=0 && ind < ind_dim_size && \"vectorized gather kernel index out of bounds\"` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/IndexKernelUtils.cu:16: vectorized_gather_kernel: block: [30,0,0], thread: [95,0,0] Assertion `ind >=0 && ind < ind_dim_size && \"vectorized gather kernel index out of bounds\"` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/IndexKernelUtils.cu:16: vectorized_gather_kernel: block: [30,0,0], thread: [32,0,0] Assertion `ind >=0 && ind < ind_dim_size && \"vectorized gather kernel index out of bounds\"` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/IndexKernelUtils.cu:16: vectorized_gather_kernel: block: [30,0,0], thread: [33,0,0] Assertion `ind >=0 && ind < ind_dim_size && \"vectorized gather kernel index out of bounds\"` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/IndexKernelUtils.cu:16: vectorized_gather_kernel: block: [30,0,0], thread: [34,0,0] Assertion `ind >=0 && ind < ind_dim_size && \"vectorized gather kernel index out of bounds\"` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/IndexKernelUtils.cu:16: vectorized_gather_kernel: block: [30,0,0], thread: [35,0,0] Assertion `ind >=0 && ind < ind_dim_size && \"vectorized gather kernel index out of bounds\"` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/IndexKernelUtils.cu:16: vectorized_gather_kernel: block: [30,0,0], thread: [36,0,0] Assertion `ind >=0 && ind < ind_dim_size && \"vectorized gather kernel index out of bounds\"` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/IndexKernelUtils.cu:16: vectorized_gather_kernel: block: [30,0,0], thread: [37,0,0] Assertion `ind >=0 && ind < ind_dim_size && \"vectorized gather kernel index out of bounds\"` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/IndexKernelUtils.cu:16: vectorized_gather_kernel: block: [30,0,0], thread: [38,0,0] Assertion `ind >=0 && ind < ind_dim_size && \"vectorized gather kernel index out of bounds\"` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/IndexKernelUtils.cu:16: vectorized_gather_kernel: block: [30,0,0], thread: [39,0,0] Assertion `ind >=0 && ind < ind_dim_size && \"vectorized gather kernel index out of bounds\"` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/IndexKernelUtils.cu:16: vectorized_gather_kernel: block: [30,0,0], thread: [40,0,0] Assertion `ind >=0 && ind < ind_dim_size && \"vectorized gather kernel index out of bounds\"` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/IndexKernelUtils.cu:16: vectorized_gather_kernel: block: [30,0,0], thread: [41,0,0] Assertion `ind >=0 && ind < ind_dim_size && \"vectorized gather kernel index out of bounds\"` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/IndexKernelUtils.cu:16: vectorized_gather_kernel: block: [30,0,0], thread: [42,0,0] Assertion `ind >=0 && ind < ind_dim_size && \"vectorized gather kernel index out of bounds\"` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/IndexKernelUtils.cu:16: vectorized_gather_kernel: block: [30,0,0], thread: [43,0,0] Assertion `ind >=0 && ind < ind_dim_size && \"vectorized gather kernel index out of bounds\"` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/IndexKernelUtils.cu:16: vectorized_gather_kernel: block: [30,0,0], thread: [44,0,0] Assertion `ind >=0 && ind < ind_dim_size && \"vectorized gather kernel index out of bounds\"` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/IndexKernelUtils.cu:16: vectorized_gather_kernel: block: [30,0,0], thread: [45,0,0] Assertion `ind >=0 && ind < ind_dim_size && \"vectorized gather kernel index out of bounds\"` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/IndexKernelUtils.cu:16: vectorized_gather_kernel: block: [30,0,0], thread: [46,0,0] Assertion `ind >=0 && ind < ind_dim_size && \"vectorized gather kernel index out of bounds\"` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/IndexKernelUtils.cu:16: vectorized_gather_kernel: block: [30,0,0], thread: [47,0,0] Assertion `ind >=0 && ind < ind_dim_size && \"vectorized gather kernel index out of bounds\"` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/IndexKernelUtils.cu:16: vectorized_gather_kernel: block: [30,0,0], thread: [48,0,0] Assertion `ind >=0 && ind < ind_dim_size && \"vectorized gather kernel index out of bounds\"` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/IndexKernelUtils.cu:16: vectorized_gather_kernel: block: [30,0,0], thread: [49,0,0] Assertion `ind >=0 && ind < ind_dim_size && \"vectorized gather kernel index out of bounds\"` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/IndexKernelUtils.cu:16: vectorized_gather_kernel: block: [30,0,0], thread: [50,0,0] Assertion `ind >=0 && ind < ind_dim_size && \"vectorized gather kernel index out of bounds\"` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/IndexKernelUtils.cu:16: vectorized_gather_kernel: block: [30,0,0], thread: [51,0,0] Assertion `ind >=0 && ind < ind_dim_size && \"vectorized gather kernel index out of bounds\"` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/IndexKernelUtils.cu:16: vectorized_gather_kernel: block: [30,0,0], thread: [52,0,0] Assertion `ind >=0 && ind < ind_dim_size && \"vectorized gather kernel index out of bounds\"` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/IndexKernelUtils.cu:16: vectorized_gather_kernel: block: [30,0,0], thread: [53,0,0] Assertion `ind >=0 && ind < ind_dim_size && \"vectorized gather kernel index out of bounds\"` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/IndexKernelUtils.cu:16: vectorized_gather_kernel: block: [30,0,0], thread: [54,0,0] Assertion `ind >=0 && ind < ind_dim_size && \"vectorized gather kernel index out of bounds\"` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/IndexKernelUtils.cu:16: vectorized_gather_kernel: block: [30,0,0], thread: [55,0,0] Assertion `ind >=0 && ind < ind_dim_size && \"vectorized gather kernel index out of bounds\"` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/IndexKernelUtils.cu:16: vectorized_gather_kernel: block: [30,0,0], thread: [56,0,0] Assertion `ind >=0 && ind < ind_dim_size && \"vectorized gather kernel index out of bounds\"` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/IndexKernelUtils.cu:16: vectorized_gather_kernel: block: [30,0,0], thread: [57,0,0] Assertion `ind >=0 && ind < ind_dim_size && \"vectorized gather kernel index out of bounds\"` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/IndexKernelUtils.cu:16: vectorized_gather_kernel: block: [30,0,0], thread: [58,0,0] Assertion `ind >=0 && ind < ind_dim_size && \"vectorized gather kernel index out of bounds\"` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/IndexKernelUtils.cu:16: vectorized_gather_kernel: block: [30,0,0], thread: [59,0,0] Assertion `ind >=0 && ind < ind_dim_size && \"vectorized gather kernel index out of bounds\"` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/IndexKernelUtils.cu:16: vectorized_gather_kernel: block: [30,0,0], thread: [60,0,0] Assertion `ind >=0 && ind < ind_dim_size && \"vectorized gather kernel index out of bounds\"` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/IndexKernelUtils.cu:16: vectorized_gather_kernel: block: [30,0,0], thread: [61,0,0] Assertion `ind >=0 && ind < ind_dim_size && \"vectorized gather kernel index out of bounds\"` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/IndexKernelUtils.cu:16: vectorized_gather_kernel: block: [30,0,0], thread: [62,0,0] Assertion `ind >=0 && ind < ind_dim_size && \"vectorized gather kernel index out of bounds\"` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/IndexKernelUtils.cu:16: vectorized_gather_kernel: block: [30,0,0], thread: [63,0,0] Assertion `ind >=0 && ind < ind_dim_size && \"vectorized gather kernel index out of bounds\"` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/IndexKernelUtils.cu:16: vectorized_gather_kernel: block: [30,0,0], thread: [96,0,0] Assertion `ind >=0 && ind < ind_dim_size && \"vectorized gather kernel index out of bounds\"` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/IndexKernelUtils.cu:16: vectorized_gather_kernel: block: [30,0,0], thread: [97,0,0] Assertion `ind >=0 && ind < ind_dim_size && \"vectorized gather kernel index out of bounds\"` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/IndexKernelUtils.cu:16: vectorized_gather_kernel: block: [30,0,0], thread: [98,0,0] Assertion `ind >=0 && ind < ind_dim_size && \"vectorized gather kernel index out of bounds\"` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/IndexKernelUtils.cu:16: vectorized_gather_kernel: block: [30,0,0], thread: [99,0,0] Assertion `ind >=0 && ind < ind_dim_size && \"vectorized gather kernel index out of bounds\"` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/IndexKernelUtils.cu:16: vectorized_gather_kernel: block: [30,0,0], thread: [100,0,0] Assertion `ind >=0 && ind < ind_dim_size && \"vectorized gather kernel index out of bounds\"` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/IndexKernelUtils.cu:16: vectorized_gather_kernel: block: [30,0,0], thread: [101,0,0] Assertion `ind >=0 && ind < ind_dim_size && \"vectorized gather kernel index out of bounds\"` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/IndexKernelUtils.cu:16: vectorized_gather_kernel: block: [30,0,0], thread: [102,0,0] Assertion `ind >=0 && ind < ind_dim_size && \"vectorized gather kernel index out of bounds\"` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/IndexKernelUtils.cu:16: vectorized_gather_kernel: block: [30,0,0], thread: [103,0,0] Assertion `ind >=0 && ind < ind_dim_size && \"vectorized gather kernel index out of bounds\"` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/IndexKernelUtils.cu:16: vectorized_gather_kernel: block: [30,0,0], thread: [104,0,0] Assertion `ind >=0 && ind < ind_dim_size && \"vectorized gather kernel index out of bounds\"` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/IndexKernelUtils.cu:16: vectorized_gather_kernel: block: [30,0,0], thread: [105,0,0] Assertion `ind >=0 && ind < ind_dim_size && \"vectorized gather kernel index out of bounds\"` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/IndexKernelUtils.cu:16: vectorized_gather_kernel: block: [30,0,0], thread: [106,0,0] Assertion `ind >=0 && ind < ind_dim_size && \"vectorized gather kernel index out of bounds\"` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/IndexKernelUtils.cu:16: vectorized_gather_kernel: block: [30,0,0], thread: [107,0,0] Assertion `ind >=0 && ind < ind_dim_size && \"vectorized gather kernel index out of bounds\"` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/IndexKernelUtils.cu:16: vectorized_gather_kernel: block: [30,0,0], thread: [108,0,0] Assertion `ind >=0 && ind < ind_dim_size && \"vectorized gather kernel index out of bounds\"` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/IndexKernelUtils.cu:16: vectorized_gather_kernel: block: [30,0,0], thread: [109,0,0] Assertion `ind >=0 && ind < ind_dim_size && \"vectorized gather kernel index out of bounds\"` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/IndexKernelUtils.cu:16: vectorized_gather_kernel: block: [30,0,0], thread: [110,0,0] Assertion `ind >=0 && ind < ind_dim_size && \"vectorized gather kernel index out of bounds\"` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/IndexKernelUtils.cu:16: vectorized_gather_kernel: block: [30,0,0], thread: [111,0,0] Assertion `ind >=0 && ind < ind_dim_size && \"vectorized gather kernel index out of bounds\"` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/IndexKernelUtils.cu:16: vectorized_gather_kernel: block: [30,0,0], thread: [112,0,0] Assertion `ind >=0 && ind < ind_dim_size && \"vectorized gather kernel index out of bounds\"` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/IndexKernelUtils.cu:16: vectorized_gather_kernel: block: [30,0,0], thread: [113,0,0] Assertion `ind >=0 && ind < ind_dim_size && \"vectorized gather kernel index out of bounds\"` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/IndexKernelUtils.cu:16: vectorized_gather_kernel: block: [30,0,0], thread: [114,0,0] Assertion `ind >=0 && ind < ind_dim_size && \"vectorized gather kernel index out of bounds\"` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/IndexKernelUtils.cu:16: vectorized_gather_kernel: block: [30,0,0], thread: [115,0,0] Assertion `ind >=0 && ind < ind_dim_size && \"vectorized gather kernel index out of bounds\"` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/IndexKernelUtils.cu:16: vectorized_gather_kernel: block: [30,0,0], thread: [116,0,0] Assertion `ind >=0 && ind < ind_dim_size && \"vectorized gather kernel index out of bounds\"` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/IndexKernelUtils.cu:16: vectorized_gather_kernel: block: [30,0,0], thread: [117,0,0] Assertion `ind >=0 && ind < ind_dim_size && \"vectorized gather kernel index out of bounds\"` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/IndexKernelUtils.cu:16: vectorized_gather_kernel: block: [30,0,0], thread: [118,0,0] Assertion `ind >=0 && ind < ind_dim_size && \"vectorized gather kernel index out of bounds\"` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/IndexKernelUtils.cu:16: vectorized_gather_kernel: block: [30,0,0], thread: [119,0,0] Assertion `ind >=0 && ind < ind_dim_size && \"vectorized gather kernel index out of bounds\"` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/IndexKernelUtils.cu:16: vectorized_gather_kernel: block: [30,0,0], thread: [120,0,0] Assertion `ind >=0 && ind < ind_dim_size && \"vectorized gather kernel index out of bounds\"` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/IndexKernelUtils.cu:16: vectorized_gather_kernel: block: [30,0,0], thread: [121,0,0] Assertion `ind >=0 && ind < ind_dim_size && \"vectorized gather kernel index out of bounds\"` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/IndexKernelUtils.cu:16: vectorized_gather_kernel: block: [30,0,0], thread: [122,0,0] Assertion `ind >=0 && ind < ind_dim_size && \"vectorized gather kernel index out of bounds\"` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/IndexKernelUtils.cu:16: vectorized_gather_kernel: block: [30,0,0], thread: [123,0,0] Assertion `ind >=0 && ind < ind_dim_size && \"vectorized gather kernel index out of bounds\"` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/IndexKernelUtils.cu:16: vectorized_gather_kernel: block: [30,0,0], thread: [124,0,0] Assertion `ind >=0 && ind < ind_dim_size && \"vectorized gather kernel index out of bounds\"` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/IndexKernelUtils.cu:16: vectorized_gather_kernel: block: [30,0,0], thread: [125,0,0] Assertion `ind >=0 && ind < ind_dim_size && \"vectorized gather kernel index out of bounds\"` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/IndexKernelUtils.cu:16: vectorized_gather_kernel: block: [30,0,0], thread: [126,0,0] Assertion `ind >=0 && ind < ind_dim_size && \"vectorized gather kernel index out of bounds\"` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/IndexKernelUtils.cu:16: vectorized_gather_kernel: block: [30,0,0], thread: [127,0,0] Assertion `ind >=0 && ind < ind_dim_size && \"vectorized gather kernel index out of bounds\"` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/IndexKernelUtils.cu:16: vectorized_gather_kernel: block: [0,0,0], thread: [96,0,0] Assertion `ind >=0 && ind < ind_dim_size && \"vectorized gather kernel index out of bounds\"` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/IndexKernelUtils.cu:16: vectorized_gather_kernel: block: [0,0,0], thread: [97,0,0] Assertion `ind >=0 && ind < ind_dim_size && \"vectorized gather kernel index out of bounds\"` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/IndexKernelUtils.cu:16: vectorized_gather_kernel: block: [0,0,0], thread: [98,0,0] Assertion `ind >=0 && ind < ind_dim_size && \"vectorized gather kernel index out of bounds\"` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/IndexKernelUtils.cu:16: vectorized_gather_kernel: block: [0,0,0], thread: [99,0,0] Assertion `ind >=0 && ind < ind_dim_size && \"vectorized gather kernel index out of bounds\"` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/IndexKernelUtils.cu:16: vectorized_gather_kernel: block: [0,0,0], thread: [100,0,0] Assertion `ind >=0 && ind < ind_dim_size && \"vectorized gather kernel index out of bounds\"` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/IndexKernelUtils.cu:16: vectorized_gather_kernel: block: [0,0,0], thread: [101,0,0] Assertion `ind >=0 && ind < ind_dim_size && \"vectorized gather kernel index out of bounds\"` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/IndexKernelUtils.cu:16: vectorized_gather_kernel: block: [0,0,0], thread: [102,0,0] Assertion `ind >=0 && ind < ind_dim_size && \"vectorized gather kernel index out of bounds\"` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/IndexKernelUtils.cu:16: vectorized_gather_kernel: block: [0,0,0], thread: [103,0,0] Assertion `ind >=0 && ind < ind_dim_size && \"vectorized gather kernel index out of bounds\"` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/IndexKernelUtils.cu:16: vectorized_gather_kernel: block: [0,0,0], thread: [104,0,0] Assertion `ind >=0 && ind < ind_dim_size && \"vectorized gather kernel index out of bounds\"` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/IndexKernelUtils.cu:16: vectorized_gather_kernel: block: [0,0,0], thread: [105,0,0] Assertion `ind >=0 && ind < ind_dim_size && \"vectorized gather kernel index out of bounds\"` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/IndexKernelUtils.cu:16: vectorized_gather_kernel: block: [0,0,0], thread: [106,0,0] Assertion `ind >=0 && ind < ind_dim_size && \"vectorized gather kernel index out of bounds\"` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/IndexKernelUtils.cu:16: vectorized_gather_kernel: block: [0,0,0], thread: [107,0,0] Assertion `ind >=0 && ind < ind_dim_size && \"vectorized gather kernel index out of bounds\"` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/IndexKernelUtils.cu:16: vectorized_gather_kernel: block: [0,0,0], thread: [108,0,0] Assertion `ind >=0 && ind < ind_dim_size && \"vectorized gather kernel index out of bounds\"` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/IndexKernelUtils.cu:16: vectorized_gather_kernel: block: [0,0,0], thread: [109,0,0] Assertion `ind >=0 && ind < ind_dim_size && \"vectorized gather kernel index out of bounds\"` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/IndexKernelUtils.cu:16: vectorized_gather_kernel: block: [0,0,0], thread: [110,0,0] Assertion `ind >=0 && ind < ind_dim_size && \"vectorized gather kernel index out of bounds\"` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/IndexKernelUtils.cu:16: vectorized_gather_kernel: block: [0,0,0], thread: [111,0,0] Assertion `ind >=0 && ind < ind_dim_size && \"vectorized gather kernel index out of bounds\"` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/IndexKernelUtils.cu:16: vectorized_gather_kernel: block: [0,0,0], thread: [112,0,0] Assertion `ind >=0 && ind < ind_dim_size && \"vectorized gather kernel index out of bounds\"` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/IndexKernelUtils.cu:16: vectorized_gather_kernel: block: [0,0,0], thread: [113,0,0] Assertion `ind >=0 && ind < ind_dim_size && \"vectorized gather kernel index out of bounds\"` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/IndexKernelUtils.cu:16: vectorized_gather_kernel: block: [0,0,0], thread: [114,0,0] Assertion `ind >=0 && ind < ind_dim_size && \"vectorized gather kernel index out of bounds\"` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/IndexKernelUtils.cu:16: vectorized_gather_kernel: block: [0,0,0], thread: [115,0,0] Assertion `ind >=0 && ind < ind_dim_size && \"vectorized gather kernel index out of bounds\"` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/IndexKernelUtils.cu:16: vectorized_gather_kernel: block: [0,0,0], thread: [116,0,0] Assertion `ind >=0 && ind < ind_dim_size && \"vectorized gather kernel index out of bounds\"` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/IndexKernelUtils.cu:16: vectorized_gather_kernel: block: [0,0,0], thread: [117,0,0] Assertion `ind >=0 && ind < ind_dim_size && \"vectorized gather kernel index out of bounds\"` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/IndexKernelUtils.cu:16: vectorized_gather_kernel: block: [0,0,0], thread: [118,0,0] Assertion `ind >=0 && ind < ind_dim_size && \"vectorized gather kernel index out of bounds\"` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/IndexKernelUtils.cu:16: vectorized_gather_kernel: block: [0,0,0], thread: [119,0,0] Assertion `ind >=0 && ind < ind_dim_size && \"vectorized gather kernel index out of bounds\"` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/IndexKernelUtils.cu:16: vectorized_gather_kernel: block: [0,0,0], thread: [120,0,0] Assertion `ind >=0 && ind < ind_dim_size && \"vectorized gather kernel index out of bounds\"` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/IndexKernelUtils.cu:16: vectorized_gather_kernel: block: [0,0,0], thread: [121,0,0] Assertion `ind >=0 && ind < ind_dim_size && \"vectorized gather kernel index out of bounds\"` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/IndexKernelUtils.cu:16: vectorized_gather_kernel: block: [0,0,0], thread: [122,0,0] Assertion `ind >=0 && ind < ind_dim_size && \"vectorized gather kernel index out of bounds\"` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/IndexKernelUtils.cu:16: vectorized_gather_kernel: block: [0,0,0], thread: [123,0,0] Assertion `ind >=0 && ind < ind_dim_size && \"vectorized gather kernel index out of bounds\"` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/IndexKernelUtils.cu:16: vectorized_gather_kernel: block: [0,0,0], thread: [124,0,0] Assertion `ind >=0 && ind < ind_dim_size && \"vectorized gather kernel index out of bounds\"` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/IndexKernelUtils.cu:16: vectorized_gather_kernel: block: [0,0,0], thread: [125,0,0] Assertion `ind >=0 && ind < ind_dim_size && \"vectorized gather kernel index out of bounds\"` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/IndexKernelUtils.cu:16: vectorized_gather_kernel: block: [0,0,0], thread: [126,0,0] Assertion `ind >=0 && ind < ind_dim_size && \"vectorized gather kernel index out of bounds\"` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/IndexKernelUtils.cu:16: vectorized_gather_kernel: block: [0,0,0], thread: [127,0,0] Assertion `ind >=0 && ind < ind_dim_size && \"vectorized gather kernel index out of bounds\"` failed.\n"
     ]
    },
    {
     "ename": "AcceleratorError",
     "evalue": "CUDA error: device-side assert triggered\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAcceleratorError\u001b[39m                          Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[5]\u001b[39m\u001b[32m, line 6\u001b[39m\n\u001b[32m      2\u001b[39m batch = batch_to_device(batch, \u001b[33m\"\u001b[39m\u001b[33mcuda\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m      3\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m torch.autocast(enabled=\u001b[38;5;28;01mTrue\u001b[39;00m, dtype=torch.bfloat16, device_type=\u001b[33m\"\u001b[39m\u001b[33mcuda\u001b[39m\u001b[33m\"\u001b[39m):\n\u001b[32m      4\u001b[39m \u001b[38;5;66;03m# batch[\"pixel_values\"] = batch[\"pixel_values\"].to(torch.bfloat16)\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m6\u001b[39m     pooled_output, hidden_states, image_features, all_layers_embeds, attention_matrix = \u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mencode_input\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/dangnh/VLM_Embed/src/model/model.py:131\u001b[39m, in \u001b[36mMMEBModel.encode_input\u001b[39m\u001b[34m(self, input)\u001b[39m\n\u001b[32m    128\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m pooled_output, image_features, attention_matrix\n\u001b[32m    129\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mmodel_backbone\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;129;01min\u001b[39;00m [LLAVA_QWEN2, QWEN2_VL]:\n\u001b[32m    130\u001b[39m     \u001b[38;5;66;03m# print(\"Encoding input for FastVLM model backbone\")\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m131\u001b[39m     hidden_states = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mencoder\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m    132\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(hidden_states, \u001b[33m'\u001b[39m\u001b[33mbatch_image_embeds\u001b[39m\u001b[33m'\u001b[39m):\n\u001b[32m    133\u001b[39m         image_features = hidden_states.batch_image_embeds\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.conda/envs/vlm2vec/lib/python3.11/site-packages/torch/nn/modules/module.py:1773\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1771\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1772\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1773\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.conda/envs/vlm2vec/lib/python3.11/site-packages/torch/nn/modules/module.py:1784\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1779\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1780\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1781\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1782\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1783\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1784\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1786\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1787\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/dangnh/VLM_Embed/src/model/llava/model/language_model/llava_qwen.py:109\u001b[39m, in \u001b[36mLlavaQwen2ForCausalLM.forward\u001b[39m\u001b[34m(self, input_ids, attention_mask, position_ids, past_key_values, inputs_embeds, labels, use_cache, output_attentions, output_hidden_states, images, image_sizes, return_dict, cache_position)\u001b[39m\n\u001b[32m     88\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m inputs_embeds \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m     89\u001b[39m     \u001b[38;5;66;03m# print(\"Preparing inputs for multimodal forward pass.\")\u001b[39;00m\n\u001b[32m     90\u001b[39m     \u001b[38;5;66;03m# print(f\"Batch size of input_ids: {input_ids.shape[0]}\")\u001b[39;00m\n\u001b[32m     91\u001b[39m     (\n\u001b[32m     92\u001b[39m         input_ids,\n\u001b[32m     93\u001b[39m         position_ids,\n\u001b[32m   (...)\u001b[39m\u001b[32m    106\u001b[39m         image_sizes\n\u001b[32m    107\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m109\u001b[39m output = \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    110\u001b[39m \u001b[43m    \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m=\u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    111\u001b[39m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    112\u001b[39m \u001b[43m    \u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[43m=\u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    113\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    114\u001b[39m \u001b[43m    \u001b[49m\u001b[43minputs_embeds\u001b[49m\u001b[43m=\u001b[49m\u001b[43minputs_embeds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    115\u001b[39m \u001b[43m    \u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    116\u001b[39m \u001b[43m    \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[43m=\u001b[49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    117\u001b[39m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m=\u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    118\u001b[39m \u001b[43m    \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m=\u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    119\u001b[39m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[43m=\u001b[49m\u001b[43mreturn_dict\u001b[49m\n\u001b[32m    120\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    121\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m LlavaQwen2OutputWithPast(\n\u001b[32m    122\u001b[39m     loss=output.loss,\n\u001b[32m    123\u001b[39m     logits=output.logits,\n\u001b[32m   (...)\u001b[39m\u001b[32m    127\u001b[39m     batch_image_embeds=image_features\n\u001b[32m    128\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.conda/envs/vlm2vec/lib/python3.11/site-packages/transformers/utils/generic.py:940\u001b[39m, in \u001b[36mcan_return_tuple.<locals>.wrapper\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m    938\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m return_dict_passed \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    939\u001b[39m     return_dict = return_dict_passed\n\u001b[32m--> \u001b[39m\u001b[32m940\u001b[39m output = \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    941\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m return_dict \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(output, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[32m    942\u001b[39m     output = output.to_tuple()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/dangnh/VLM_Embed/src/model/llava/model/language_model/modeling_qwen2.py:449\u001b[39m, in \u001b[36mQwen2ForCausalLM.forward\u001b[39m\u001b[34m(self, input_ids, attention_mask, position_ids, past_key_values, inputs_embeds, labels, use_cache, cache_position, logits_to_keep, **kwargs)\u001b[39m\n\u001b[32m    417\u001b[39m \u001b[38;5;129m@can_return_tuple\u001b[39m\n\u001b[32m    418\u001b[39m \u001b[38;5;129m@auto_docstring\u001b[39m\n\u001b[32m    419\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\n\u001b[32m   (...)\u001b[39m\u001b[32m    430\u001b[39m     **kwargs: Unpack[TransformersKwargs],\n\u001b[32m    431\u001b[39m ) -> CausalLMOutputWithPast:\n\u001b[32m    432\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33mr\u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    433\u001b[39m \u001b[33;03m    Example:\u001b[39;00m\n\u001b[32m    434\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m    447\u001b[39m \u001b[33;03m    \"Hey, are you conscious? Can you talk to me?\\nI'm not conscious, but I can talk to you.\"\u001b[39;00m\n\u001b[32m    448\u001b[39m \u001b[33;03m    ```\"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m449\u001b[39m     outputs: BaseModelOutputWithPast = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    450\u001b[39m \u001b[43m        \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m=\u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    451\u001b[39m \u001b[43m        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    452\u001b[39m \u001b[43m        \u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[43m=\u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    453\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    454\u001b[39m \u001b[43m        \u001b[49m\u001b[43minputs_embeds\u001b[49m\u001b[43m=\u001b[49m\u001b[43minputs_embeds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    455\u001b[39m \u001b[43m        \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[43m=\u001b[49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    456\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcache_position\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcache_position\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    457\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    458\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    460\u001b[39m     hidden_states = outputs.last_hidden_state\n\u001b[32m    461\u001b[39m     \u001b[38;5;66;03m# Only compute necessary logits, and do not upcast them to float if we are not computing the loss\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.conda/envs/vlm2vec/lib/python3.11/site-packages/torch/nn/modules/module.py:1773\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1771\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1772\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1773\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.conda/envs/vlm2vec/lib/python3.11/site-packages/torch/nn/modules/module.py:1784\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1779\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1780\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1781\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1782\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1783\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1784\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1786\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1787\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.conda/envs/vlm2vec/lib/python3.11/site-packages/transformers/utils/generic.py:1064\u001b[39m, in \u001b[36mcheck_model_inputs.<locals>.wrapper\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1061\u001b[39m                 module.forward = make_capture_wrapper(module, original_forward, key, specs.index)\n\u001b[32m   1062\u001b[39m                 monkey_patched_layers.append((module, original_forward))\n\u001b[32m-> \u001b[39m\u001b[32m1064\u001b[39m outputs = \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1065\u001b[39m \u001b[38;5;66;03m# Restore original forward methods\u001b[39;00m\n\u001b[32m   1066\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m module, original_forward \u001b[38;5;129;01min\u001b[39;00m monkey_patched_layers:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/dangnh/VLM_Embed/src/model/llava/model/language_model/modeling_qwen2.py:352\u001b[39m, in \u001b[36mQwen2Model.forward\u001b[39m\u001b[34m(self, input_ids, attention_mask, position_ids, past_key_values, inputs_embeds, use_cache, cache_position, **kwargs)\u001b[39m\n\u001b[32m    350\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m cache_position \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    351\u001b[39m     past_seen_tokens = past_key_values.get_seq_length() \u001b[38;5;28;01mif\u001b[39;00m past_key_values \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[32m0\u001b[39m\n\u001b[32m--> \u001b[39m\u001b[32m352\u001b[39m     cache_position = \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43marange\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    353\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpast_seen_tokens\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpast_seen_tokens\u001b[49m\u001b[43m \u001b[49m\u001b[43m+\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs_embeds\u001b[49m\u001b[43m.\u001b[49m\u001b[43mshape\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m=\u001b[49m\u001b[43minputs_embeds\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdevice\u001b[49m\n\u001b[32m    354\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    356\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m position_ids \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    357\u001b[39m     position_ids = cache_position.unsqueeze(\u001b[32m0\u001b[39m)\n",
      "\u001b[31mAcceleratorError\u001b[39m: CUDA error: device-side assert triggered\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n"
     ]
    }
   ],
   "source": [
    "for batch in eval_qry_loader:\n",
    "    batch = batch_to_device(batch, \"cuda\")\n",
    "    with torch.autocast(enabled=True, dtype=torch.bfloat16, device_type=\"cuda\"):\n",
    "    # batch[\"pixel_values\"] = batch[\"pixel_values\"].to(torch.bfloat16)\n",
    "    \n",
    "        pooled_output, hidden_states, image_features, all_layers_embeds, attention_matrix = model.encode_input(batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "89c123ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(\"test\", \"output_t_qry.pkl\"), \"wb\") as f:\n",
    "    pickle.dump({\n",
    "        \"pooled_output\": pooled_output,\n",
    "        \"hidden_states\": hidden_states,\n",
    "        \"image_features\": image_features,\n",
    "        \"all_layers_embeds\": all_layers_embeds,\n",
    "        \"attention_matrix\": attention_matrix,\n",
    "        \"input_data\": batch,\n",
    "    }, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d31685f2",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'os' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(\u001b[43mos\u001b[49m.path.join(\u001b[33m\"\u001b[39m\u001b[33mtest\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33moutput_s_qry.pkl\u001b[39m\u001b[33m\"\u001b[39m), \u001b[33m\"\u001b[39m\u001b[33mrb\u001b[39m\u001b[33m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[32m      2\u001b[39m     x = pickle.load(f)\n",
      "\u001b[31mNameError\u001b[39m: name 'os' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "with open(os.path.join(\"test\", \"output_s_qry.pkl\"), \"rb\") as f:\n",
    "    x = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2e79ac91",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(\"test\", \"output_t_qry.pkl\"), \"rb\") as f:\n",
    "    y = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c0ac4f99",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 12, 278, 278])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y['attention_matrix'][0].size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "891c8f26",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(x['image_features'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f58f5f7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(\"test\", \"output_s_qry.pkl\"), \"wb\") as f:\n",
    "    pickle.dump({\n",
    "        \"pooled_output\": pooled_output,\n",
    "        \"hidden_states\": hidden_states,\n",
    "        \"image_features\": image_features,\n",
    "        \"all_layers_embeds\": all_layers_embeds,\n",
    "        \"attention_matrix\": attention_matrix,\n",
    "        \"input_data\": batch,\n",
    "    }, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8d8e41ae",
   "metadata": {},
   "outputs": [
    {
     "ename": "AcceleratorError",
     "evalue": "CUDA error: device-side assert triggered\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAcceleratorError\u001b[39m                          Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[9]\u001b[39m\u001b[32m, line 12\u001b[39m\n\u001b[32m      9\u001b[39m             \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[32m     11\u001b[39m gc.collect()\n\u001b[32m---> \u001b[39m\u001b[32m12\u001b[39m \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcuda\u001b[49m\u001b[43m.\u001b[49m\u001b[43mempty_cache\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     13\u001b[39m torch.cuda.synchronize()\n\u001b[32m     15\u001b[39m \u001b[38;5;66;03m# optional: reset tracking and print status\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.conda/envs/vlm2vec/lib/python3.11/site-packages/torch/cuda/memory.py:224\u001b[39m, in \u001b[36mempty_cache\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m    213\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33mr\u001b[39m\u001b[33;03m\"\"\"Release all unoccupied cached memory currently held by the caching\u001b[39;00m\n\u001b[32m    214\u001b[39m \u001b[33;03mallocator so that those can be used in other GPU application and visible in\u001b[39;00m\n\u001b[32m    215\u001b[39m \u001b[33;03m`nvidia-smi`.\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    221\u001b[39m \u001b[33;03m    more details about GPU memory management.\u001b[39;00m\n\u001b[32m    222\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    223\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m is_initialized():\n\u001b[32m--> \u001b[39m\u001b[32m224\u001b[39m     \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_C\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_cuda_emptyCache\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mAcceleratorError\u001b[39m: CUDA error: device-side assert triggered\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n"
     ]
    }
   ],
   "source": [
    "import gc, torch\n",
    "\n",
    "# delete references to large tensors/models you created\n",
    "for name in (\"batch\", \"pooled_output\", \"image_features\", \"attention_matrix\", \"model\"):\n",
    "    if name in globals():\n",
    "        try:\n",
    "            del globals()[name]\n",
    "        except Exception:\n",
    "            pass\n",
    "\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()\n",
    "torch.cuda.synchronize()\n",
    "\n",
    "# optional: reset tracking and print status\n",
    "for i in range(torch.cuda.device_count()):\n",
    "    torch.cuda.reset_peak_memory_stats(i)\n",
    "print(\"allocated:\", torch.cuda.memory_allocated(), \"cached:\", torch.cuda.memory_reserved())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "bb4bcb57",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"/home/user2/dangnh/VLM_Embed/test/output_t_qry.pkl\", 'rb') as file:\n",
    "    # Use pickle.load() to read the byte stream and deserialize the object\n",
    "    loaded_object = pickle.load(file)\n",
    "    # load to cuda\n",
    "    loaded_object = {k: v.to(\"cuda\") if isinstance(v, torch.Tensor) else v for k, v in loaded_object.items()}\n",
    "    t_qry_reps, t_qry_hidden_states, t_qry_img_feats, t_qry_layers_embeds, t_qry_attention, t_qry_input_data = \\\n",
    "                                                                                loaded_object.values()\n",
    "    t_pos_reps, t_pos_hidden_states, t_pos_img_feats, t_pos_layers_embeds, t_pos_attention, t_pos_input_data = \\\n",
    "                                                                                loaded_object.values()\n",
    "    \n",
    "with open(\"/home/user2/dangnh/VLM_Embed/test/output_s_qry.pkl\", 'rb') as file:\n",
    "    # Use pickle.load() to read the byte stream and deserialize the object\n",
    "    loaded_object = pickle.load(file)\n",
    "    loaded_object = {k: v.to(\"cuda\") if isinstance(v, torch.Tensor) else v for k, v in loaded_object.items()}\n",
    "\n",
    "    s_qry_reps, s_qry_hidden_states, s_qry_img_feats, s_qry_layers_embeds, s_qry_attention, s_qry_input_data = \\\n",
    "                                                                loaded_object.values()\n",
    "    s_pos_reps, s_pos_hidden_states, s_pos_img_feats, s_pos_layers_embeds, s_pos_attention, s_pos_input_data = \\\n",
    "                                                                loaded_object.values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1de947de",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[106]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43mmodel\u001b[49m\n",
      "\u001b[31mNameError\u001b[39m: name 'model' is not defined"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8ad7532a",
   "metadata": {},
   "source": [
    "# Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "f3c2f13f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn \n",
    "import torch.distributed as dist\n",
    "import torch.nn.functional as F\n",
    "from src.criterions.soft_DTW import SoftDTW\n",
    "import ot\n",
    "# ot.backend.get_backend('pytorch')\n",
    "\n",
    "def create_semi_orthogonal_matrix(tensor):\n",
    "    rows, cols = tensor.shape\n",
    "    if rows >= cols:\n",
    "        # QR trực tiếp\n",
    "        a = torch.randn(rows, cols, device=tensor.device, dtype=tensor.dtype)\n",
    "        q, _ = torch.linalg.qr(a, mode='reduced')\n",
    "        tensor.data[:] = q[:, :cols]\n",
    "    else:\n",
    "        # QR trên ma trận transpose để đảm bảo W W^T = I\n",
    "        a = torch.randn(cols, rows, device=tensor.device, dtype=tensor.dtype)\n",
    "        q, _ = torch.linalg.qr(a, mode='reduced')\n",
    "        tensor.data[:] = q.T[:rows, :]\n",
    "    return tensor\n",
    "\n",
    "class Distiller(nn.Module):\n",
    "    def __init__(self, model_args, training_args, device):\n",
    "        super(Distiller, self).__init__()\n",
    "        self.model_args = model_args\n",
    "        self.training_args = training_args\n",
    "        self.device = device\n",
    "\n",
    "        self.student_hidden_dim = 896\n",
    "        self.teacher_hidden_dim = 1536\n",
    "        self.temperature = 0.02\n",
    "        self.set_projector()\n",
    "        print(\"Projectors set.\")\n",
    "\n",
    "        self.t2s_img_align = nn.Sequential(\n",
    "            nn.Linear(self.teacher_hidden_dim, self.student_hidden_dim),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        self.t2s_img_align.to(device=\"cuda\")\n",
    "\n",
    "        # for simple kd\n",
    "        self.last_layer_projector = nn.Sequential(\n",
    "            nn.Linear(self.teacher_hidden_dim, self.student_hidden_dim),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        self.last_layer_projector.to(device=\"cuda\")\n",
    "\n",
    "        # for Soft-DTW\n",
    "        self.num_chosen_hidden_states = 3\n",
    "        self.t2s = nn.ModuleList([\n",
    "            nn.Sequential(\n",
    "                nn.Linear(self.teacher_hidden_dim, self.student_hidden_dim),\n",
    "                nn.ReLU()\n",
    "            )       \n",
    "        ] * self.num_chosen_hidden_states)\n",
    "\n",
    "        self.t2s.to(device=\"cuda\")\n",
    "        \n",
    "    def set_projector(self):\n",
    "        self.projectors = nn.ModuleDict()\n",
    "        projector_config = json.load(open(\"/home/user2/dangnh/VLM_Embed/config/projector_config.json\", 'r'))\n",
    "        \n",
    "        name_dict = {\n",
    "            \"s\": self.student_hidden_dim,\n",
    "            \"t\": self.teacher_hidden_dim,\n",
    "            \"relu\": nn.ReLU()\n",
    "        }\n",
    "        \n",
    "        for name, cfg in projector_config.items():\n",
    "            if not cfg.get(\"enabled\", False):\n",
    "                continue\n",
    "            seq = nn.Sequential()\n",
    "            parts = cfg[\"structure\"].split(\"-\")\n",
    "            parsed = []\n",
    "            \n",
    "            for p in parts:\n",
    "                if p == \"relu\":\n",
    "                    parsed.append(\"relu\")\n",
    "                else:\n",
    "                    coef = int(p[:-1]) if len(p) > 1 and p[:-1].isdigit() else 1\n",
    "                    parsed.append(coef * name_dict[p[-1]])\n",
    "            for i in range(len(parsed) -1):\n",
    "                a, b = parsed[i], parsed[i+1]\n",
    "                if isinstance(a, int) and isinstance(b, int):\n",
    "                    layer = nn.Linear(a, b)\n",
    "                    create_semi_orthogonal_matrix(layer.weight)\n",
    "                    seq.append(layer)\n",
    "                elif b == \"relu\":\n",
    "                    seq.append(name_dict[b])\n",
    "                elif a ==\"relu\" and isinstance(b, int):\n",
    "                    prev_out = parsed[i-1] if isinstance(parsed[i-1], int) else None\n",
    "                    layer = nn.Linear(prev_out, b)\n",
    "                    create_semi_orthogonal_matrix(layer.weight)\n",
    "                    seq.append(layer)\n",
    "            self.projectors[name] = seq\n",
    "            print(f\"Projector {name} created with structure: {seq}\")\n",
    "    \n",
    "    def add_optimizer_param_group(self, optimizer):\n",
    "        if hasattr(self, 'projectors'):\n",
    "            lr = 0.001\n",
    "            optimizer.add_param_group({\n",
    "                \"params\": [p for proj in self.projectors.values() for p in proj.parameters()],\n",
    "                \"lr\": lr\n",
    "            })\n",
    "        print(\"Projector parameters added to optimizer.\")\n",
    "        return optimizer\n",
    "\n",
    "class StrongerKD(nn.Module):\n",
    "    def __init__(self, args):\n",
    "        super(StrongerKD, self).__init__()\n",
    "        self.args = args\n",
    "        self.rkd_loss_weight = 0.5\n",
    "        self.simple_kd_weight = 0.5\n",
    "        self.intra_rkd_weight = 0.5\n",
    "        self.cross_modal_kd_weight = 0.01\n",
    "        self.ot_loss_weight = 0.5\n",
    "        self.num_chosen_hidden_states = 3\n",
    "\n",
    "        self.cross_entropy_loss = nn.CrossEntropyLoss()\n",
    "        self.sdtw = SoftDTW(use_cuda=True, gamma=0.001)\n",
    "        self.mse_loss = nn.MSELoss(reduction=\"mean\")\n",
    "\n",
    "\n",
    "    def forward(self, distiller, input_data):\n",
    "        self.distiller = Distiller(model_args, training_args, \"cuda\")\n",
    "        # student_model = distiller.student\n",
    "        # teacher_model = distiller.teacher\n",
    "        \n",
    "        with open(\"/home/user2/dangnh/VLM_Embed/test/output_t_qry.pkl\", 'rb') as file:\n",
    "            # Use pickle.load() to read the byte stream and deserialize the object\n",
    "            loaded_object = pickle.load(file)\n",
    "            # load to cuda\n",
    "            loaded_object = {k: v.to(\"cuda\") if isinstance(v, torch.Tensor) else v for k, v in loaded_object.items()}\n",
    "            t_qry_reps, t_qry_hidden_states, t_qry_img_feats, t_qry_layers_embeds, t_qry_attention, t_qry_input_data = \\\n",
    "                                                                                        loaded_object.values()\n",
    "            t_pos_reps, t_pos_hidden_states, t_pos_img_feats, t_pos_layers_embeds, t_pos_attention, t_pos_input_data = \\\n",
    "                                                                                        loaded_object.values()\n",
    "            \n",
    "            # t_qry_hidden_states, t_qry_img_feats = torch.stack(t_qry_hidden_states, dim=0), torch.stack(t_qry_img_feats, dim=0)\n",
    "            # t_pos_hidden_states, t_pos_img_feats = torch.stack(t_pos_hidden_states, dim=0), torch.stack(t_pos_img_feats, dim=0)\n",
    "        with open(\"/home/user2/dangnh/VLM_Embed/test/output_s_qry.pkl\", 'rb') as file:\n",
    "            # Use pickle.load() to read the byte stream and deserialize the object\n",
    "            loaded_object = pickle.load(file)\n",
    "            loaded_object = {k: v.to(\"cuda\") if isinstance(v, torch.Tensor) else v for k, v in loaded_object.items()}\n",
    "\n",
    "            s_qry_reps, s_qry_hidden_states, s_qry_img_feats, s_qry_layers_embeds, s_qry_attention, s_qry_input_data = \\\n",
    "                                                                        loaded_object.values()\n",
    "            s_pos_reps, s_pos_hidden_states, s_pos_img_feats, s_pos_layers_embeds, s_pos_attention, s_pos_input_data = \\\n",
    "                                                                        loaded_object.values()\n",
    "            # s_qry_hidden_states, s_qry_img_feats = torch.stack(s_qry_hidden_states, dim=0), torch.stack(s_qry_img_feats, dim=0)\n",
    "            # s_pos_hidden_states, s_pos_img_feats = torch.stack(s_pos_hidden_states, dim=0), torch.stack(s_pos_img_feats, dim=0)\n",
    "\n",
    "        ## contrastive\n",
    "        # scores = student_model.compute_similarity(s_qry_reps, s_pos_reps)\n",
    "        # scores = scores.view(s_qry_reps.size(0), -1)\n",
    "        # target = torch.arange(scores.size(0), device=scores.device, dtype=torch.long)\n",
    "        # target = target * (s_qry_reps.size(0) // s_pos_reps.size(0))\n",
    "        # contrastive_loss = self.cross_entropy_loss(scores / self.distiller.temperature, target)\n",
    "        contrastive_loss = torch.tensor(0.0).to(\"cuda\")\n",
    "        ## image alignments\n",
    "        img_align_loss = 0.0\n",
    "        batch_size = s_qry_reps.size(0)\n",
    "\n",
    "        for i in range(batch_size):\n",
    "            if s_qry_img_feats is not None and t_qry_img_feats is not None:\n",
    "                if s_qry_img_feats[i] is not None and t_qry_img_feats[i] is not None:\n",
    "                    tmp_s_qry_img_feats = F.normalize(s_qry_img_feats[i], p=2, dim=-1)\n",
    "                    tmp_t_qry_img_feats = self.distiller.t2s_img_align(t_qry_img_feats[i])\n",
    "\n",
    "                    tmp_t_qry_image_features = F.normalize(tmp_t_qry_img_feats, p=2, dim=-1)\n",
    "\n",
    "                    img_align_loss += self.alignment_loss_mmd(tmp_t_qry_image_features, tmp_s_qry_img_feats)\n",
    "\n",
    "            if s_pos_img_feats is not None and t_pos_img_feats is not None:\n",
    "                if s_pos_img_feats[i] is not None and t_pos_img_feats[i] is not None:\n",
    "                    tmp_s_pos_img_feats = F.normalize(s_pos_img_feats[i], p=2, dim=-1)\n",
    "                    tmp_t_pos_img_feats = self.distiller.t2s_img_align(t_pos_img_feats[i])\n",
    "                    \n",
    "                    tmp_t_pos_image_features = F.normalize(tmp_t_pos_img_feats, p=2, dim=-1)\n",
    "\n",
    "                    img_align_loss += self.alignment_loss_mmd(tmp_t_pos_image_features, tmp_s_pos_img_feats)\n",
    "\n",
    "        img_align_loss = img_align_loss / batch_size\n",
    "\n",
    "        ## data-points rkd \n",
    "        distance_loss = self.compute_distance_loss(s_qry_reps, s_pos_reps, t_qry_reps, t_pos_reps)\n",
    "        angle_loss = self.compute_angle_loss(s_qry_reps, s_pos_reps, t_qry_reps, t_pos_reps)\n",
    "\n",
    "        rkd_loss = (0.5 * distance_loss + 0.5 * angle_loss)\n",
    "\n",
    "        ## simple kd\n",
    "        simple_kd_loss = self.simple_kd_logit_loss(s_qry_reps, s_pos_reps, t_qry_reps, t_pos_reps)\n",
    "\n",
    "        ## intra rkd\n",
    "        intra_rkd_loss = self.intra_rkd(t_qry_layers_embeds, t_pos_layers_embeds,\n",
    "                                        s_qry_layers_embeds, s_pos_layers_embeds)\n",
    "        \n",
    "        ## cross modal kd\n",
    "        # num_s_img_tokens, num_t_img_tokens = s_qry_img_feats.size(1), t_qry_img_feats.size(1)\n",
    "        qry_cross_modal_kd_loss = self.cross_modal_kd_loss(s_qry_hidden_states,\n",
    "                                                       t_qry_hidden_states,\n",
    "                                                       s_qry_img_feats,\n",
    "                                                       t_qry_img_feats)\n",
    "\n",
    "        # num_s_img_tokens, num_t_img_tokens = s_pos_img_feats.size(1), t_pos_img_feats.size(1)\n",
    "        pos_cross_modal_kd_loss = self.cross_modal_kd_loss(s_pos_hidden_states,\n",
    "                                                       t_pos_hidden_states,\n",
    "                                                       s_pos_img_feats,\n",
    "                                                       t_pos_img_feats)\n",
    "        \n",
    "        cross_modal_kd_loss = 0.5 * qry_cross_modal_kd_loss + 0.5 * pos_cross_modal_kd_loss\n",
    "\n",
    "        ## optimal transport loss\n",
    "        ot_loss = self.compute_ot(s_qry_hidden_states, s_qry_attention,\n",
    "                                  t_qry_hidden_states, t_qry_attention)\n",
    "        ot_loss += self.compute_ot(s_pos_hidden_states, s_pos_attention,\n",
    "                                  t_pos_hidden_states, t_pos_attention)\n",
    "        ot_loss = ot_loss / 2.0\n",
    "\n",
    "        total_loss = contrastive_loss + \\\n",
    "                     self.rkd_loss_weight * rkd_loss + \\\n",
    "                     self.simple_kd_weight * simple_kd_loss + \\\n",
    "                     self.intra_rkd_weight * intra_rkd_loss + \\\n",
    "                     self.cross_modal_kd_weight * cross_modal_kd_loss + \\\n",
    "                     self.ot_loss_weight * ot_loss\n",
    "        \n",
    "        return {\n",
    "            \"total_loss\": total_loss,\n",
    "            \"contrastive_loss\": contrastive_loss,\n",
    "            \"rkd_loss\": rkd_loss,\n",
    "            \"simple_kd_loss\": simple_kd_loss,\n",
    "            \"intra_rkd_loss\": intra_rkd_loss,\n",
    "            \"cross_modal_kd_loss\": cross_modal_kd_loss,\n",
    "            \"ot_loss\": ot_loss,\n",
    "            \"img_align_loss\": img_align_loss\n",
    "        }\n",
    "\n",
    "    def gaussian_kernel(self, x, y, sigma=2.0):\n",
    "        \"\"\"\n",
    "        Computes the RBF (Gaussian) kernel between two sets of vectors.\n",
    "        k(x, y) = exp(-||x - y||^2 / (2 * sigma^2))\n",
    "        \n",
    "        Args:\n",
    "            x (torch.Tensor): Shape (n, dim)\n",
    "            y (torch.Tensor): Shape (m, dim)\n",
    "            sigma (float): Kernel bandwidth.\n",
    "        \"\"\"\n",
    "        beta = 1.0 / (2.0 * (sigma ** 2))\n",
    "        # (n, m) matrix of squared pairwise distances\n",
    "        dist_sq = torch.cdist(x.unsqueeze(0), y.unsqueeze(0), p=2).pow(2)\n",
    "        return torch.exp(-beta * dist_sq)\n",
    "\n",
    "    def alignment_loss_mmd(self, t_feats, s_feats, sigma=2.0):\n",
    "        \"\"\"\n",
    "        Computes the Maximum Mean Discrepancy (MMD) loss using a Gaussian kernel.\n",
    "\n",
    "        Args:\n",
    "            x_teacher (torch.Tensor): Teacher features, shape (n, dim)\n",
    "            x_student (torch.Tensor): Student features, shape (m, dim)\n",
    "            sigma (float): Kernel bandwidth.\n",
    "        \"\"\"\n",
    "        \n",
    "        # Compute kernel matrices\n",
    "        k_tt = self.gaussian_kernel(t_feats, t_feats, sigma) # (n, n)\n",
    "        k_ss = self.gaussian_kernel(s_feats, s_feats, sigma) # (m, m)\n",
    "        k_ts = self.gaussian_kernel(t_feats, s_feats, sigma) # (n, m)\n",
    "        \n",
    "        # This is the (biased) MMD^2 statistic\n",
    "        # E[k(t, t')] + E[k(s, s')] - 2 * E[k(t, s)]\n",
    "        mmd_loss = k_tt.mean() + k_ss.mean() - 2 * k_ts.mean()\n",
    "        \n",
    "        return mmd_loss\n",
    "    \n",
    "    def compute_ot(self, s_hidden_states, s_attn, t_hidden_states, t_attn):\n",
    "        \n",
    "        loss = 0.0\n",
    "        num_student_layers = len(s_hidden_states)\n",
    "        num_teacher_layers = len(t_hidden_states)\n",
    "        scale = num_teacher_layers // num_student_layers\n",
    "        start_layer = num_student_layers - self.distiller.num_chosen_hidden_states\n",
    "\n",
    "        for l in range(start_layer, num_student_layers):\n",
    "            s_dist = F.softmax(s_attn[l - 1].mean(dim=1)[:, -1], dim=-1) # (b, n)\n",
    "            t_dist = F.softmax(t_attn[l - 1].mean(dim=1)[:, -1], dim=-1) # (b, m)\n",
    "\n",
    "            s_hidden_state = s_hidden_states[l] # (b, n, emb_dim)\n",
    "            proj_t_hidden_state = self.distiller.t2s[l - start_layer](t_hidden_states[scale * l]) # (b, m, emb_dim)\n",
    "\n",
    "            for b in range(s_dist.size(0)):\n",
    "                cost_matrix = torch.cdist(s_hidden_state[b].unsqueeze(0), \n",
    "                                          proj_t_hidden_state[b].unsqueeze(0)).squeeze(0)\n",
    "\n",
    "                transport = self.sinkhorn(s_dist[b], t_dist[b], cost_matrix) \n",
    "                loss += torch.sum(transport * cost_matrix)\n",
    "\n",
    "        return loss / s_dist.size(0)\n",
    "    \n",
    "    def sinkhorn(self, a, b, cost_matrix, reg=0.1, num_iters=100, eps=1e-9, stopThr = 1e-7):\n",
    "        \"\"\"\n",
    "        a: (m,) or (m,1) torch tensor (source weights)\n",
    "        b: (n,) or (n,1) torch tensor (target weights)\n",
    "        cost_matrix: (m, n) torch tensor\n",
    "        reg: regularization (>=0) -- larger reg -> smoother K = exp(-C/reg)\n",
    "        num_iters: number of Sinkhorn iterations\n",
    "        \"\"\"\n",
    "        device = cost_matrix.device\n",
    "        # use float32 for numeric stability\n",
    "        dtype = torch.float32\n",
    "        a = a.detach().to(device=device, dtype=dtype).view(-1, 1)\n",
    "        b = b.detach().to(device=device, dtype=dtype).view(-1, 1)\n",
    "        C = cost_matrix.detach().to(device=device, dtype=dtype)\n",
    "\n",
    "        m, n = C.shape\n",
    "        if m == 0 or n == 0:\n",
    "            return torch.zeros((m, n), device=device, dtype=dtype)\n",
    "\n",
    "        # ensure shapes\n",
    "        if a.shape[0] != m:\n",
    "            a = torch.ones((m, 1), device=device, dtype=dtype) / m\n",
    "        if b.shape[0] != n:\n",
    "            b = torch.ones((n, 1), device=device, dtype=dtype) / n\n",
    "\n",
    "        suma = a.sum()\n",
    "        sumb = b.sum()\n",
    "        if suma <= eps or sumb <= eps:\n",
    "            a = torch.ones((m, 1), device=device, dtype=dtype) / m\n",
    "            b = torch.ones((n, 1), device=device, dtype=dtype) / n\n",
    "        else:\n",
    "            a = a / suma\n",
    "            b = b / sumb\n",
    "\n",
    "        K = torch.exp(-C / (reg + 1e-12))\n",
    "        K = torch.clamp(K, min=1e-200)\n",
    "\n",
    "        u = torch.ones((m, 1), device=device, dtype=dtype)\n",
    "        v = torch.ones((n, 1), device=device, dtype=dtype)\n",
    "\n",
    "        for i in range(num_iters):\n",
    "            u_prev = u.clone()\n",
    "            KTv = (K.t() @ u)  # shape (n,1)\n",
    "            v = b / (KTv + eps)\n",
    "            Kv = (K @ v)       # shape (m,1)\n",
    "            u = a / (Kv + eps)\n",
    "\n",
    "            err = torch.max(torch.abs(u - u_prev))\n",
    "            if err.item() < stopThr:\n",
    "                break\n",
    "\n",
    "        # transport plan\n",
    "        U = torch.diag_embed(u.squeeze())   # (m,m) diag(u)\n",
    "        V = torch.diag_embed(v.squeeze())   # (n,n) diag(v)\n",
    "        P = U @ K @ V                       # (m,n)\n",
    "        return P\n",
    "    \n",
    "    def cross_modal_kd_loss(self, s_hidden_states, t_hidden_states, s_img_feats, t_img_feats):\n",
    "        \"\"\"\n",
    "            hidden_states: list of (n_layers, b, n, dim)\n",
    "            img_feats: (b, n_img_tokens, dim)\n",
    "        \"\"\"\n",
    "\n",
    "        loss = 0.0\n",
    "        num_student_layers = len(s_hidden_states)\n",
    "        num_teacher_layers = len(t_hidden_states)\n",
    "        scale = num_teacher_layers // num_student_layers\n",
    "        batch_size = s_hidden_states[0].size(0)\n",
    "        start_layer = num_student_layers - self.distiller.num_chosen_hidden_states\n",
    "\n",
    "        if s_img_feats is None or t_img_feats is None:\n",
    "            return loss\n",
    "        \n",
    "        for b in range(batch_size):\n",
    "            if s_img_feats[b] is not None and t_img_feats[b] is not None:\n",
    "\n",
    "                for l in range(start_layer, num_student_layers):\n",
    "\n",
    "                    num_s_img_tokens = s_img_feats[b].size(0)\n",
    "                    num_t_img_tokens = t_img_feats[b].size(0)\n",
    "\n",
    "                    s_img_hidden_states = F.normalize(s_hidden_states[l][b][:num_s_img_tokens])\n",
    "                    s_text_hidden_states = F.normalize(s_hidden_states[l][b][num_s_img_tokens:])\n",
    "\n",
    "                    proj_t_img_hidden_states = F.normalize(self.distiller.t2s[l - start_layer](t_hidden_states[scale * l][b][:num_t_img_tokens]))\n",
    "                    proj_t_text_hidden_states = F.normalize(self.distiller.t2s[l - start_layer](t_hidden_states[scale * l][b][num_t_img_tokens:]))\n",
    "                    print(f\"s_img_hidden_states shape: {s_img_hidden_states.shape}\")\n",
    "                    print(f\"t_img_hs shape: {proj_t_img_hidden_states.shape}\")\n",
    "                    \n",
    "                    loss += 0.5 * self.sdtw(s_img_hidden_states.unsqueeze(0), proj_t_text_hidden_states.unsqueeze(0)).mean()\n",
    "                    loss += 0.5 * self.sdtw(s_text_hidden_states.unsqueeze(0), proj_t_img_hidden_states.unsqueeze(0)).mean()\n",
    "\n",
    "        return loss / (batch_size * self.distiller.num_chosen_hidden_states)\n",
    "    \n",
    "    def simple_kd_logit_loss(self, student_qry_reps, student_pos_reps, teacher_qry_reps, teacher_pos_reps):\n",
    "            projector_teacher_qry_reps = self.distiller.last_layer_projector(teacher_qry_reps)\n",
    "            projector_teacher_qry_reps = F.normalize(projector_teacher_qry_reps, p=2, dim=-1)\n",
    "\n",
    "            projector_teacher_pos_reps = self.distiller.last_layer_projector(teacher_pos_reps)\n",
    "            projector_teacher_pos_reps = F.normalize(projector_teacher_qry_reps, p=2, dim=-1)\n",
    "\n",
    "\n",
    "            loss = (\n",
    "                    self.mse_loss(student_qry_reps, projector_teacher_qry_reps) +  \n",
    "                    self.mse_loss(student_pos_reps, projector_teacher_pos_reps)\n",
    "                   ) / 2.0\n",
    "            return loss\n",
    "    \n",
    "    def intra_rkd(self, \n",
    "                  teacher_qry_layers_embeds, # (b, n_layers, dim), \n",
    "                  teacher_pos_layers_embeds,\n",
    "                  student_qry_layers_embeds,\n",
    "                  student_pos_layers_embeds):\n",
    "        \n",
    "        loss = 0.0\n",
    "        batch_size = student_pos_layers_embeds.size(0)\n",
    "\n",
    "        for b in range(batch_size):\n",
    "\n",
    "            dist_loss = self.compute_distance_loss(student_qry_layers_embeds[b], student_pos_layers_embeds[b], \n",
    "                                                   teacher_qry_layers_embeds[b], teacher_pos_layers_embeds[b])\n",
    "            \n",
    "            angle_loss = self.compute_angle_loss(student_qry_layers_embeds[b], student_pos_layers_embeds[b], \n",
    "                                                    teacher_qry_layers_embeds[b], teacher_pos_layers_embeds[b])\n",
    "            loss += 0.5 * dist_loss + 0.5 * angle_loss\n",
    "\n",
    "        return loss / batch_size\n",
    "\n",
    "    def pairwise_distance(self, x):\n",
    "        norm = (x**2).sum(dim=1, keepdim=True)\n",
    "        dist = norm + norm.t() - 2.0 * torch.mm(x, x.t())\n",
    "        return dist\n",
    "    \n",
    "    def compute_distance_loss(self, student_qry, student_pos, teacher_qry, teacher_pos):\n",
    "        \n",
    "        num_student_layers = student_qry.size(0)\n",
    "        num_teacher_layers = teacher_qry.size(0)\n",
    "        scale = num_teacher_layers // num_student_layers\n",
    "\n",
    "        student_repr = torch.cat([student_qry, student_pos], dim=1)\n",
    "        teacher_repr = torch.cat([teacher_qry, teacher_pos], dim=1)[\n",
    "            torch.tensor([i * scale for i in range(num_student_layers)], device=teacher_qry.device)\n",
    "        ]\n",
    "\n",
    "        dist_student = self.pairwise_distance(student_repr)\n",
    "        dist_teacher = self.pairwise_distance(teacher_repr)\n",
    "        \n",
    "        mask = torch.triu(torch.ones_like(dist_student), diagonal=1).bool()\n",
    "        dist_student = dist_student[mask]\n",
    "        dist_teacher = dist_teacher[mask]\n",
    "        \n",
    "        mean_td = dist_teacher.mean().detach() + 1e-8\n",
    "        mean_sd = dist_student.mean().detach() + 1e-8\n",
    "        \n",
    "        dist_student = dist_student / mean_sd\n",
    "        dist_teacher = dist_teacher / mean_td\n",
    "        \n",
    "        diff = dist_student - dist_teacher\n",
    "        abs_diff = torch.abs(diff)\n",
    "        quadratic = 0.5 * (abs_diff ** 2)\n",
    "        linear = abs_diff - 0.5\n",
    "        \n",
    "        loss = torch.where(abs_diff < 1.0, quadratic, linear)\n",
    "        loss = loss.mean()\n",
    "        return loss\n",
    "    \n",
    "    def angle_potentials(self, x):\n",
    "        n = x.size(0)\n",
    "        diffs = x.unsqueeze(0) - x.unsqueeze(1)\n",
    "        norms = torch.norm(diffs, dim=-1, keepdim=True) + 1e-8\n",
    "        e = diffs / norms\n",
    "        \n",
    "        cos_angles = torch.einsum('ijd,kjd->ijk', e, e)\n",
    "        return cos_angles\n",
    "    \n",
    "    def compute_angle_loss(self, student_qry, student_pos, teacher_qry, teacher_pos):\n",
    "        \n",
    "        num_student_layers = student_qry.size(0)\n",
    "        num_teacher_layers = teacher_qry.size(0)\n",
    "        scale = num_teacher_layers // num_student_layers\n",
    "    \n",
    "        student_repr = torch.cat([student_qry, student_pos], dim=1)\n",
    "        teacher_repr = torch.cat([teacher_qry, teacher_pos], dim=1)[\n",
    "            torch.tensor([i * scale for i in range(num_student_layers)], device=teacher_qry.device)\n",
    "        ]\n",
    "\n",
    "        psi_student = self.angle_potentials(student_repr)\n",
    "        psi_teacher = self.angle_potentials(teacher_repr)\n",
    "        \n",
    "        n = psi_student.size(0)\n",
    "        mask = torch.ones((n, n, n), dtype=torch.bool, device=psi_student.device)\n",
    "        idx = torch.arange(n, device=psi_student.device)\n",
    "        mask[idx, idx, :] = 0\n",
    "        mask[idx, :, idx] = 0\n",
    "        mask[:, idx, idx] = 0\n",
    "        \n",
    "        psi_teacher = psi_teacher[mask]\n",
    "        psi_student = psi_student[mask]\n",
    "        \n",
    "        diff = psi_student - psi_teacher\n",
    "        abs_diff = torch.abs(diff)\n",
    "        quadratic = 0.5 * (abs_diff ** 2)\n",
    "        linear = abs_diff - 0.5\n",
    "        loss = torch.where(abs_diff < 1.0, quadratic, linear)\n",
    "        loss = loss.mean()\n",
    "        return loss\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "fbe499be",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = StrongerKD(training_args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "63f09590",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Projector t2s_img created with structure: Sequential(\n",
      "  (0): Linear(in_features=1536, out_features=896, bias=True)\n",
      ")\n",
      "Projector t2s_txt created with structure: Sequential(\n",
      "  (0): Linear(in_features=1536, out_features=896, bias=True)\n",
      ")\n",
      "Projectors set.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2025-11-08 05:00:53,548] DEBUG [numba.cuda.cudadrv.driver:325] call driver api: cuCtxGetCurrent\n",
      "[2025-11-08 05:00:53,549] DEBUG [numba.cuda.cudadrv.driver:325] call driver api: cuCtxGetDevice\n",
      "[2025-11-08 05:00:53,549] DEBUG [numba.cuda.cudadrv.driver:325] call driver api: cuPointerGetAttribute\n",
      "[2025-11-08 05:00:53,550] DEBUG [numba.cuda.cudadrv.driver:325] call driver api: cuCtxGetCurrent\n",
      "[2025-11-08 05:00:53,551] DEBUG [numba.cuda.cudadrv.driver:325] call driver api: cuCtxGetDevice\n",
      "[2025-11-08 05:00:53,552] DEBUG [numba.cuda.cudadrv.driver:325] call driver api: cuPointerGetAttribute\n",
      "[2025-11-08 05:00:53,552] DEBUG [numba.cuda.cudadrv.driver:325] call driver api: cuCtxGetCurrent\n",
      "[2025-11-08 05:00:53,553] DEBUG [numba.cuda.cudadrv.driver:325] call driver api: cuCtxGetDevice\n",
      "[2025-11-08 05:00:53,554] DEBUG [numba.cuda.cudadrv.driver:325] call driver api: cuLaunchKernel\n",
      "[2025-11-08 05:00:53,557] DEBUG [numba.cuda.cudadrv.driver:325] call driver api: cuCtxGetCurrent\n",
      "[2025-11-08 05:00:53,557] DEBUG [numba.cuda.cudadrv.driver:325] call driver api: cuCtxGetDevice\n",
      "[2025-11-08 05:00:53,558] DEBUG [numba.cuda.cudadrv.driver:325] call driver api: cuPointerGetAttribute\n",
      "[2025-11-08 05:00:53,559] DEBUG [numba.cuda.cudadrv.driver:325] call driver api: cuCtxGetCurrent\n",
      "[2025-11-08 05:00:53,560] DEBUG [numba.cuda.cudadrv.driver:325] call driver api: cuCtxGetDevice\n",
      "[2025-11-08 05:00:53,561] DEBUG [numba.cuda.cudadrv.driver:325] call driver api: cuPointerGetAttribute\n",
      "[2025-11-08 05:00:53,561] DEBUG [numba.cuda.cudadrv.driver:325] call driver api: cuCtxGetCurrent\n",
      "[2025-11-08 05:00:53,562] DEBUG [numba.cuda.cudadrv.driver:325] call driver api: cuCtxGetDevice\n",
      "[2025-11-08 05:00:53,562] DEBUG [numba.cuda.cudadrv.driver:325] call driver api: cuLaunchKernel\n",
      "[2025-11-08 05:00:53,566] DEBUG [numba.cuda.cudadrv.driver:325] call driver api: cuCtxGetCurrent\n",
      "[2025-11-08 05:00:53,567] DEBUG [numba.cuda.cudadrv.driver:325] call driver api: cuCtxGetDevice\n",
      "[2025-11-08 05:00:53,568] DEBUG [numba.cuda.cudadrv.driver:325] call driver api: cuPointerGetAttribute\n",
      "[2025-11-08 05:00:53,569] DEBUG [numba.cuda.cudadrv.driver:325] call driver api: cuCtxGetCurrent\n",
      "[2025-11-08 05:00:53,569] DEBUG [numba.cuda.cudadrv.driver:325] call driver api: cuCtxGetDevice\n",
      "[2025-11-08 05:00:53,570] DEBUG [numba.cuda.cudadrv.driver:325] call driver api: cuPointerGetAttribute\n",
      "[2025-11-08 05:00:53,571] DEBUG [numba.cuda.cudadrv.driver:325] call driver api: cuCtxGetCurrent\n",
      "[2025-11-08 05:00:53,571] DEBUG [numba.cuda.cudadrv.driver:325] call driver api: cuCtxGetDevice\n",
      "[2025-11-08 05:00:53,572] DEBUG [numba.cuda.cudadrv.driver:325] call driver api: cuLaunchKernel\n",
      "[2025-11-08 05:00:53,574] DEBUG [numba.cuda.cudadrv.driver:325] call driver api: cuCtxGetCurrent\n",
      "[2025-11-08 05:00:53,575] DEBUG [numba.cuda.cudadrv.driver:325] call driver api: cuCtxGetDevice\n",
      "[2025-11-08 05:00:53,575] DEBUG [numba.cuda.cudadrv.driver:325] call driver api: cuPointerGetAttribute\n",
      "[2025-11-08 05:00:53,577] DEBUG [numba.cuda.cudadrv.driver:325] call driver api: cuCtxGetCurrent\n",
      "[2025-11-08 05:00:53,577] DEBUG [numba.cuda.cudadrv.driver:325] call driver api: cuCtxGetDevice\n",
      "[2025-11-08 05:00:53,578] DEBUG [numba.cuda.cudadrv.driver:325] call driver api: cuPointerGetAttribute\n",
      "[2025-11-08 05:00:53,578] DEBUG [numba.cuda.cudadrv.driver:325] call driver api: cuCtxGetCurrent\n",
      "[2025-11-08 05:00:53,579] DEBUG [numba.cuda.cudadrv.driver:325] call driver api: cuCtxGetDevice\n",
      "[2025-11-08 05:00:53,580] DEBUG [numba.cuda.cudadrv.driver:325] call driver api: cuLaunchKernel\n",
      "[2025-11-08 05:00:53,587] DEBUG [numba.cuda.cudadrv.driver:325] call driver api: cuCtxGetCurrent\n",
      "[2025-11-08 05:00:53,587] DEBUG [numba.cuda.cudadrv.driver:325] call driver api: cuCtxGetDevice\n",
      "[2025-11-08 05:00:53,588] DEBUG [numba.cuda.cudadrv.driver:325] call driver api: cuPointerGetAttribute\n",
      "[2025-11-08 05:00:53,589] DEBUG [numba.cuda.cudadrv.driver:325] call driver api: cuCtxGetCurrent\n",
      "[2025-11-08 05:00:53,590] DEBUG [numba.cuda.cudadrv.driver:325] call driver api: cuCtxGetDevice\n",
      "[2025-11-08 05:00:53,591] DEBUG [numba.cuda.cudadrv.driver:325] call driver api: cuPointerGetAttribute\n",
      "[2025-11-08 05:00:53,591] DEBUG [numba.cuda.cudadrv.driver:325] call driver api: cuCtxGetCurrent\n",
      "[2025-11-08 05:00:53,592] DEBUG [numba.cuda.cudadrv.driver:325] call driver api: cuCtxGetDevice\n",
      "[2025-11-08 05:00:53,593] DEBUG [numba.cuda.cudadrv.driver:325] call driver api: cuLaunchKernel\n",
      "[2025-11-08 05:00:53,597] DEBUG [numba.cuda.cudadrv.driver:325] call driver api: cuCtxGetCurrent\n",
      "[2025-11-08 05:00:53,597] DEBUG [numba.cuda.cudadrv.driver:325] call driver api: cuCtxGetDevice\n",
      "[2025-11-08 05:00:53,598] DEBUG [numba.cuda.cudadrv.driver:325] call driver api: cuPointerGetAttribute\n",
      "[2025-11-08 05:00:53,599] DEBUG [numba.cuda.cudadrv.driver:325] call driver api: cuCtxGetCurrent\n",
      "[2025-11-08 05:00:53,600] DEBUG [numba.cuda.cudadrv.driver:325] call driver api: cuCtxGetDevice\n",
      "[2025-11-08 05:00:53,600] DEBUG [numba.cuda.cudadrv.driver:325] call driver api: cuPointerGetAttribute\n",
      "[2025-11-08 05:00:53,601] DEBUG [numba.cuda.cudadrv.driver:325] call driver api: cuCtxGetCurrent\n",
      "[2025-11-08 05:00:53,601] DEBUG [numba.cuda.cudadrv.driver:325] call driver api: cuCtxGetDevice\n",
      "[2025-11-08 05:00:53,602] DEBUG [numba.cuda.cudadrv.driver:325] call driver api: cuLaunchKernel\n",
      "[2025-11-08 05:00:53,605] DEBUG [numba.cuda.cudadrv.driver:325] call driver api: cuCtxGetCurrent\n",
      "[2025-11-08 05:00:53,605] DEBUG [numba.cuda.cudadrv.driver:325] call driver api: cuCtxGetDevice\n",
      "[2025-11-08 05:00:53,606] DEBUG [numba.cuda.cudadrv.driver:325] call driver api: cuPointerGetAttribute\n",
      "[2025-11-08 05:00:53,607] DEBUG [numba.cuda.cudadrv.driver:325] call driver api: cuCtxGetCurrent\n",
      "[2025-11-08 05:00:53,607] DEBUG [numba.cuda.cudadrv.driver:325] call driver api: cuCtxGetDevice\n",
      "[2025-11-08 05:00:53,608] DEBUG [numba.cuda.cudadrv.driver:325] call driver api: cuPointerGetAttribute\n",
      "[2025-11-08 05:00:53,608] DEBUG [numba.cuda.cudadrv.driver:325] call driver api: cuCtxGetCurrent\n",
      "[2025-11-08 05:00:53,609] DEBUG [numba.cuda.cudadrv.driver:325] call driver api: cuCtxGetDevice\n",
      "[2025-11-08 05:00:53,609] DEBUG [numba.cuda.cudadrv.driver:325] call driver api: cuLaunchKernel\n",
      "[2025-11-08 05:00:53,611] DEBUG [numba.cuda.cudadrv.driver:325] call driver api: cuCtxGetCurrent\n",
      "[2025-11-08 05:00:53,611] DEBUG [numba.cuda.cudadrv.driver:325] call driver api: cuCtxGetDevice\n",
      "[2025-11-08 05:00:53,612] DEBUG [numba.cuda.cudadrv.driver:325] call driver api: cuPointerGetAttribute\n",
      "[2025-11-08 05:00:53,612] DEBUG [numba.cuda.cudadrv.driver:325] call driver api: cuCtxGetCurrent\n",
      "[2025-11-08 05:00:53,613] DEBUG [numba.cuda.cudadrv.driver:325] call driver api: cuCtxGetDevice\n",
      "[2025-11-08 05:00:53,613] DEBUG [numba.cuda.cudadrv.driver:325] call driver api: cuPointerGetAttribute\n",
      "[2025-11-08 05:00:53,614] DEBUG [numba.cuda.cudadrv.driver:325] call driver api: cuCtxGetCurrent\n",
      "[2025-11-08 05:00:53,614] DEBUG [numba.cuda.cudadrv.driver:325] call driver api: cuCtxGetDevice\n",
      "[2025-11-08 05:00:53,614] DEBUG [numba.cuda.cudadrv.driver:325] call driver api: cuLaunchKernel\n",
      "[2025-11-08 05:00:53,617] DEBUG [numba.cuda.cudadrv.driver:325] call driver api: cuCtxGetCurrent\n",
      "[2025-11-08 05:00:53,617] DEBUG [numba.cuda.cudadrv.driver:325] call driver api: cuCtxGetDevice\n",
      "[2025-11-08 05:00:53,617] DEBUG [numba.cuda.cudadrv.driver:325] call driver api: cuPointerGetAttribute\n",
      "[2025-11-08 05:00:53,618] DEBUG [numba.cuda.cudadrv.driver:325] call driver api: cuCtxGetCurrent\n",
      "[2025-11-08 05:00:53,618] DEBUG [numba.cuda.cudadrv.driver:325] call driver api: cuCtxGetDevice\n",
      "[2025-11-08 05:00:53,619] DEBUG [numba.cuda.cudadrv.driver:325] call driver api: cuPointerGetAttribute\n",
      "[2025-11-08 05:00:53,619] DEBUG [numba.cuda.cudadrv.driver:325] call driver api: cuCtxGetCurrent\n",
      "[2025-11-08 05:00:53,619] DEBUG [numba.cuda.cudadrv.driver:325] call driver api: cuCtxGetDevice\n",
      "[2025-11-08 05:00:53,620] DEBUG [numba.cuda.cudadrv.driver:325] call driver api: cuLaunchKernel\n",
      "[2025-11-08 05:00:53,621] DEBUG [numba.cuda.cudadrv.driver:325] call driver api: cuCtxGetCurrent\n",
      "[2025-11-08 05:00:53,622] DEBUG [numba.cuda.cudadrv.driver:325] call driver api: cuCtxGetDevice\n",
      "[2025-11-08 05:00:53,622] DEBUG [numba.cuda.cudadrv.driver:325] call driver api: cuPointerGetAttribute\n",
      "[2025-11-08 05:00:53,623] DEBUG [numba.cuda.cudadrv.driver:325] call driver api: cuCtxGetCurrent\n",
      "[2025-11-08 05:00:53,623] DEBUG [numba.cuda.cudadrv.driver:325] call driver api: cuCtxGetDevice\n",
      "[2025-11-08 05:00:53,623] DEBUG [numba.cuda.cudadrv.driver:325] call driver api: cuPointerGetAttribute\n",
      "[2025-11-08 05:00:53,624] DEBUG [numba.cuda.cudadrv.driver:325] call driver api: cuCtxGetCurrent\n",
      "[2025-11-08 05:00:53,624] DEBUG [numba.cuda.cudadrv.driver:325] call driver api: cuCtxGetDevice\n",
      "[2025-11-08 05:00:53,624] DEBUG [numba.cuda.cudadrv.driver:325] call driver api: cuLaunchKernel\n",
      "[2025-11-08 05:00:53,627] DEBUG [numba.cuda.cudadrv.driver:325] call driver api: cuCtxGetCurrent\n",
      "[2025-11-08 05:00:53,627] DEBUG [numba.cuda.cudadrv.driver:325] call driver api: cuCtxGetDevice\n",
      "[2025-11-08 05:00:53,627] DEBUG [numba.cuda.cudadrv.driver:325] call driver api: cuPointerGetAttribute\n",
      "[2025-11-08 05:00:53,628] DEBUG [numba.cuda.cudadrv.driver:325] call driver api: cuCtxGetCurrent\n",
      "[2025-11-08 05:00:53,628] DEBUG [numba.cuda.cudadrv.driver:325] call driver api: cuCtxGetDevice\n",
      "[2025-11-08 05:00:53,629] DEBUG [numba.cuda.cudadrv.driver:325] call driver api: cuPointerGetAttribute\n",
      "[2025-11-08 05:00:53,629] DEBUG [numba.cuda.cudadrv.driver:325] call driver api: cuCtxGetCurrent\n",
      "[2025-11-08 05:00:53,630] DEBUG [numba.cuda.cudadrv.driver:325] call driver api: cuCtxGetDevice\n",
      "[2025-11-08 05:00:53,630] DEBUG [numba.cuda.cudadrv.driver:325] call driver api: cuLaunchKernel\n",
      "[2025-11-08 05:00:53,633] DEBUG [numba.cuda.cudadrv.driver:325] call driver api: cuCtxGetCurrent\n",
      "[2025-11-08 05:00:53,633] DEBUG [numba.cuda.cudadrv.driver:325] call driver api: cuCtxGetDevice\n",
      "[2025-11-08 05:00:53,634] DEBUG [numba.cuda.cudadrv.driver:325] call driver api: cuPointerGetAttribute\n",
      "[2025-11-08 05:00:53,634] DEBUG [numba.cuda.cudadrv.driver:325] call driver api: cuCtxGetCurrent\n",
      "[2025-11-08 05:00:53,635] DEBUG [numba.cuda.cudadrv.driver:325] call driver api: cuCtxGetDevice\n",
      "[2025-11-08 05:00:53,635] DEBUG [numba.cuda.cudadrv.driver:325] call driver api: cuPointerGetAttribute\n",
      "[2025-11-08 05:00:53,636] DEBUG [numba.cuda.cudadrv.driver:325] call driver api: cuCtxGetCurrent\n",
      "[2025-11-08 05:00:53,636] DEBUG [numba.cuda.cudadrv.driver:325] call driver api: cuCtxGetDevice\n",
      "[2025-11-08 05:00:53,637] DEBUG [numba.cuda.cudadrv.driver:325] call driver api: cuLaunchKernel\n",
      "[2025-11-08 05:00:53,641] DEBUG [numba.cuda.cudadrv.driver:325] call driver api: cuCtxGetCurrent\n",
      "[2025-11-08 05:00:53,641] DEBUG [numba.cuda.cudadrv.driver:325] call driver api: cuCtxGetDevice\n",
      "[2025-11-08 05:00:53,641] DEBUG [numba.cuda.cudadrv.driver:325] call driver api: cuPointerGetAttribute\n",
      "[2025-11-08 05:00:53,642] DEBUG [numba.cuda.cudadrv.driver:325] call driver api: cuCtxGetCurrent\n",
      "[2025-11-08 05:00:53,643] DEBUG [numba.cuda.cudadrv.driver:325] call driver api: cuCtxGetDevice\n",
      "[2025-11-08 05:00:53,643] DEBUG [numba.cuda.cudadrv.driver:325] call driver api: cuPointerGetAttribute\n",
      "[2025-11-08 05:00:53,643] DEBUG [numba.cuda.cudadrv.driver:325] call driver api: cuCtxGetCurrent\n",
      "[2025-11-08 05:00:53,644] DEBUG [numba.cuda.cudadrv.driver:325] call driver api: cuCtxGetDevice\n",
      "[2025-11-08 05:00:53,645] DEBUG [numba.cuda.cudadrv.driver:325] call driver api: cuLaunchKernel\n",
      "[2025-11-08 05:00:53,648] DEBUG [numba.cuda.cudadrv.driver:325] call driver api: cuCtxGetCurrent\n",
      "[2025-11-08 05:00:53,648] DEBUG [numba.cuda.cudadrv.driver:325] call driver api: cuCtxGetDevice\n",
      "[2025-11-08 05:00:53,649] DEBUG [numba.cuda.cudadrv.driver:325] call driver api: cuPointerGetAttribute\n",
      "[2025-11-08 05:00:53,650] DEBUG [numba.cuda.cudadrv.driver:325] call driver api: cuCtxGetCurrent\n",
      "[2025-11-08 05:00:53,650] DEBUG [numba.cuda.cudadrv.driver:325] call driver api: cuCtxGetDevice\n",
      "[2025-11-08 05:00:53,651] DEBUG [numba.cuda.cudadrv.driver:325] call driver api: cuPointerGetAttribute\n",
      "[2025-11-08 05:00:53,651] DEBUG [numba.cuda.cudadrv.driver:325] call driver api: cuCtxGetCurrent\n",
      "[2025-11-08 05:00:53,652] DEBUG [numba.cuda.cudadrv.driver:325] call driver api: cuCtxGetDevice\n",
      "[2025-11-08 05:00:53,653] DEBUG [numba.cuda.cudadrv.driver:325] call driver api: cuLaunchKernel\n",
      "[2025-11-08 05:00:53,658] DEBUG [numba.cuda.cudadrv.driver:325] call driver api: cuCtxGetCurrent\n",
      "[2025-11-08 05:00:53,658] DEBUG [numba.cuda.cudadrv.driver:325] call driver api: cuCtxGetDevice\n",
      "[2025-11-08 05:00:53,659] DEBUG [numba.cuda.cudadrv.driver:325] call driver api: cuPointerGetAttribute\n",
      "[2025-11-08 05:00:53,660] DEBUG [numba.cuda.cudadrv.driver:325] call driver api: cuCtxGetCurrent\n",
      "[2025-11-08 05:00:53,660] DEBUG [numba.cuda.cudadrv.driver:325] call driver api: cuCtxGetDevice\n",
      "[2025-11-08 05:00:53,661] DEBUG [numba.cuda.cudadrv.driver:325] call driver api: cuPointerGetAttribute\n",
      "[2025-11-08 05:00:53,662] DEBUG [numba.cuda.cudadrv.driver:325] call driver api: cuCtxGetCurrent\n",
      "[2025-11-08 05:00:53,662] DEBUG [numba.cuda.cudadrv.driver:325] call driver api: cuCtxGetDevice\n",
      "[2025-11-08 05:00:53,663] DEBUG [numba.cuda.cudadrv.driver:325] call driver api: cuLaunchKernel\n",
      "[2025-11-08 05:00:53,667] DEBUG [numba.cuda.cudadrv.driver:325] call driver api: cuCtxGetCurrent\n",
      "[2025-11-08 05:00:53,668] DEBUG [numba.cuda.cudadrv.driver:325] call driver api: cuCtxGetDevice\n",
      "[2025-11-08 05:00:53,668] DEBUG [numba.cuda.cudadrv.driver:325] call driver api: cuPointerGetAttribute\n",
      "[2025-11-08 05:00:53,670] DEBUG [numba.cuda.cudadrv.driver:325] call driver api: cuCtxGetCurrent\n",
      "[2025-11-08 05:00:53,670] DEBUG [numba.cuda.cudadrv.driver:325] call driver api: cuCtxGetDevice\n",
      "[2025-11-08 05:00:53,671] DEBUG [numba.cuda.cudadrv.driver:325] call driver api: cuPointerGetAttribute\n",
      "[2025-11-08 05:00:53,672] DEBUG [numba.cuda.cudadrv.driver:325] call driver api: cuCtxGetCurrent\n",
      "[2025-11-08 05:00:53,672] DEBUG [numba.cuda.cudadrv.driver:325] call driver api: cuCtxGetDevice\n",
      "[2025-11-08 05:00:53,673] DEBUG [numba.cuda.cudadrv.driver:325] call driver api: cuLaunchKernel\n",
      "[2025-11-08 05:00:53,677] DEBUG [numba.cuda.cudadrv.driver:325] call driver api: cuCtxGetCurrent\n",
      "[2025-11-08 05:00:53,677] DEBUG [numba.cuda.cudadrv.driver:325] call driver api: cuCtxGetDevice\n",
      "[2025-11-08 05:00:53,678] DEBUG [numba.cuda.cudadrv.driver:325] call driver api: cuPointerGetAttribute\n",
      "[2025-11-08 05:00:53,679] DEBUG [numba.cuda.cudadrv.driver:325] call driver api: cuCtxGetCurrent\n",
      "[2025-11-08 05:00:53,680] DEBUG [numba.cuda.cudadrv.driver:325] call driver api: cuCtxGetDevice\n",
      "[2025-11-08 05:00:53,680] DEBUG [numba.cuda.cudadrv.driver:325] call driver api: cuPointerGetAttribute\n",
      "[2025-11-08 05:00:53,681] DEBUG [numba.cuda.cudadrv.driver:325] call driver api: cuCtxGetCurrent\n",
      "[2025-11-08 05:00:53,681] DEBUG [numba.cuda.cudadrv.driver:325] call driver api: cuCtxGetDevice\n",
      "[2025-11-08 05:00:53,682] DEBUG [numba.cuda.cudadrv.driver:325] call driver api: cuLaunchKernel\n",
      "[2025-11-08 05:00:53,686] DEBUG [numba.cuda.cudadrv.driver:325] call driver api: cuCtxGetCurrent\n",
      "[2025-11-08 05:00:53,687] DEBUG [numba.cuda.cudadrv.driver:325] call driver api: cuCtxGetDevice\n",
      "[2025-11-08 05:00:53,687] DEBUG [numba.cuda.cudadrv.driver:325] call driver api: cuPointerGetAttribute\n",
      "[2025-11-08 05:00:53,689] DEBUG [numba.cuda.cudadrv.driver:325] call driver api: cuCtxGetCurrent\n",
      "[2025-11-08 05:00:53,689] DEBUG [numba.cuda.cudadrv.driver:325] call driver api: cuCtxGetDevice\n",
      "[2025-11-08 05:00:53,690] DEBUG [numba.cuda.cudadrv.driver:325] call driver api: cuPointerGetAttribute\n",
      "[2025-11-08 05:00:53,690] DEBUG [numba.cuda.cudadrv.driver:325] call driver api: cuCtxGetCurrent\n",
      "[2025-11-08 05:00:53,691] DEBUG [numba.cuda.cudadrv.driver:325] call driver api: cuCtxGetDevice\n",
      "[2025-11-08 05:00:53,692] DEBUG [numba.cuda.cudadrv.driver:325] call driver api: cuLaunchKernel\n",
      "[2025-11-08 05:00:53,698] DEBUG [numba.cuda.cudadrv.driver:325] call driver api: cuCtxGetCurrent\n",
      "[2025-11-08 05:00:53,699] DEBUG [numba.cuda.cudadrv.driver:325] call driver api: cuCtxGetDevice\n",
      "[2025-11-08 05:00:53,700] DEBUG [numba.cuda.cudadrv.driver:325] call driver api: cuPointerGetAttribute\n",
      "[2025-11-08 05:00:53,701] DEBUG [numba.cuda.cudadrv.driver:325] call driver api: cuCtxGetCurrent\n",
      "[2025-11-08 05:00:53,702] DEBUG [numba.cuda.cudadrv.driver:325] call driver api: cuCtxGetDevice\n",
      "[2025-11-08 05:00:53,702] DEBUG [numba.cuda.cudadrv.driver:325] call driver api: cuPointerGetAttribute\n",
      "[2025-11-08 05:00:53,704] DEBUG [numba.cuda.cudadrv.driver:325] call driver api: cuCtxGetCurrent\n",
      "[2025-11-08 05:00:53,704] DEBUG [numba.cuda.cudadrv.driver:325] call driver api: cuCtxGetDevice\n",
      "[2025-11-08 05:00:53,705] DEBUG [numba.cuda.cudadrv.driver:325] call driver api: cuLaunchKernel\n",
      "[2025-11-08 05:00:53,708] DEBUG [numba.cuda.cudadrv.driver:325] call driver api: cuCtxGetCurrent\n",
      "[2025-11-08 05:00:53,708] DEBUG [numba.cuda.cudadrv.driver:325] call driver api: cuCtxGetDevice\n",
      "[2025-11-08 05:00:53,709] DEBUG [numba.cuda.cudadrv.driver:325] call driver api: cuPointerGetAttribute\n",
      "[2025-11-08 05:00:53,711] DEBUG [numba.cuda.cudadrv.driver:325] call driver api: cuCtxGetCurrent\n",
      "[2025-11-08 05:00:53,711] DEBUG [numba.cuda.cudadrv.driver:325] call driver api: cuCtxGetDevice\n",
      "[2025-11-08 05:00:53,712] DEBUG [numba.cuda.cudadrv.driver:325] call driver api: cuPointerGetAttribute\n",
      "[2025-11-08 05:00:53,713] DEBUG [numba.cuda.cudadrv.driver:325] call driver api: cuCtxGetCurrent\n",
      "[2025-11-08 05:00:53,713] DEBUG [numba.cuda.cudadrv.driver:325] call driver api: cuCtxGetDevice\n",
      "[2025-11-08 05:00:53,714] DEBUG [numba.cuda.cudadrv.driver:325] call driver api: cuLaunchKernel\n",
      "[2025-11-08 05:00:53,718] DEBUG [numba.cuda.cudadrv.driver:325] call driver api: cuCtxGetCurrent\n",
      "[2025-11-08 05:00:53,718] DEBUG [numba.cuda.cudadrv.driver:325] call driver api: cuCtxGetDevice\n",
      "[2025-11-08 05:00:53,719] DEBUG [numba.cuda.cudadrv.driver:325] call driver api: cuPointerGetAttribute\n",
      "[2025-11-08 05:00:53,720] DEBUG [numba.cuda.cudadrv.driver:325] call driver api: cuCtxGetCurrent\n",
      "[2025-11-08 05:00:53,721] DEBUG [numba.cuda.cudadrv.driver:325] call driver api: cuCtxGetDevice\n",
      "[2025-11-08 05:00:53,721] DEBUG [numba.cuda.cudadrv.driver:325] call driver api: cuPointerGetAttribute\n",
      "[2025-11-08 05:00:53,722] DEBUG [numba.cuda.cudadrv.driver:325] call driver api: cuCtxGetCurrent\n",
      "[2025-11-08 05:00:53,723] DEBUG [numba.cuda.cudadrv.driver:325] call driver api: cuCtxGetDevice\n",
      "[2025-11-08 05:00:53,723] DEBUG [numba.cuda.cudadrv.driver:325] call driver api: cuLaunchKernel\n",
      "[2025-11-08 05:00:53,726] DEBUG [numba.cuda.cudadrv.driver:325] call driver api: cuCtxGetCurrent\n",
      "[2025-11-08 05:00:53,726] DEBUG [numba.cuda.cudadrv.driver:325] call driver api: cuCtxGetDevice\n",
      "[2025-11-08 05:00:53,727] DEBUG [numba.cuda.cudadrv.driver:325] call driver api: cuPointerGetAttribute\n",
      "[2025-11-08 05:00:53,728] DEBUG [numba.cuda.cudadrv.driver:325] call driver api: cuCtxGetCurrent\n",
      "[2025-11-08 05:00:53,729] DEBUG [numba.cuda.cudadrv.driver:325] call driver api: cuCtxGetDevice\n",
      "[2025-11-08 05:00:53,729] DEBUG [numba.cuda.cudadrv.driver:325] call driver api: cuPointerGetAttribute\n",
      "[2025-11-08 05:00:53,730] DEBUG [numba.cuda.cudadrv.driver:325] call driver api: cuCtxGetCurrent\n",
      "[2025-11-08 05:00:53,731] DEBUG [numba.cuda.cudadrv.driver:325] call driver api: cuCtxGetDevice\n",
      "[2025-11-08 05:00:53,732] DEBUG [numba.cuda.cudadrv.driver:325] call driver api: cuLaunchKernel\n",
      "[2025-11-08 05:00:53,734] DEBUG [numba.cuda.cudadrv.driver:325] call driver api: cuCtxGetCurrent\n",
      "[2025-11-08 05:00:53,735] DEBUG [numba.cuda.cudadrv.driver:325] call driver api: cuCtxGetDevice\n",
      "[2025-11-08 05:00:53,735] DEBUG [numba.cuda.cudadrv.driver:325] call driver api: cuPointerGetAttribute\n",
      "[2025-11-08 05:00:53,736] DEBUG [numba.cuda.cudadrv.driver:325] call driver api: cuCtxGetCurrent\n",
      "[2025-11-08 05:00:53,737] DEBUG [numba.cuda.cudadrv.driver:325] call driver api: cuCtxGetDevice\n",
      "[2025-11-08 05:00:53,738] DEBUG [numba.cuda.cudadrv.driver:325] call driver api: cuPointerGetAttribute\n",
      "[2025-11-08 05:00:53,739] DEBUG [numba.cuda.cudadrv.driver:325] call driver api: cuCtxGetCurrent\n",
      "[2025-11-08 05:00:53,739] DEBUG [numba.cuda.cudadrv.driver:325] call driver api: cuCtxGetDevice\n",
      "[2025-11-08 05:00:53,740] DEBUG [numba.cuda.cudadrv.driver:325] call driver api: cuLaunchKernel\n",
      "[2025-11-08 05:00:53,742] DEBUG [numba.cuda.cudadrv.driver:325] call driver api: cuCtxGetCurrent\n",
      "[2025-11-08 05:00:53,742] DEBUG [numba.cuda.cudadrv.driver:325] call driver api: cuCtxGetDevice\n",
      "[2025-11-08 05:00:53,743] DEBUG [numba.cuda.cudadrv.driver:325] call driver api: cuPointerGetAttribute\n",
      "[2025-11-08 05:00:53,744] DEBUG [numba.cuda.cudadrv.driver:325] call driver api: cuCtxGetCurrent\n",
      "[2025-11-08 05:00:53,744] DEBUG [numba.cuda.cudadrv.driver:325] call driver api: cuCtxGetDevice\n",
      "[2025-11-08 05:00:53,745] DEBUG [numba.cuda.cudadrv.driver:325] call driver api: cuPointerGetAttribute\n",
      "[2025-11-08 05:00:53,746] DEBUG [numba.cuda.cudadrv.driver:325] call driver api: cuCtxGetCurrent\n",
      "[2025-11-08 05:00:53,746] DEBUG [numba.cuda.cudadrv.driver:325] call driver api: cuCtxGetDevice\n",
      "[2025-11-08 05:00:53,747] DEBUG [numba.cuda.cudadrv.driver:325] call driver api: cuLaunchKernel\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "s_img_hidden_states shape: torch.Size([256, 896])\n",
      "t_img_hs shape: torch.Size([260, 896])\n",
      "s_img_hidden_states shape: torch.Size([256, 896])\n",
      "t_img_hs shape: torch.Size([260, 896])\n",
      "s_img_hidden_states shape: torch.Size([256, 896])\n",
      "t_img_hs shape: torch.Size([260, 896])\n",
      "s_img_hidden_states shape: torch.Size([256, 896])\n",
      "t_img_hs shape: torch.Size([260, 896])\n",
      "s_img_hidden_states shape: torch.Size([256, 896])\n",
      "t_img_hs shape: torch.Size([260, 896])\n",
      "s_img_hidden_states shape: torch.Size([256, 896])\n",
      "t_img_hs shape: torch.Size([260, 896])\n",
      "s_img_hidden_states shape: torch.Size([256, 896])\n",
      "t_img_hs shape: torch.Size([260, 896])\n",
      "s_img_hidden_states shape: torch.Size([256, 896])\n",
      "t_img_hs shape: torch.Size([260, 896])\n",
      "s_img_hidden_states shape: torch.Size([256, 896])\n",
      "t_img_hs shape: torch.Size([260, 896])\n",
      "s_img_hidden_states shape: torch.Size([256, 896])\n",
      "t_img_hs shape: torch.Size([260, 896])\n",
      "s_img_hidden_states shape: torch.Size([256, 896])\n",
      "t_img_hs shape: torch.Size([260, 896])\n",
      "s_img_hidden_states shape: torch.Size([256, 896])\n",
      "t_img_hs shape: torch.Size([260, 896])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'total_loss': tensor(nan, device='cuda:0', grad_fn=<AddBackward0>),\n",
       " 'contrastive_loss': tensor(0., device='cuda:0'),\n",
       " 'rkd_loss': tensor(nan, device='cuda:0', grad_fn=<AddBackward0>),\n",
       " 'simple_kd_loss': tensor(0.0022, device='cuda:0', grad_fn=<DivBackward0>),\n",
       " 'intra_rkd_loss': tensor(0.0345, device='cuda:0', grad_fn=<DivBackward0>),\n",
       " 'cross_modal_kd_loss': tensor(497.8580, device='cuda:0', grad_fn=<AddBackward0>),\n",
       " 'ot_loss': tensor(0., device='cuda:0', grad_fn=<DivBackward0>),\n",
       " 'img_align_loss': tensor(0.3857, device='cuda:0', grad_fn=<DivBackward0>)}"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with torch.autocast(enabled=True, dtype=torch.bfloat16, device_type=\"cuda\"):\n",
    "    loss = criterion.forward(None, None)\n",
    "\n",
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "78130ff7",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"./test/output_t_qry.pkl\", 'rb') as file:\n",
    "    # Use pickle.load() to read the byte stream and deserialize the object\n",
    "    loaded_object = pickle.load(file)\n",
    "    # load to cuda\n",
    "    loaded_object = {k: v.to(\"cuda\") if isinstance(v, torch.Tensor) else v for k, v in loaded_object.items()}\n",
    "    t_qry_reps, t_qry_hidden_states, t_qry_img_feats, t_qry_layers_embeds, t_qry_attention, t_qry_input_data = \\\n",
    "                                                                                loaded_object.values()\n",
    "    t_pos_reps, t_pos_hidden_states, t_pos_img_feats, t_pos_layers_embeds, t_pos_attention, t_pos_input_data = \\\n",
    "                                                                                loaded_object.values()\n",
    "    \n",
    "with open(\"./test/output_s_qry.pkl\", 'rb') as file:\n",
    "    # Use pickle.load() to read the byte stream and deserialize the object\n",
    "    loaded_object = pickle.load(file)\n",
    "    loaded_object = {k: v.to(\"cuda\") if isinstance(v, torch.Tensor) else v for k, v in loaded_object.items()}\n",
    "\n",
    "    s_qry_reps, s_qry_hidden_states, s_qry_img_feats, s_qry_layers_embeds, s_qry_attention, s_qry_input_data = \\\n",
    "                                                                loaded_object.values()\n",
    "    s_pos_reps, s_pos_hidden_states, s_pos_img_feats, s_pos_layers_embeds, s_pos_attention, s_pos_input_data = \\\n",
    "                                                                loaded_object.values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d9159d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pairwise_distance(x):\n",
    "        norm = (x**2).sum(dim=1, keepdim=True)\n",
    "        dist = norm + norm.t() - 2.0 * torch.mm(x, x.t())\n",
    "        return dist\n",
    "    \n",
    "def compute_distance_loss(student_qry, student_pos, teacher_qry, teacher_pos):\n",
    "    \n",
    "    num_student_layers = student_qry.size(0)\n",
    "    num_teacher_layers = teacher_qry.size(0)\n",
    "    scale = num_teacher_layers // num_student_layers\n",
    "\n",
    "    student_repr = torch.cat([student_qry, student_pos], dim=1)\n",
    "    teacher_repr = torch.cat([teacher_qry, teacher_pos], dim=1)[\n",
    "        torch.tensor([i * scale for i in range(num_student_layers)], device=teacher_qry.device)\n",
    "    ]\n",
    "\n",
    "    dist_student = pairwise_distance(student_repr)\n",
    "    dist_teacher = pairwise_distance(teacher_repr)\n",
    "    \n",
    "    mask = torch.triu(torch.ones_like(dist_student), diagonal=1).bool()\n",
    "    dist_student = dist_student[mask]\n",
    "    dist_teacher = dist_teacher[mask]\n",
    "    \n",
    "    mean_td = dist_teacher.mean().detach() + 1e-8\n",
    "    mean_sd = dist_student.mean().detach() + 1e-8\n",
    "    \n",
    "    dist_student = dist_student / mean_sd\n",
    "    dist_teacher = dist_teacher / mean_td\n",
    "    \n",
    "    diff = dist_student - dist_teacher\n",
    "    abs_diff = torch.abs(diff)\n",
    "    quadratic = 0.5 * (abs_diff ** 2)\n",
    "    linear = abs_diff - 0.5\n",
    "    \n",
    "    loss = torch.where(abs_diff < 1.0, quadratic, linear)\n",
    "    loss = loss.mean()\n",
    "    return loss\n",
    "\n",
    "def angle_potentials(x):\n",
    "    x = torch.clamp(x, min=-1e10, max=1e10)\n",
    "\n",
    "    n = x.size(0)\n",
    "    diffs = x.unsqueeze(0) - x.unsqueeze(1)\n",
    "    norms = torch.norm(diffs, dim=-1, keepdim=True) + 1e-8\n",
    "\n",
    "    bfloat16_max_safe = 1e38 \n",
    "    \n",
    "    safe_norms = torch.where(torch.isinf(norms), \n",
    "                             torch.tensor(bfloat16_max_safe, dtype=x.dtype, device=x.device), \n",
    "                             norms)\n",
    "    e = diffs / safe_norms\n",
    "    \n",
    "    cos_angles = torch.einsum('ijd,kjd->ijk', e, e)\n",
    "    return cos_angles\n",
    "\n",
    "def compute_angle_loss(student_qry, student_pos, teacher_qry, teacher_pos):\n",
    "    \n",
    "    num_student_layers = student_qry.size(0)\n",
    "    num_teacher_layers = teacher_qry.size(0)\n",
    "    scale = num_teacher_layers // num_student_layers\n",
    "\n",
    "    student_repr = torch.cat([student_qry, student_pos], dim=1)\n",
    "    teacher_repr = torch.cat([teacher_qry, teacher_pos], dim=1)[\n",
    "        torch.tensor([i * scale for i in range(num_student_layers)], device=teacher_qry.device)\n",
    "    ]\n",
    "\n",
    "    psi_student = angle_potentials(student_repr)\n",
    "    psi_teacher = angle_potentials(teacher_repr)\n",
    "    \n",
    "    n = psi_student.size(0)\n",
    "    mask = torch.ones((n, n, n), dtype=torch.bool, device=psi_student.device)\n",
    "    idx = torch.arange(n, device=psi_student.device)\n",
    "    mask[idx, idx, :] = 0\n",
    "    mask[idx, :, idx] = 0\n",
    "    mask[:, idx, idx] = 0\n",
    "    \n",
    "    psi_teacher = psi_teacher[mask]\n",
    "    psi_student = psi_student[mask]\n",
    "    \n",
    "    diff = psi_student - psi_teacher\n",
    "    abs_diff = torch.abs(diff)\n",
    "    quadratic = 0.5 * (abs_diff ** 2)\n",
    "    linear = abs_diff - 0.5\n",
    "    loss = torch.where(abs_diff < 1.0, quadratic, linear)\n",
    "    loss = loss.mean()\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "c42d8a1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Projector t2s_img created with structure: Sequential(\n",
      "  (0): Linear(in_features=1536, out_features=896, bias=True)\n",
      ")\n",
      "Projector t2s_txt created with structure: Sequential(\n",
      "  (0): Linear(in_features=1536, out_features=896, bias=True)\n",
      ")\n",
      "Projectors set.\n"
     ]
    }
   ],
   "source": [
    "distiller  = Distiller(model_args, training_args, \"cuda\")\n",
    "\n",
    "def compute_ot(s_hidden_states, s_attn, t_hidden_states, t_attn):\n",
    "    \n",
    "    loss = 0.0\n",
    "    num_student_layers = len(s_hidden_states)\n",
    "    num_teacher_layers = len(t_hidden_states)\n",
    "    scale = num_teacher_layers // num_student_layers\n",
    "    start_layer = num_student_layers - 3\n",
    "\n",
    "    for l in range(start_layer, num_student_layers):\n",
    "        s_dist = F.softmax(s_attn[l - 1].mean(dim=1)[:, -1], dim=-1) # (b, n)\n",
    "        t_dist = F.softmax(t_attn[l - 1].mean(dim=1)[:, -1], dim=-1) # (b, m)\n",
    "\n",
    "        s_hidden_state = s_hidden_states[l] # (b, n, emb_dim)\n",
    "        proj_t_hidden_state = distiller.t2s[l - start_layer](t_hidden_states[scale * l]) # (b, m, emb_dim)\n",
    "\n",
    "        for b in range(s_dist.size(0)):\n",
    "            norm_s_hs = torch.norm(s_hidden_state[b], dim=-1, keepdim=True) + 1e-8\n",
    "            norm_t_hs = torch.norm(proj_t_hidden_state[b], dim=-1, keepdim=True) + 1e-8\n",
    "\n",
    "            cost_matrix = torch.cdist(norm_s_hs.unsqueeze(0), \n",
    "                                      norm_t_hs.unsqueeze(0)).squeeze(0)\n",
    "            cost_matrix /= cost_matrix.mean().item()\n",
    "\n",
    "            transport = sinkhorn(s_dist[b], t_dist[b], cost_matrix) \n",
    "            print(transport)\n",
    "            loss += torch.sum(transport * cost_matrix)\n",
    "\n",
    "            print(\"Cost mean:\", cost_matrix.mean().item())\n",
    "            print(\"s_dist sum:\", s_dist[b].sum().item())\n",
    "            print(\"t_dist sum:\", t_dist[b].sum().item())\n",
    "            print(\"Transport mean:\", transport.mean())\n",
    "            print(\"OT cost:\", torch.sum(transport * cost_matrix).item())\n",
    "    return loss / s_dist.size(0), cost_matrix\n",
    "\n",
    "epsilon = 1e-9\n",
    "stopThr = 1e-7\n",
    "sinkhorn_alpha = 0.1\n",
    "\n",
    "def sinkhorn(a, b, cost_matrix, reg=10, num_iters=100, eps=1e-9):\n",
    "    \"\"\"\n",
    "    a: (m,) or (m,1) torch tensor (source weights)\n",
    "    b: (n,) or (n,1) torch tensor (target weights)\n",
    "    cost_matrix: (m, n) torch tensor\n",
    "    reg: regularization (>=0) -- larger reg -> smoother K = exp(-C/reg)\n",
    "    num_iters: number of Sinkhorn iterations\n",
    "    \"\"\"\n",
    "    device = cost_matrix.device\n",
    "    # use float32 for numeric stability\n",
    "    dtype = torch.float32\n",
    "    a = a.detach().to(device=device, dtype=dtype).view(-1, 1)\n",
    "    b = b.detach().to(device=device, dtype=dtype).view(-1, 1)\n",
    "    C = cost_matrix.detach().to(device=device, dtype=dtype)\n",
    "\n",
    "    m, n = C.shape\n",
    "    if m == 0 or n == 0:\n",
    "        return torch.zeros((m, n), device=device, dtype=dtype)\n",
    "\n",
    "    # ensure shapes\n",
    "    if a.shape[0] != m:\n",
    "        a = torch.ones((m, 1), device=device, dtype=dtype) / m\n",
    "    if b.shape[0] != n:\n",
    "        b = torch.ones((n, 1), device=device, dtype=dtype) / n\n",
    "\n",
    "    suma = a.sum()\n",
    "    sumb = b.sum()\n",
    "    if suma <= eps or sumb <= eps:\n",
    "        a = torch.ones((m, 1), device=device, dtype=dtype) / m\n",
    "        b = torch.ones((n, 1), device=device, dtype=dtype) / n\n",
    "    else:\n",
    "        a = a / suma\n",
    "        b = b / sumb\n",
    "\n",
    "    K = torch.exp(-C / (reg + 1e-12))\n",
    "    K = torch.clamp(K, min=1e-10)\n",
    "\n",
    "    u = torch.ones((m, 1), device=device, dtype=dtype)\n",
    "    v = torch.ones((n, 1), device=device, dtype=dtype)\n",
    "\n",
    "    for i in range(num_iters):\n",
    "        u_prev = u.clone()\n",
    "        KTv = (K.t() @ u)  # shape (n,1)\n",
    "        v = b / (KTv + eps)\n",
    "        Kv = (K @ v)       # shape (m,1)\n",
    "        u = a / (Kv + eps)\n",
    "\n",
    "        err = torch.max(torch.abs(u - u_prev))\n",
    "        if err.item() < stopThr:\n",
    "            break\n",
    "\n",
    "    # transport plan\n",
    "    U = torch.diag_embed(u.squeeze())   # (m,m) diag(u)\n",
    "    V = torch.diag_embed(v.squeeze())   # (n,n) diag(v)\n",
    "    P = U @ K @ V                       # (m,n)\n",
    "    return P"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "42b55ea2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[2.1100e-05, 2.1100e-05, 2.1815e-05,  ..., 2.1100e-05, 2.2292e-05,\n",
      "         2.4676e-05],\n",
      "        [1.3292e-05, 1.3232e-05, 1.3828e-05,  ..., 1.3292e-05, 1.4067e-05,\n",
      "         1.5497e-05],\n",
      "        [1.3232e-05, 1.3232e-05, 1.3769e-05,  ..., 1.3232e-05, 1.4007e-05,\n",
      "         1.5497e-05],\n",
      "        ...,\n",
      "        [1.3292e-05, 1.3292e-05, 1.3769e-05,  ..., 1.3292e-05, 1.4007e-05,\n",
      "         1.5497e-05],\n",
      "        [1.3232e-05, 1.3232e-05, 1.3828e-05,  ..., 1.3292e-05, 1.4067e-05,\n",
      "         1.5497e-05],\n",
      "        [1.4186e-05, 1.4126e-05, 1.4663e-05,  ..., 1.4186e-05, 1.4901e-05,\n",
      "         1.6570e-05]], device='cuda:0', dtype=torch.bfloat16)\n",
      "Cost mean: 1.0\n",
      "s_dist sum: 0.9999999403953552\n",
      "t_dist sum: 1.0\n",
      "Transport mean: tensor(1.3113e-05, device='cuda:0', dtype=torch.bfloat16)\n",
      "OT cost: 1.0381078720092773\n",
      "tensor([[2.2411e-05, 2.2411e-05, 2.2173e-05,  ..., 2.2531e-05, 2.3246e-05,\n",
      "         2.6584e-05],\n",
      "        [1.3292e-05, 1.3232e-05, 1.3053e-05,  ..., 1.3292e-05, 1.3709e-05,\n",
      "         1.5616e-05],\n",
      "        [1.3113e-05, 1.3053e-05, 1.2934e-05,  ..., 1.3173e-05, 1.3590e-05,\n",
      "         1.5497e-05],\n",
      "        ...,\n",
      "        [1.3292e-05, 1.3232e-05, 1.3113e-05,  ..., 1.3351e-05, 1.3769e-05,\n",
      "         1.5736e-05],\n",
      "        [1.3292e-05, 1.3232e-05, 1.3113e-05,  ..., 1.3351e-05, 1.3769e-05,\n",
      "         1.5616e-05],\n",
      "        [1.3828e-05, 1.3769e-05, 1.3649e-05,  ..., 1.3888e-05, 1.4305e-05,\n",
      "         1.6332e-05]], device='cuda:0', dtype=torch.bfloat16)\n",
      "Cost mean: 1.0\n",
      "s_dist sum: 0.9999999403953552\n",
      "t_dist sum: 0.9999999403953552\n",
      "Transport mean: tensor(1.3113e-05, device='cuda:0', dtype=torch.bfloat16)\n",
      "OT cost: 1.0412834882736206\n",
      "tensor([[1.8597e-05, 1.8597e-05, 1.8716e-05,  ..., 1.8835e-05, 1.9431e-05,\n",
      "         1.9073e-05],\n",
      "        [1.3232e-05, 1.3292e-05, 1.3411e-05,  ..., 1.3471e-05, 1.3947e-05,\n",
      "         1.3649e-05],\n",
      "        [1.3173e-05, 1.3232e-05, 1.3351e-05,  ..., 1.3411e-05, 1.3888e-05,\n",
      "         1.3590e-05],\n",
      "        ...,\n",
      "        [1.3411e-05, 1.3471e-05, 1.3649e-05,  ..., 1.3649e-05, 1.4126e-05,\n",
      "         1.3828e-05],\n",
      "        [1.3471e-05, 1.3530e-05, 1.3649e-05,  ..., 1.3709e-05, 1.4186e-05,\n",
      "         1.3888e-05],\n",
      "        [1.4782e-05, 1.4842e-05, 1.4961e-05,  ..., 1.5020e-05, 1.5497e-05,\n",
      "         1.5199e-05]], device='cuda:0', dtype=torch.bfloat16)\n",
      "Cost mean: 1.0\n",
      "s_dist sum: 0.9999999403953552\n",
      "t_dist sum: 0.9999999403953552\n",
      "Transport mean: tensor(1.3113e-05, device='cuda:0', dtype=torch.bfloat16)\n",
      "OT cost: 1.0156306028366089\n",
      "tensor([[1.8835e-05, 1.8716e-05, 1.8477e-05,  ..., 1.8597e-05, 1.8835e-05,\n",
      "         1.8954e-05],\n",
      "        [1.3351e-05, 1.3351e-05, 1.3173e-05,  ..., 1.3351e-05, 1.3471e-05,\n",
      "         1.3530e-05],\n",
      "        [1.3292e-05, 1.3232e-05, 1.3113e-05,  ..., 1.3232e-05, 1.3411e-05,\n",
      "         1.3471e-05],\n",
      "        ...,\n",
      "        [1.3530e-05, 1.3530e-05, 1.3351e-05,  ..., 1.3530e-05, 1.3649e-05,\n",
      "         1.3709e-05],\n",
      "        [1.3530e-05, 1.3530e-05, 1.3351e-05,  ..., 1.3530e-05, 1.3649e-05,\n",
      "         1.3709e-05],\n",
      "        [1.4842e-05, 1.4722e-05, 1.4544e-05,  ..., 1.4722e-05, 1.4901e-05,\n",
      "         1.4961e-05]], device='cuda:0', dtype=torch.bfloat16)\n",
      "Cost mean: 1.0\n",
      "s_dist sum: 1.0\n",
      "t_dist sum: 0.9999998807907104\n",
      "Transport mean: tensor(1.3113e-05, device='cuda:0', dtype=torch.bfloat16)\n",
      "OT cost: 1.0148656368255615\n",
      "tensor([[1.3649e-05, 1.3590e-05, 1.3709e-05,  ..., 1.3769e-05, 1.4424e-05,\n",
      "         1.4603e-05],\n",
      "        [1.3471e-05, 1.3411e-05, 1.3530e-05,  ..., 1.3590e-05, 1.4186e-05,\n",
      "         1.4424e-05],\n",
      "        [1.3351e-05, 1.3292e-05, 1.3351e-05,  ..., 1.3471e-05, 1.4007e-05,\n",
      "         1.4305e-05],\n",
      "        ...,\n",
      "        [1.3888e-05, 1.3828e-05, 1.3888e-05,  ..., 1.3947e-05, 1.4544e-05,\n",
      "         1.4782e-05],\n",
      "        [1.4067e-05, 1.4007e-05, 1.4126e-05,  ..., 1.4246e-05, 1.4901e-05,\n",
      "         1.5199e-05],\n",
      "        [1.5974e-05, 1.5855e-05, 1.6093e-05,  ..., 1.6212e-05, 1.6928e-05,\n",
      "         1.7166e-05]], device='cuda:0', dtype=torch.bfloat16)\n",
      "Cost mean: 0.9999999403953552\n",
      "s_dist sum: 1.0\n",
      "t_dist sum: 0.9999999403953552\n",
      "Transport mean: tensor(1.3113e-05, device='cuda:0', dtype=torch.bfloat16)\n",
      "OT cost: 0.9993240833282471\n",
      "tensor([[1.3411e-05, 1.3292e-05, 1.3351e-05,  ..., 1.3590e-05, 1.3709e-05,\n",
      "         1.4365e-05],\n",
      "        [1.3232e-05, 1.3113e-05, 1.3173e-05,  ..., 1.3411e-05, 1.3590e-05,\n",
      "         1.4186e-05],\n",
      "        [1.3232e-05, 1.3113e-05, 1.3173e-05,  ..., 1.3471e-05, 1.3590e-05,\n",
      "         1.4246e-05],\n",
      "        ...,\n",
      "        [1.3769e-05, 1.3649e-05, 1.3709e-05,  ..., 1.3947e-05, 1.4126e-05,\n",
      "         1.4782e-05],\n",
      "        [1.3769e-05, 1.3649e-05, 1.3709e-05,  ..., 1.3947e-05, 1.4126e-05,\n",
      "         1.4842e-05],\n",
      "        [1.6570e-05, 1.6451e-05, 1.6570e-05,  ..., 1.6809e-05, 1.7047e-05,\n",
      "         1.7881e-05]], device='cuda:0', dtype=torch.bfloat16)\n",
      "Cost mean: 1.0\n",
      "s_dist sum: 1.0\n",
      "t_dist sum: 1.0\n",
      "Transport mean: tensor(1.3113e-05, device='cuda:0', dtype=torch.bfloat16)\n",
      "OT cost: 0.9992185831069946\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(tensor(3.0542, device='cuda:0', grad_fn=<DivBackward0>),\n",
       " tensor([[0.7022, 0.7447, 0.9193,  ..., 0.8969, 0.9255, 0.9026],\n",
       "         [0.9866, 1.0291, 1.2037,  ..., 1.1813, 1.2100, 1.1871],\n",
       "         [0.9766, 1.0191, 1.1937,  ..., 1.1713, 1.1999, 1.1770],\n",
       "         ...,\n",
       "         [1.0242, 1.0667, 1.2413,  ..., 1.2189, 1.2476, 1.2247],\n",
       "         [0.7187, 0.7611, 0.9358,  ..., 0.9134, 0.9420, 0.9191],\n",
       "         [1.3639, 1.4064, 1.5810,  ..., 1.5586, 1.5873, 1.5644]],\n",
       "        device='cuda:0', grad_fn=<AsStridedBackward0>))"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with torch.autocast(enabled=True, dtype=torch.bfloat16, device_type=\"cuda\"):\n",
    "    x = compute_ot(s_qry_hidden_states, s_qry_attention,\n",
    "                t_qry_hidden_states, t_qry_attention)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "74869b45",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 12, 278, 278])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s_qry_hidden_states[0].size()\n",
    "t_qry_hidden_states[0].size()\n",
    "s_qry_attention[0].size()\n",
    "t_qry_attention[0].size()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "vlm2vec",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
