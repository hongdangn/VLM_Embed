{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1b50b07f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import sys\n",
    "from collections import OrderedDict\n",
    "from contextlib import contextmanager\n",
    "import time\n",
    "\n",
    "from src.arguments import ModelArguments, DataArguments, TrainingArguments\n",
    "from transformers import HfArgumentParser, AutoConfig\n",
    "\n",
    "from src.model.model import MMEBModel\n",
    "from src.data.dataset.mmeb_dataset import EvalDataset\n",
    "from src.data.collator.eval_collator import EvalCollator\n",
    "from torch.utils.data import DataLoader\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import pickle\n",
    "import os\n",
    "from datasets import load_dataset\n",
    "from evaluation.mmeb_baselines.eval_utils import get_pred\n",
    "from src.utils import print_rank\n",
    "from src.model.processor import get_backbone_name, load_processor, COLPALI\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "import shutil "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "361f6af5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2025-11-08 10:31:05,795] DEBUG [urllib3.connectionpool:544] https://huggingface.co:443 \"HEAD /apple/FastVLM-0.5B/resolve/main/config.json HTTP/1.1\" 307 0\n",
      "[2025-11-08 10:31:05,852] DEBUG [urllib3.connectionpool:544] https://huggingface.co:443 \"HEAD /api/resolve-cache/models/apple/FastVLM-0.5B/16375720c2d673fa583e57e9876afde27549c7d0/config.json HTTP/1.1\" 200 0\n",
      "[2025-11-08 10:31:06,584] DEBUG [urllib3.connectionpool:544] https://huggingface.co:443 \"HEAD /apple/FastVLM-0.5B/resolve/main/llava_qwen.py HTTP/1.1\" 307 0\n",
      "[2025-11-08 10:31:06,640] DEBUG [urllib3.connectionpool:544] https://huggingface.co:443 \"HEAD /api/resolve-cache/models/apple/FastVLM-0.5B/16375720c2d673fa583e57e9876afde27549c7d0/llava_qwen.py HTTP/1.1\" 200 0\n",
      "[2025-11-08 10:31:06,977] DEBUG [urllib3.connectionpool:544] https://huggingface.co:443 \"HEAD /apple/FastVLM-0.5B/resolve/main/config.json HTTP/1.1\" 307 0\n",
      "[2025-11-08 10:31:07,045] DEBUG [urllib3.connectionpool:544] https://huggingface.co:443 \"HEAD /api/resolve-cache/models/apple/FastVLM-0.5B/16375720c2d673fa583e57e9876afde27549c7d0/config.json HTTP/1.1\" 200 0\n",
      "[2025-11-08 10:31:07,052] INFO [src.utils:12] model_backbone: llava_qwen2\n",
      "[2025-11-08 10:31:07,053] INFO [src.utils:21] Loading processor from: apple/FastVLM-0.5B\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected model type: llava_qwen2\n",
      "Determined model backbone: llava_qwen2\n",
      "Processor load here for LLAVA-QWEN2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2025-11-08 10:31:07,355] DEBUG [urllib3.connectionpool:544] https://huggingface.co:443 \"HEAD /apple/FastVLM-0.5B/resolve/main/tokenizer_config.json HTTP/1.1\" 307 0\n",
      "[2025-11-08 10:31:07,409] DEBUG [urllib3.connectionpool:544] https://huggingface.co:443 \"HEAD /api/resolve-cache/models/apple/FastVLM-0.5B/16375720c2d673fa583e57e9876afde27549c7d0/tokenizer_config.json HTTP/1.1\" 200 0\n",
      "[2025-11-08 10:31:07,722] DEBUG [urllib3.connectionpool:544] https://huggingface.co:443 \"GET /api/models/apple/FastVLM-0.5B/tree/main/additional_chat_templates?recursive=False&expand=False HTTP/1.1\" 404 64\n",
      "[2025-11-08 10:31:08,417] DEBUG [urllib3.connectionpool:544] https://huggingface.co:443 \"HEAD /apple/FastVLM-0.5B/resolve/main/config.json HTTP/1.1\" 307 0\n",
      "[2025-11-08 10:31:08,474] DEBUG [urllib3.connectionpool:544] https://huggingface.co:443 \"HEAD /api/resolve-cache/models/apple/FastVLM-0.5B/16375720c2d673fa583e57e9876afde27549c7d0/config.json HTTP/1.1\" 200 0\n",
      "[2025-11-08 10:31:08,775] DEBUG [urllib3.connectionpool:544] https://huggingface.co:443 \"HEAD /apple/FastVLM-0.5B/resolve/main/llava_qwen.py HTTP/1.1\" 307 0\n",
      "[2025-11-08 10:31:08,834] DEBUG [urllib3.connectionpool:544] https://huggingface.co:443 \"HEAD /api/resolve-cache/models/apple/FastVLM-0.5B/16375720c2d673fa583e57e9876afde27549c7d0/llava_qwen.py HTTP/1.1\" 200 0\n",
      "[2025-11-08 10:31:09,643] DEBUG [urllib3.connectionpool:544] https://huggingface.co:443 \"HEAD /apple/FastVLM-0.5B/resolve/main/config.json HTTP/1.1\" 307 0\n",
      "[2025-11-08 10:31:09,705] DEBUG [urllib3.connectionpool:544] https://huggingface.co:443 \"HEAD /api/resolve-cache/models/apple/FastVLM-0.5B/16375720c2d673fa583e57e9876afde27549c7d0/config.json HTTP/1.1\" 200 0\n",
      "[2025-11-08 10:31:09,711] INFO [src.utils:21] Loading backbone [llava_qwen2] from apple/FastVLM-0.5B\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected model type: llava_qwen2\n",
      "Determined model backbone: llava_qwen2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2025-11-08 10:31:10,706] DEBUG [urllib3.connectionpool:544] https://huggingface.co:443 \"HEAD /apple/FastVLM-0.5B/resolve/main/generation_config.json HTTP/1.1\" 307 0\n",
      "[2025-11-08 10:31:10,762] DEBUG [urllib3.connectionpool:544] https://huggingface.co:443 \"HEAD /api/resolve-cache/models/apple/FastVLM-0.5B/16375720c2d673fa583e57e9876afde27549c7d0/generation_config.json HTTP/1.1\" 200 0\n",
      "[2025-11-08 10:31:11,064] DEBUG [urllib3.connectionpool:544] https://huggingface.co:443 \"HEAD /apple/FastVLM-0.5B/resolve/main/custom_generate/generate.py HTTP/1.1\" 404 0\n"
     ]
    }
   ],
   "source": [
    "model_args = ModelArguments(\n",
    "    model_name=\"apple/FastVLM-0.5B\",\n",
    "    # model_name=\"raghavlite/B3_Qwen2_2B\",\n",
    "    pooling=\"eos\",\n",
    "    normalize=True\n",
    ")\n",
    "\n",
    "data_args = DataArguments(\n",
    "    encode_output_path=\"encode_output_path\",\n",
    "    dataset_name=\"TIGER-Lab/MMEB-eval\",\n",
    "    subset_name=[\"WebQA\"],\n",
    "    dataset_split=\"test\",\n",
    "    tgt_prefix_mod=True,\n",
    "    image_dir=\"../VLMEmbed/eval-data\",\n",
    ")\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    per_device_eval_batch_size=2,\n",
    ")\n",
    "\n",
    "os.makedirs(data_args.encode_output_path, exist_ok=True)\n",
    "\n",
    "hf_config = AutoConfig.from_pretrained(model_args.model_name, trust_remote_code=True)\n",
    "if not hasattr(model_args, \"model_backbone\") or not model_args.model_backbone:\n",
    "    model_backbone = get_backbone_name(hf_config=hf_config, model_type=model_args.model_type)\n",
    "    setattr(model_args, 'model_backbone', model_backbone)\n",
    "    setattr(training_args, 'model_backbone', model_backbone)\n",
    "print_rank(f'model_backbone: {model_args.model_backbone}')\n",
    "processor = load_processor(model_args, data_args)\n",
    "model = MMEBModel.build(model_args)\n",
    "model.eval()\n",
    "# model = model.to(training_args.device, dtype=torch.bfloat16)\n",
    "model = model.to(training_args.device)\n",
    "\n",
    "eval_collator = EvalCollator(\n",
    "    data_args=data_args,\n",
    "    model_args=model_args,\n",
    "    processor=processor,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ab23072b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2025-11-08 10:31:11,846] DEBUG [urllib3.connectionpool:544] https://huggingface.co:443 \"HEAD /dangnguyens1/sft-fastvlm-1e/resolve/main/processor_config.json HTTP/1.1\" 404 0\n",
      "[2025-11-08 10:31:12,156] DEBUG [urllib3.connectionpool:544] https://huggingface.co:443 \"HEAD /dangnguyens1/sft-fastvlm-1e/resolve/main/preprocessor_config.json HTTP/1.1\" 307 0\n",
      "[2025-11-08 10:31:12,492] DEBUG [urllib3.connectionpool:544] https://huggingface.co:443 \"HEAD /api/resolve-cache/models/dangnguyens1/sft-fastvlm-1e/eb3df95553c7a0a6cb1667bb715a3db89ba464f4/preprocessor_config.json HTTP/1.1\" 200 0\n",
      "[2025-11-08 10:31:12,496] DEBUG [filelock:331] Attempting to acquire lock 140179351359312 on /home/user2/.cache/huggingface/hub/.locks/models--dangnguyens1--sft-fastvlm-1e/12032f8aaa74bfa77b08688d5508981733fed85e.lock\n",
      "[2025-11-08 10:31:12,498] DEBUG [filelock:334] Lock 140179351359312 acquired on /home/user2/.cache/huggingface/hub/.locks/models--dangnguyens1--sft-fastvlm-1e/12032f8aaa74bfa77b08688d5508981733fed85e.lock\n",
      "[2025-11-08 10:31:12,893] DEBUG [urllib3.connectionpool:544] https://huggingface.co:443 \"GET /api/resolve-cache/models/dangnguyens1/sft-fastvlm-1e/eb3df95553c7a0a6cb1667bb715a3db89ba464f4/preprocessor_config.json HTTP/1.1\" 200 786\n",
      "[2025-11-08 10:31:12,900] DEBUG [filelock:364] Attempting to release lock 140179351359312 on /home/user2/.cache/huggingface/hub/.locks/models--dangnguyens1--sft-fastvlm-1e/12032f8aaa74bfa77b08688d5508981733fed85e.lock\n",
      "[2025-11-08 10:31:12,902] DEBUG [filelock:367] Lock 140179351359312 released on /home/user2/.cache/huggingface/hub/.locks/models--dangnguyens1--sft-fastvlm-1e/12032f8aaa74bfa77b08688d5508981733fed85e.lock\n",
      "[2025-11-08 10:31:13,206] DEBUG [urllib3.connectionpool:544] https://huggingface.co:443 \"GET /api/models/dangnguyens1/sft-fastvlm-1e/revision/main HTTP/1.1\" 200 3110\n",
      "Fetching 1 files: 100%|██████████| 1/1 [00:00<00:00, 3819.95it/s]\n",
      "[2025-11-08 10:31:13,593] DEBUG [urllib3.connectionpool:544] https://huggingface.co:443 \"GET /api/models/dangnguyens1/sft-fastvlm-1e/revision/main HTTP/1.1\" 200 3110\n",
      "Fetching 1 files: 100%|██████████| 1/1 [00:00<00:00, 4777.11it/s]\n",
      "[2025-11-08 10:31:13,923] DEBUG [urllib3.connectionpool:544] https://huggingface.co:443 \"HEAD /dangnguyens1/sft-fastvlm-1e/resolve/main/tokenizer_config.json HTTP/1.1\" 307 0\n",
      "[2025-11-08 10:31:14,267] DEBUG [urllib3.connectionpool:544] https://huggingface.co:443 \"HEAD /api/resolve-cache/models/dangnguyens1/sft-fastvlm-1e/eb3df95553c7a0a6cb1667bb715a3db89ba464f4/tokenizer_config.json HTTP/1.1\" 200 0\n",
      "[2025-11-08 10:31:14,271] DEBUG [filelock:331] Attempting to acquire lock 140180226151824 on /home/user2/.cache/huggingface/hub/.locks/models--dangnguyens1--sft-fastvlm-1e/8b0c601fb744f4e0d5a385090750f61cc901a47b.lock\n",
      "[2025-11-08 10:31:14,273] DEBUG [filelock:334] Lock 140180226151824 acquired on /home/user2/.cache/huggingface/hub/.locks/models--dangnguyens1--sft-fastvlm-1e/8b0c601fb744f4e0d5a385090750f61cc901a47b.lock\n",
      "[2025-11-08 10:31:14,275] DEBUG [filelock:364] Attempting to release lock 140180226151824 on /home/user2/.cache/huggingface/hub/.locks/models--dangnguyens1--sft-fastvlm-1e/8b0c601fb744f4e0d5a385090750f61cc901a47b.lock\n",
      "[2025-11-08 10:31:14,277] DEBUG [filelock:367] Lock 140180226151824 released on /home/user2/.cache/huggingface/hub/.locks/models--dangnguyens1--sft-fastvlm-1e/8b0c601fb744f4e0d5a385090750f61cc901a47b.lock\n",
      "[2025-11-08 10:31:14,603] DEBUG [urllib3.connectionpool:544] https://huggingface.co:443 \"GET /api/models/dangnguyens1/sft-fastvlm-1e/tree/main/additional_chat_templates?recursive=False&expand=False HTTP/1.1\" 404 64\n",
      "[2025-11-08 10:31:14,920] DEBUG [urllib3.connectionpool:544] https://huggingface.co:443 \"HEAD /dangnguyens1/sft-fastvlm-1e/resolve/main/vocab.json HTTP/1.1\" 307 0\n",
      "[2025-11-08 10:31:15,253] DEBUG [urllib3.connectionpool:544] https://huggingface.co:443 \"HEAD /api/resolve-cache/models/dangnguyens1/sft-fastvlm-1e/eb3df95553c7a0a6cb1667bb715a3db89ba464f4/vocab.json HTTP/1.1\" 200 0\n",
      "[2025-11-08 10:31:15,257] DEBUG [filelock:331] Attempting to acquire lock 140180226159440 on /home/user2/.cache/huggingface/hub/.locks/models--dangnguyens1--sft-fastvlm-1e/4783fe10ac3adce15ac8f358ef5462739852c569.lock\n",
      "[2025-11-08 10:31:15,259] DEBUG [filelock:334] Lock 140180226159440 acquired on /home/user2/.cache/huggingface/hub/.locks/models--dangnguyens1--sft-fastvlm-1e/4783fe10ac3adce15ac8f358ef5462739852c569.lock\n",
      "[2025-11-08 10:31:15,262] DEBUG [filelock:364] Attempting to release lock 140180226159440 on /home/user2/.cache/huggingface/hub/.locks/models--dangnguyens1--sft-fastvlm-1e/4783fe10ac3adce15ac8f358ef5462739852c569.lock\n",
      "[2025-11-08 10:31:15,263] DEBUG [filelock:367] Lock 140180226159440 released on /home/user2/.cache/huggingface/hub/.locks/models--dangnguyens1--sft-fastvlm-1e/4783fe10ac3adce15ac8f358ef5462739852c569.lock\n",
      "[2025-11-08 10:31:15,580] DEBUG [urllib3.connectionpool:544] https://huggingface.co:443 \"HEAD /dangnguyens1/sft-fastvlm-1e/resolve/main/merges.txt HTTP/1.1\" 307 0\n",
      "[2025-11-08 10:31:15,929] DEBUG [urllib3.connectionpool:544] https://huggingface.co:443 \"HEAD /api/resolve-cache/models/dangnguyens1/sft-fastvlm-1e/eb3df95553c7a0a6cb1667bb715a3db89ba464f4/merges.txt HTTP/1.1\" 200 0\n",
      "[2025-11-08 10:31:15,933] DEBUG [filelock:331] Attempting to acquire lock 140179692827216 on /home/user2/.cache/huggingface/hub/.locks/models--dangnguyens1--sft-fastvlm-1e/31349551d90c7606f325fe0f11bbb8bd5fa0d7c7.lock\n",
      "[2025-11-08 10:31:15,935] DEBUG [filelock:334] Lock 140179692827216 acquired on /home/user2/.cache/huggingface/hub/.locks/models--dangnguyens1--sft-fastvlm-1e/31349551d90c7606f325fe0f11bbb8bd5fa0d7c7.lock\n",
      "[2025-11-08 10:31:15,937] DEBUG [filelock:364] Attempting to release lock 140179692827216 on /home/user2/.cache/huggingface/hub/.locks/models--dangnguyens1--sft-fastvlm-1e/31349551d90c7606f325fe0f11bbb8bd5fa0d7c7.lock\n",
      "[2025-11-08 10:31:15,939] DEBUG [filelock:367] Lock 140179692827216 released on /home/user2/.cache/huggingface/hub/.locks/models--dangnguyens1--sft-fastvlm-1e/31349551d90c7606f325fe0f11bbb8bd5fa0d7c7.lock\n",
      "[2025-11-08 10:31:16,239] DEBUG [urllib3.connectionpool:544] https://huggingface.co:443 \"HEAD /dangnguyens1/sft-fastvlm-1e/resolve/main/tokenizer.json HTTP/1.1\" 302 0\n",
      "[2025-11-08 10:31:16,244] DEBUG [filelock:331] Attempting to acquire lock 140180225867664 on /home/user2/.cache/huggingface/hub/.locks/models--dangnguyens1--sft-fastvlm-1e/f9f1b25be0b5a53ffc83ca52290a5ebcf3e45ce4ea9fd378dc6d9091bf111ac2.lock\n",
      "[2025-11-08 10:31:16,246] DEBUG [filelock:334] Lock 140180225867664 acquired on /home/user2/.cache/huggingface/hub/.locks/models--dangnguyens1--sft-fastvlm-1e/f9f1b25be0b5a53ffc83ca52290a5ebcf3e45ce4ea9fd378dc6d9091bf111ac2.lock\n",
      "[2025-11-08 10:31:16,249] DEBUG [filelock:364] Attempting to release lock 140180225867664 on /home/user2/.cache/huggingface/hub/.locks/models--dangnguyens1--sft-fastvlm-1e/f9f1b25be0b5a53ffc83ca52290a5ebcf3e45ce4ea9fd378dc6d9091bf111ac2.lock\n",
      "[2025-11-08 10:31:16,250] DEBUG [filelock:367] Lock 140180225867664 released on /home/user2/.cache/huggingface/hub/.locks/models--dangnguyens1--sft-fastvlm-1e/f9f1b25be0b5a53ffc83ca52290a5ebcf3e45ce4ea9fd378dc6d9091bf111ac2.lock\n",
      "[2025-11-08 10:31:16,547] DEBUG [urllib3.connectionpool:544] https://huggingface.co:443 \"HEAD /dangnguyens1/sft-fastvlm-1e/resolve/main/added_tokens.json HTTP/1.1\" 307 0\n",
      "[2025-11-08 10:31:17,027] DEBUG [urllib3.connectionpool:544] https://huggingface.co:443 \"HEAD /api/resolve-cache/models/dangnguyens1/sft-fastvlm-1e/eb3df95553c7a0a6cb1667bb715a3db89ba464f4/added_tokens.json HTTP/1.1\" 200 0\n",
      "[2025-11-08 10:31:17,032] DEBUG [filelock:331] Attempting to acquire lock 140179692827216 on /home/user2/.cache/huggingface/hub/.locks/models--dangnguyens1--sft-fastvlm-1e/caa81304af029feb531f1fe80a096dc539ea0153.lock\n",
      "[2025-11-08 10:31:17,036] DEBUG [filelock:334] Lock 140179692827216 acquired on /home/user2/.cache/huggingface/hub/.locks/models--dangnguyens1--sft-fastvlm-1e/caa81304af029feb531f1fe80a096dc539ea0153.lock\n",
      "[2025-11-08 10:31:17,037] DEBUG [filelock:364] Attempting to release lock 140179692827216 on /home/user2/.cache/huggingface/hub/.locks/models--dangnguyens1--sft-fastvlm-1e/caa81304af029feb531f1fe80a096dc539ea0153.lock\n",
      "[2025-11-08 10:31:17,038] DEBUG [filelock:367] Lock 140179692827216 released on /home/user2/.cache/huggingface/hub/.locks/models--dangnguyens1--sft-fastvlm-1e/caa81304af029feb531f1fe80a096dc539ea0153.lock\n",
      "[2025-11-08 10:31:17,364] DEBUG [urllib3.connectionpool:544] https://huggingface.co:443 \"HEAD /dangnguyens1/sft-fastvlm-1e/resolve/main/special_tokens_map.json HTTP/1.1\" 307 0\n",
      "[2025-11-08 10:31:17,699] DEBUG [urllib3.connectionpool:544] https://huggingface.co:443 \"HEAD /api/resolve-cache/models/dangnguyens1/sft-fastvlm-1e/eb3df95553c7a0a6cb1667bb715a3db89ba464f4/special_tokens_map.json HTTP/1.1\" 200 0\n",
      "[2025-11-08 10:31:17,701] DEBUG [filelock:331] Attempting to acquire lock 140180301382864 on /home/user2/.cache/huggingface/hub/.locks/models--dangnguyens1--sft-fastvlm-1e/ac23c0aaa2434523c494330aeb79c58395378103.lock\n",
      "[2025-11-08 10:31:17,703] DEBUG [filelock:334] Lock 140180301382864 acquired on /home/user2/.cache/huggingface/hub/.locks/models--dangnguyens1--sft-fastvlm-1e/ac23c0aaa2434523c494330aeb79c58395378103.lock\n",
      "[2025-11-08 10:31:17,705] DEBUG [filelock:364] Attempting to release lock 140180301382864 on /home/user2/.cache/huggingface/hub/.locks/models--dangnguyens1--sft-fastvlm-1e/ac23c0aaa2434523c494330aeb79c58395378103.lock\n",
      "[2025-11-08 10:31:17,705] DEBUG [filelock:367] Lock 140180301382864 released on /home/user2/.cache/huggingface/hub/.locks/models--dangnguyens1--sft-fastvlm-1e/ac23c0aaa2434523c494330aeb79c58395378103.lock\n",
      "[2025-11-08 10:31:18,007] DEBUG [urllib3.connectionpool:544] https://huggingface.co:443 \"HEAD /dangnguyens1/sft-fastvlm-1e/resolve/main/chat_template.jinja HTTP/1.1\" 307 0\n",
      "[2025-11-08 10:31:18,336] DEBUG [urllib3.connectionpool:544] https://huggingface.co:443 \"HEAD /api/resolve-cache/models/dangnguyens1/sft-fastvlm-1e/eb3df95553c7a0a6cb1667bb715a3db89ba464f4/chat_template.jinja HTTP/1.1\" 200 0\n",
      "[2025-11-08 10:31:18,339] DEBUG [filelock:331] Attempting to acquire lock 140179692693264 on /home/user2/.cache/huggingface/hub/.locks/models--dangnguyens1--sft-fastvlm-1e/6c226632394ae7474b0d4b13e15793eac2e21ee9.lock\n",
      "[2025-11-08 10:31:18,341] DEBUG [filelock:334] Lock 140179692693264 acquired on /home/user2/.cache/huggingface/hub/.locks/models--dangnguyens1--sft-fastvlm-1e/6c226632394ae7474b0d4b13e15793eac2e21ee9.lock\n",
      "[2025-11-08 10:31:18,343] DEBUG [filelock:364] Attempting to release lock 140179692693264 on /home/user2/.cache/huggingface/hub/.locks/models--dangnguyens1--sft-fastvlm-1e/6c226632394ae7474b0d4b13e15793eac2e21ee9.lock\n",
      "[2025-11-08 10:31:18,344] DEBUG [filelock:367] Lock 140179692693264 released on /home/user2/.cache/huggingface/hub/.locks/models--dangnguyens1--sft-fastvlm-1e/6c226632394ae7474b0d4b13e15793eac2e21ee9.lock\n",
      "[2025-11-08 10:31:19,045] DEBUG [urllib3.connectionpool:544] https://huggingface.co:443 \"GET /api/models/dangnguyens1/sft-fastvlm-1e/revision/main HTTP/1.1\" 200 3110\n",
      "Fetching 2 files:   0%|          | 0/2 [00:00<?, ?it/s][2025-11-08 10:31:19,057] DEBUG [urllib3.connectionpool:1049] Starting new HTTPS connection (1): huggingface.co:443\n",
      "[2025-11-08 10:31:19,504] DEBUG [urllib3.connectionpool:544] https://huggingface.co:443 \"HEAD /dangnguyens1/sft-fastvlm-1e/resolve/eb3df95553c7a0a6cb1667bb715a3db89ba464f4/video_preprocessor_config.json HTTP/1.1\" 307 0\n",
      "[2025-11-08 10:31:19,833] DEBUG [urllib3.connectionpool:544] https://huggingface.co:443 \"HEAD /api/resolve-cache/models/dangnguyens1/sft-fastvlm-1e/eb3df95553c7a0a6cb1667bb715a3db89ba464f4/video_preprocessor_config.json HTTP/1.1\" 200 0\n",
      "[2025-11-08 10:31:19,836] DEBUG [filelock:331] Attempting to acquire lock 140180225866000 on /home/user2/.cache/huggingface/hub/.locks/models--dangnguyens1--sft-fastvlm-1e/c3c4a3e151a26f02a290bf3fa1007e382371365b.lock\n",
      "[2025-11-08 10:31:19,838] DEBUG [filelock:334] Lock 140180225866000 acquired on /home/user2/.cache/huggingface/hub/.locks/models--dangnguyens1--sft-fastvlm-1e/c3c4a3e151a26f02a290bf3fa1007e382371365b.lock\n",
      "[2025-11-08 10:31:20,180] DEBUG [urllib3.connectionpool:544] https://huggingface.co:443 \"GET /api/resolve-cache/models/dangnguyens1/sft-fastvlm-1e/eb3df95553c7a0a6cb1667bb715a3db89ba464f4/video_preprocessor_config.json HTTP/1.1\" 200 930\n",
      "[2025-11-08 10:31:20,184] DEBUG [filelock:364] Attempting to release lock 140180225866000 on /home/user2/.cache/huggingface/hub/.locks/models--dangnguyens1--sft-fastvlm-1e/c3c4a3e151a26f02a290bf3fa1007e382371365b.lock\n",
      "[2025-11-08 10:31:20,185] DEBUG [filelock:367] Lock 140180225866000 released on /home/user2/.cache/huggingface/hub/.locks/models--dangnguyens1--sft-fastvlm-1e/c3c4a3e151a26f02a290bf3fa1007e382371365b.lock\n",
      "Fetching 2 files: 100%|██████████| 2/2 [00:01<00:00,  1.77it/s]\n",
      "[2025-11-08 10:31:20,506] DEBUG [urllib3.connectionpool:544] https://huggingface.co:443 \"GET /api/models/dangnguyens1/sft-fastvlm-1e/tree/main/additional_chat_templates?recursive=False&expand=False HTTP/1.1\" 404 64\n",
      "[2025-11-08 10:31:20,800] DEBUG [urllib3.connectionpool:544] https://huggingface.co:443 \"HEAD /dangnguyens1/sft-fastvlm-1e/resolve/main/processor_config.json HTTP/1.1\" 404 0\n",
      "[2025-11-08 10:31:21,106] DEBUG [urllib3.connectionpool:544] https://huggingface.co:443 \"HEAD /dangnguyens1/sft-fastvlm-1e/resolve/main/chat_template.json HTTP/1.1\" 404 0\n",
      "[2025-11-08 10:31:21,417] DEBUG [urllib3.connectionpool:544] https://huggingface.co:443 \"HEAD /dangnguyens1/sft-fastvlm-1e/resolve/main/chat_template.jinja HTTP/1.1\" 307 0\n",
      "[2025-11-08 10:31:21,522] DEBUG [urllib3.connectionpool:544] https://huggingface.co:443 \"HEAD /api/resolve-cache/models/dangnguyens1/sft-fastvlm-1e/eb3df95553c7a0a6cb1667bb715a3db89ba464f4/chat_template.jinja HTTP/1.1\" 200 0\n",
      "[2025-11-08 10:31:21,824] DEBUG [urllib3.connectionpool:544] https://huggingface.co:443 \"HEAD /dangnguyens1/sft-fastvlm-1e/resolve/main/audio_tokenizer_config.json HTTP/1.1\" 404 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processor loaded from dangnguyens1/sft-fastvlm-1e\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoProcessor\n",
    "\n",
    "repo_id = \"dangnguyens1/sft-fastvlm-1e\" \n",
    "processor = AutoProcessor.from_pretrained(repo_id)\n",
    "\n",
    "print(f\"Processor loaded from {repo_id}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7458b5cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2025-11-08 10:31:22,606] DEBUG [urllib3.connectionpool:544] https://huggingface.co:443 \"GET /api/whoami-v2 HTTP/1.1\" 401 47\n"
     ]
    },
    {
     "ename": "HTTPError",
     "evalue": "Invalid user token.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mHTTPError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.conda/envs/vlm2vec/lib/python3.11/site-packages/huggingface_hub/utils/_http.py:407\u001b[39m, in \u001b[36mhf_raise_for_status\u001b[39m\u001b[34m(response, endpoint_name)\u001b[39m\n\u001b[32m    406\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m407\u001b[39m     \u001b[43mresponse\u001b[49m\u001b[43m.\u001b[49m\u001b[43mraise_for_status\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    408\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m HTTPError \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.conda/envs/vlm2vec/lib/python3.11/site-packages/requests/models.py:1026\u001b[39m, in \u001b[36mResponse.raise_for_status\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1025\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m http_error_msg:\n\u001b[32m-> \u001b[39m\u001b[32m1026\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m HTTPError(http_error_msg, response=\u001b[38;5;28mself\u001b[39m)\n",
      "\u001b[31mHTTPError\u001b[39m: 401 Client Error: Unauthorized for url: https://huggingface.co/api/whoami-v2",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[31mHfHubHTTPError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.conda/envs/vlm2vec/lib/python3.11/site-packages/huggingface_hub/hf_api.py:1782\u001b[39m, in \u001b[36mHfApi.whoami\u001b[39m\u001b[34m(self, token)\u001b[39m\n\u001b[32m   1781\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1782\u001b[39m     \u001b[43mhf_raise_for_status\u001b[49m\u001b[43m(\u001b[49m\u001b[43mr\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1783\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m HTTPError \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.conda/envs/vlm2vec/lib/python3.11/site-packages/huggingface_hub/utils/_http.py:480\u001b[39m, in \u001b[36mhf_raise_for_status\u001b[39m\u001b[34m(response, endpoint_name)\u001b[39m\n\u001b[32m    478\u001b[39m \u001b[38;5;66;03m# Convert `HTTPError` into a `HfHubHTTPError` to display request information\u001b[39;00m\n\u001b[32m    479\u001b[39m \u001b[38;5;66;03m# as well (request id and/or server error message)\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m480\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m _format(HfHubHTTPError, \u001b[38;5;28mstr\u001b[39m(e), response) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01me\u001b[39;00m\n",
      "\u001b[31mHfHubHTTPError\u001b[39m: 401 Client Error: Unauthorized for url: https://huggingface.co/api/whoami-v2 (Request ID: Root=1-690f1bfa-09a01dad1f97237152bc4f57;f1e036b9-eae5-4a34-b32a-adc413833f9a)\n\nUser Access Token \"kd\" is expired",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[31mHTTPError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[32m/tmp/ipykernel_631354/3798275080.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m huggingface_hub \u001b[38;5;28;01mimport\u001b[39;00m login\n\u001b[32m      2\u001b[39m token=\u001b[33m\"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\"\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m login(token=token)\n\u001b[32m      4\u001b[39m \n\u001b[32m      5\u001b[39m ckpt_dir = \u001b[33m\"test-save\"\u001b[39m\n\u001b[32m      6\u001b[39m \u001b[38;5;66;03m# processor.tokenizer.save_pretrained(ckpt_dir)\u001b[39;00m\n",
      "\u001b[32m~/.conda/envs/vlm2vec/lib/python3.11/site-packages/huggingface_hub/utils/_deprecation.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m     97\u001b[39m                 )\n\u001b[32m     98\u001b[39m                 \u001b[38;5;28;01mif\u001b[39;00m custom_message \u001b[38;5;28;01mis\u001b[39;00m \u001b[38;5;28;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m     99\u001b[39m                     message += \u001b[33m\"\\n\\n\"\u001b[39m + custom_message\n\u001b[32m    100\u001b[39m                 warnings.warn(message, FutureWarning)\n\u001b[32m--> \u001b[39m\u001b[32m101\u001b[39m             \u001b[38;5;28;01mreturn\u001b[39;00m f(*args, **kwargs)\n",
      "\u001b[32m~/.conda/envs/vlm2vec/lib/python3.11/site-packages/huggingface_hub/utils/_deprecation.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m     27\u001b[39m         @wraps(f)\n\u001b[32m     28\u001b[39m         \u001b[38;5;28;01mdef\u001b[39;00m inner_f(*args, **kwargs):\n\u001b[32m     29\u001b[39m             extra_args = len(args) - len(all_args)\n\u001b[32m     30\u001b[39m             \u001b[38;5;28;01mif\u001b[39;00m extra_args <= \u001b[32m0\u001b[39m:\n\u001b[32m---> \u001b[39m\u001b[32m31\u001b[39m                 \u001b[38;5;28;01mreturn\u001b[39;00m f(*args, **kwargs)\n\u001b[32m     32\u001b[39m             \u001b[38;5;66;03m# extra_args > 0\u001b[39;00m\n\u001b[32m     33\u001b[39m             args_msg = [\n\u001b[32m     34\u001b[39m                 \u001b[33mf\"{name}='{arg}'\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m isinstance(arg, str) \u001b[38;5;28;01melse\u001b[39;00m \u001b[33mf\"{name}={arg}\"\u001b[39m\n",
      "\u001b[32m~/.conda/envs/vlm2vec/lib/python3.11/site-packages/huggingface_hub/_login.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(token, add_to_git_credential, new_session, write_permission)\u001b[39m\n\u001b[32m    122\u001b[39m                 \u001b[33m\"`add_to_git_credential=True` in this function directly or \"\u001b[39m\n\u001b[32m    123\u001b[39m                 \u001b[33m\"`--add-to-git-credential` if using via `hf`CLI if \"\u001b[39m\n\u001b[32m    124\u001b[39m                 \u001b[33m\"you want to set the git credential as well.\"\u001b[39m\n\u001b[32m    125\u001b[39m             )\n\u001b[32m--> \u001b[39m\u001b[32m126\u001b[39m         _login(token, add_to_git_credential=add_to_git_credential)\n\u001b[32m    127\u001b[39m     \u001b[38;5;28;01melif\u001b[39;00m is_notebook():\n\u001b[32m    128\u001b[39m         notebook_login(new_session=new_session)\n\u001b[32m    129\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[32m~/.conda/envs/vlm2vec/lib/python3.11/site-packages/huggingface_hub/_login.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(token, add_to_git_credential)\u001b[39m\n\u001b[32m    400\u001b[39m \n\u001b[32m    401\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m token.startswith(\u001b[33m\"api_org\"\u001b[39m):\n\u001b[32m    402\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m ValueError(\u001b[33m\"You must use your personal account token, not an organization token.\"\u001b[39m)\n\u001b[32m    403\u001b[39m \n\u001b[32m--> \u001b[39m\u001b[32m404\u001b[39m     token_info = whoami(token)\n\u001b[32m    405\u001b[39m     permission = token_info[\u001b[33m\"auth\"\u001b[39m][\u001b[33m\"accessToken\"\u001b[39m][\u001b[33m\"role\"\u001b[39m]\n\u001b[32m    406\u001b[39m     logger.info(\u001b[33mf\"Token is valid (permission: {permission}).\"\u001b[39m)\n\u001b[32m    407\u001b[39m \n",
      "\u001b[32m~/.conda/envs/vlm2vec/lib/python3.11/site-packages/huggingface_hub/utils/_validators.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    110\u001b[39m \n\u001b[32m    111\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m check_use_auth_token:\n\u001b[32m    112\u001b[39m             kwargs = smoothly_deprecate_use_auth_token(fn_name=fn.__name__, has_token=has_token, kwargs=kwargs)\n\u001b[32m    113\u001b[39m \n\u001b[32m--> \u001b[39m\u001b[32m114\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m fn(*args, **kwargs)\n",
      "\u001b[32m~/.conda/envs/vlm2vec/lib/python3.11/site-packages/huggingface_hub/hf_api.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(self, token)\u001b[39m\n\u001b[32m   1792\u001b[39m                         \u001b[33m\"Note that HF_TOKEN takes precedence over `hf auth login`.\"\u001b[39m\n\u001b[32m   1793\u001b[39m                     )\n\u001b[32m   1794\u001b[39m                 \u001b[38;5;28;01melif\u001b[39;00m effective_token == _get_token_from_file():\n\u001b[32m   1795\u001b[39m                     error_message += \u001b[33m\" The token stored is invalid. Please run `hf auth login` to update it.\"\u001b[39m\n\u001b[32m-> \u001b[39m\u001b[32m1796\u001b[39m                 \u001b[38;5;28;01mraise\u001b[39;00m HTTPError(error_message, request=e.request, response=e.response) \u001b[38;5;28;01mfrom\u001b[39;00m e\n\u001b[32m   1797\u001b[39m             \u001b[38;5;28;01mraise\u001b[39;00m\n\u001b[32m   1798\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m r.json()\n",
      "\u001b[31mHTTPError\u001b[39m: Invalid user token."
     ]
    }
   ],
   "source": [
    "from huggingface_hub import login\n",
    "token=\"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\"\n",
    "login(token=token)\n",
    "\n",
    "ckpt_dir = \"test-save\"\n",
    "# processor.tokenizer.save_pretrained(ckpt_dir)\n",
    "processor.save_pretrained(ckpt_dir)\n",
    "model.encoder.save_pretrained(ckpt_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74adfe88",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from huggingface_hub import HfApi, HfFolder, Repository, create_repo\n",
    "\n",
    "def push_to_hub(repo_name=None, token=None, commit_message=\"Upload model\", \n",
    "                local_dir=\"./temp_model\", private=False):\n",
    "    try:\n",
    "        if not repo_name:\n",
    "            raise ValueError(\"must specify a repo name to push to hub\")\n",
    "        \n",
    "        if not os.path.exists(local_dir):\n",
    "            raise ValueError(f\"local_dir {local_dir} does not exist\")\n",
    "        \n",
    "        print_rank(f\"Pushing model to the hub at {repo_name}...\")\n",
    "        api = HfApi()\n",
    "        create_repo(repo_name, token=token, private=private, exist_ok=True)\n",
    "        api.upload_folder(\n",
    "            folder_path=local_dir,\n",
    "            repo_id=repo_name, \n",
    "            token=token, \n",
    "            commit_message=commit_message\n",
    "        )\n",
    "\n",
    "        print_rank(f\"Model has been pushed to the hub at: {repo_name}\")\n",
    "        return True\n",
    "        \n",
    "    except Exception as e:\n",
    "        print_rank(f\"Error pushing to hub: {str(e)}\")\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbfda101",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2025-11-07 10:55:20,306] INFO [src.utils:12] Pushing model to the hub at dangnguyens1/sft-fastvlm-kd_final_e...\n",
      "[2025-11-07 10:55:20,310] DEBUG [urllib3.connectionpool:289] Resetting dropped connection: huggingface.co\n",
      "[2025-11-07 10:55:23,132] DEBUG [urllib3.connectionpool:544] https://huggingface.co:443 \"POST /api/repos/create HTTP/1.1\" 200 145\n",
      "[2025-11-07 10:55:23,562] DEBUG [urllib3.connectionpool:544] https://huggingface.co:443 \"POST /api/models/dangnguyens1/sft-fastvlm-kd_final_e/preupload/main HTTP/1.1\" 200 878\n",
      "[2025-11-07 10:55:23,867] DEBUG [urllib3.connectionpool:544] https://huggingface.co:443 \"GET /api/models/dangnguyens1/sft-fastvlm-kd_final_e/revision/main?expand=xetEnabled HTTP/1.1\" 200 95\n",
      "[2025-11-07 10:55:24,162] DEBUG [urllib3.connectionpool:544] https://huggingface.co:443 \"GET /api/models/dangnguyens1/sft-fastvlm-kd_final_e/xet-write-token/main HTTP/1.1\" 200 418\n",
      "Processing Files (2 / 2): 100%|██████████| 20.8MB / 20.8MB,  0.00B/s  \n",
      "New Data Upload: |          |  0.00B /  0.00B,  0.00B/s  \n",
      "[2025-11-07 10:55:33,000] DEBUG [urllib3.connectionpool:544] https://huggingface.co:443 \"POST /api/models/dangnguyens1/sft-fastvlm-kd_final_e/commit/main HTTP/1.1\" 200 208\n",
      "[2025-11-07 10:55:33,002] INFO [src.utils:12] Model has been pushed to the hub at: dangnguyens1/sft-fastvlm-kd_final_e\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "push_to_hub(\n",
    "    repo_name=\"dangnguyens1/sft-fastvlm-kd_final_e\",\n",
    "    token=token,\n",
    "    local_dir=\"test-save\",\n",
    "    \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bf8010bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2025-11-08 10:33:16,370] DEBUG [urllib3.connectionpool:544] https://huggingface.co:443 \"HEAD /datasets/TIGER-Lab/MMEB-eval/resolve/main/README.md HTTP/1.1\" 307 0\n",
      "[2025-11-08 10:33:16,429] DEBUG [urllib3.connectionpool:544] https://huggingface.co:443 \"HEAD /api/resolve-cache/datasets/TIGER-Lab/MMEB-eval/2f069730be515ea60778413777816b53e2d2a697/README.md HTTP/1.1\" 200 0\n",
      "[2025-11-08 10:33:16,733] DEBUG [urllib3.connectionpool:544] https://huggingface.co:443 \"HEAD /datasets/TIGER-Lab/MMEB-eval/resolve/2f069730be515ea60778413777816b53e2d2a697/MMEB-eval.py HTTP/1.1\" 404 0\n",
      "[2025-11-08 10:33:16,738] DEBUG [urllib3.connectionpool:1049] Starting new HTTPS connection (1): s3.amazonaws.com:443\n",
      "[2025-11-08 10:33:19,755] DEBUG [urllib3.connectionpool:544] https://s3.amazonaws.com:443 \"HEAD /datasets.huggingface.co/datasets/datasets/TIGER-Lab/MMEB-eval/TIGER-Lab/MMEB-eval.py HTTP/1.1\" 404 0\n",
      "[2025-11-08 10:33:20,746] DEBUG [urllib3.connectionpool:544] https://huggingface.co:443 \"GET /api/datasets/TIGER-Lab/MMEB-eval/revision/2f069730be515ea60778413777816b53e2d2a697 HTTP/1.1\" 200 18440\n",
      "[2025-11-08 10:33:21,059] DEBUG [urllib3.connectionpool:544] https://huggingface.co:443 \"HEAD /datasets/TIGER-Lab/MMEB-eval/resolve/2f069730be515ea60778413777816b53e2d2a697/.huggingface.yaml HTTP/1.1\" 404 0\n",
      "[2025-11-08 10:33:21,079] DEBUG [urllib3.connectionpool:1049] Starting new HTTPS connection (1): datasets-server.huggingface.co:443\n",
      "[2025-11-08 10:33:23,626] DEBUG [urllib3.connectionpool:544] https://datasets-server.huggingface.co:443 \"GET /info?dataset=TIGER-Lab/MMEB-eval HTTP/1.1\" 200 None\n",
      "[2025-11-08 10:33:23,936] DEBUG [urllib3.connectionpool:544] https://huggingface.co:443 \"GET /api/datasets/TIGER-Lab/MMEB-eval/revision/2f069730be515ea60778413777816b53e2d2a697 HTTP/1.1\" 200 18456\n",
      "[2025-11-08 10:33:24,269] DEBUG [urllib3.connectionpool:544] https://huggingface.co:443 \"GET /api/datasets/TIGER-Lab/MMEB-eval/tree/2f069730be515ea60778413777816b53e2d2a697/A-OKVQA?recursive=True&expand=False HTTP/1.1\" 200 317\n",
      "[2025-11-08 10:33:24,595] DEBUG [urllib3.connectionpool:544] https://huggingface.co:443 \"GET /api/datasets/TIGER-Lab/MMEB-eval/tree/2f069730be515ea60778413777816b53e2d2a697?recursive=False&expand=False HTTP/1.1\" 200 4692\n",
      "[2025-11-08 10:33:24,920] DEBUG [urllib3.connectionpool:544] https://huggingface.co:443 \"HEAD /datasets/TIGER-Lab/MMEB-eval/resolve/2f069730be515ea60778413777816b53e2d2a697/dataset_infos.json HTTP/1.1\" 404 0\n",
      "[2025-11-08 10:33:25,242] DEBUG [urllib3.connectionpool:544] https://huggingface.co:443 \"GET /api/datasets/TIGER-Lab/MMEB-eval/tree/2f069730be515ea60778413777816b53e2d2a697/WebQA?recursive=True&expand=False HTTP/1.1\" 200 315\n",
      "[2025-11-08 10:33:25,247] DEBUG [filelock:331] Attempting to acquire lock 140180228780112 on /home/user2/.cache/huggingface/datasets/_home_user2_.cache_huggingface_datasets_TIGER-Lab___mmeb-eval_WebQA_0.0.0_2f069730be515ea60778413777816b53e2d2a697.lock\n",
      "[2025-11-08 10:33:25,248] DEBUG [filelock:334] Lock 140180228780112 acquired on /home/user2/.cache/huggingface/datasets/_home_user2_.cache_huggingface_datasets_TIGER-Lab___mmeb-eval_WebQA_0.0.0_2f069730be515ea60778413777816b53e2d2a697.lock\n",
      "[2025-11-08 10:33:25,250] DEBUG [fsspec.local:379] open file: /home/user2/.cache/huggingface/datasets/TIGER-Lab___mmeb-eval/WebQA/0.0.0/2f069730be515ea60778413777816b53e2d2a697/dataset_info.json\n",
      "[2025-11-08 10:33:25,252] DEBUG [filelock:364] Attempting to release lock 140180228780112 on /home/user2/.cache/huggingface/datasets/_home_user2_.cache_huggingface_datasets_TIGER-Lab___mmeb-eval_WebQA_0.0.0_2f069730be515ea60778413777816b53e2d2a697.lock\n",
      "[2025-11-08 10:33:25,252] DEBUG [filelock:367] Lock 140180228780112 released on /home/user2/.cache/huggingface/datasets/_home_user2_.cache_huggingface_datasets_TIGER-Lab___mmeb-eval_WebQA_0.0.0_2f069730be515ea60778413777816b53e2d2a697.lock\n",
      "[2025-11-08 10:33:25,283] DEBUG [filelock:331] Attempting to acquire lock 140193646338576 on /home/user2/.cache/huggingface/datasets/TIGER-Lab___mmeb-eval/WebQA/0.0.0/2f069730be515ea60778413777816b53e2d2a697_builder.lock\n",
      "[2025-11-08 10:33:25,285] DEBUG [filelock:334] Lock 140193646338576 acquired on /home/user2/.cache/huggingface/datasets/TIGER-Lab___mmeb-eval/WebQA/0.0.0/2f069730be515ea60778413777816b53e2d2a697_builder.lock\n",
      "[2025-11-08 10:33:25,285] DEBUG [fsspec.local:379] open file: /home/user2/.cache/huggingface/datasets/TIGER-Lab___mmeb-eval/WebQA/0.0.0/2f069730be515ea60778413777816b53e2d2a697/dataset_info.json\n",
      "[2025-11-08 10:33:25,286] DEBUG [filelock:364] Attempting to release lock 140193646338576 on /home/user2/.cache/huggingface/datasets/TIGER-Lab___mmeb-eval/WebQA/0.0.0/2f069730be515ea60778413777816b53e2d2a697_builder.lock\n",
      "[2025-11-08 10:33:25,287] DEBUG [filelock:367] Lock 140193646338576 released on /home/user2/.cache/huggingface/datasets/TIGER-Lab___mmeb-eval/WebQA/0.0.0/2f069730be515ea60778413777816b53e2d2a697_builder.lock\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Not using TGT mod None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2025-11-08 10:33:27,148] DEBUG [urllib3.connectionpool:544] https://huggingface.co:443 \"HEAD /datasets/TIGER-Lab/MMEB-eval/resolve/main/README.md HTTP/1.1\" 307 0\n",
      "[2025-11-08 10:33:27,204] DEBUG [urllib3.connectionpool:544] https://huggingface.co:443 \"HEAD /api/resolve-cache/datasets/TIGER-Lab/MMEB-eval/2f069730be515ea60778413777816b53e2d2a697/README.md HTTP/1.1\" 200 0\n",
      "[2025-11-08 10:33:27,516] DEBUG [urllib3.connectionpool:544] https://huggingface.co:443 \"HEAD /datasets/TIGER-Lab/MMEB-eval/resolve/2f069730be515ea60778413777816b53e2d2a697/MMEB-eval.py HTTP/1.1\" 404 0\n",
      "[2025-11-08 10:33:27,521] DEBUG [urllib3.connectionpool:289] Resetting dropped connection: s3.amazonaws.com\n",
      "[2025-11-08 10:33:33,537] DEBUG [urllib3.connectionpool:544] https://s3.amazonaws.com:443 \"HEAD /datasets.huggingface.co/datasets/datasets/TIGER-Lab/MMEB-eval/TIGER-Lab/MMEB-eval.py HTTP/1.1\" 404 0\n",
      "[2025-11-08 10:33:33,893] DEBUG [urllib3.connectionpool:544] https://huggingface.co:443 \"HEAD /datasets/TIGER-Lab/MMEB-eval/resolve/2f069730be515ea60778413777816b53e2d2a697/.huggingface.yaml HTTP/1.1\" 404 0\n",
      "[2025-11-08 10:33:34,194] DEBUG [urllib3.connectionpool:544] https://datasets-server.huggingface.co:443 \"GET /info?dataset=TIGER-Lab/MMEB-eval HTTP/1.1\" 200 None\n",
      "[2025-11-08 10:33:34,510] DEBUG [urllib3.connectionpool:544] https://huggingface.co:443 \"HEAD /datasets/TIGER-Lab/MMEB-eval/resolve/2f069730be515ea60778413777816b53e2d2a697/dataset_infos.json HTTP/1.1\" 404 0\n",
      "[2025-11-08 10:33:34,516] DEBUG [filelock:331] Attempting to acquire lock 140179358419152 on /home/user2/.cache/huggingface/datasets/_home_user2_.cache_huggingface_datasets_TIGER-Lab___mmeb-eval_WebQA_0.0.0_2f069730be515ea60778413777816b53e2d2a697.lock\n",
      "[2025-11-08 10:33:34,517] DEBUG [filelock:334] Lock 140179358419152 acquired on /home/user2/.cache/huggingface/datasets/_home_user2_.cache_huggingface_datasets_TIGER-Lab___mmeb-eval_WebQA_0.0.0_2f069730be515ea60778413777816b53e2d2a697.lock\n",
      "[2025-11-08 10:33:34,519] DEBUG [fsspec.local:379] open file: /home/user2/.cache/huggingface/datasets/TIGER-Lab___mmeb-eval/WebQA/0.0.0/2f069730be515ea60778413777816b53e2d2a697/dataset_info.json\n",
      "[2025-11-08 10:33:34,521] DEBUG [filelock:364] Attempting to release lock 140179358419152 on /home/user2/.cache/huggingface/datasets/_home_user2_.cache_huggingface_datasets_TIGER-Lab___mmeb-eval_WebQA_0.0.0_2f069730be515ea60778413777816b53e2d2a697.lock\n",
      "[2025-11-08 10:33:34,521] DEBUG [filelock:367] Lock 140179358419152 released on /home/user2/.cache/huggingface/datasets/_home_user2_.cache_huggingface_datasets_TIGER-Lab___mmeb-eval_WebQA_0.0.0_2f069730be515ea60778413777816b53e2d2a697.lock\n",
      "[2025-11-08 10:33:34,525] DEBUG [filelock:331] Attempting to acquire lock 140179357244880 on /home/user2/.cache/huggingface/datasets/TIGER-Lab___mmeb-eval/WebQA/0.0.0/2f069730be515ea60778413777816b53e2d2a697_builder.lock\n",
      "[2025-11-08 10:33:34,527] DEBUG [filelock:334] Lock 140179357244880 acquired on /home/user2/.cache/huggingface/datasets/TIGER-Lab___mmeb-eval/WebQA/0.0.0/2f069730be515ea60778413777816b53e2d2a697_builder.lock\n",
      "[2025-11-08 10:33:34,528] DEBUG [fsspec.local:379] open file: /home/user2/.cache/huggingface/datasets/TIGER-Lab___mmeb-eval/WebQA/0.0.0/2f069730be515ea60778413777816b53e2d2a697/dataset_info.json\n",
      "[2025-11-08 10:33:34,530] DEBUG [filelock:364] Attempting to release lock 140179357244880 on /home/user2/.cache/huggingface/datasets/TIGER-Lab___mmeb-eval/WebQA/0.0.0/2f069730be515ea60778413777816b53e2d2a697_builder.lock\n",
      "[2025-11-08 10:33:34,531] DEBUG [filelock:367] Lock 140179357244880 released on /home/user2/.cache/huggingface/datasets/TIGER-Lab___mmeb-eval/WebQA/0.0.0/2f069730be515ea60778413777816b53e2d2a697_builder.lock\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Not using TGT mod None\n"
     ]
    }
   ],
   "source": [
    "POS_MOD_CLASS_LABEL = \"Represent the class label: \"\n",
    "POS_MOD_IMAGE_CAPTION = \"Represent the image caption: \"\n",
    "POS_MOD_ANSWER = \"Represent the answer: \"\n",
    "\n",
    "POS_MOD_DICT = {\n",
    "                \"ImageNet-1K\": POS_MOD_CLASS_LABEL,\"HatefulMemes\":POS_MOD_CLASS_LABEL,\"SUN397\":POS_MOD_CLASS_LABEL,\"N24News\":POS_MOD_CLASS_LABEL,\"VOC2007\":POS_MOD_CLASS_LABEL, \"Place365\":POS_MOD_CLASS_LABEL,\"ImageNet-A\":POS_MOD_CLASS_LABEL,\"ImageNet-R\":POS_MOD_CLASS_LABEL,\"ObjectNet\":POS_MOD_CLASS_LABEL,\"Country211\":POS_MOD_CLASS_LABEL,\n",
    "                \n",
    "                \"OK-VQA\":POS_MOD_ANSWER, \"A-OKVQA\":POS_MOD_ANSWER, \"DocVQA\":POS_MOD_ANSWER, \"InfographicsVQA\":POS_MOD_ANSWER, \"ChartQA\":POS_MOD_ANSWER, \"Visual7W\":POS_MOD_ANSWER,\"ScienceQA\":POS_MOD_ANSWER, \"GQA\":POS_MOD_ANSWER, \"TextVQA\":POS_MOD_ANSWER, \"VizWiz\":POS_MOD_ANSWER,\n",
    "                \n",
    "                \"MSCOCO_i2t\":POS_MOD_IMAGE_CAPTION, \"VisualNews_i2t\":POS_MOD_IMAGE_CAPTION,\n",
    "                }\n",
    "\n",
    "eval_qry_dataset = EvalDataset(\n",
    "    data_args=data_args,\n",
    "    model_args=model_args,\n",
    "    subset=data_args.subset_name[0],\n",
    "    text_field=\"qry_text\",\n",
    "    img_path_field=\"qry_img_path\",\n",
    ")\n",
    "eval_tgt_dataset = EvalDataset(\n",
    "    data_args=data_args,\n",
    "    model_args=model_args,\n",
    "    subset=data_args.subset_name[0],\n",
    "    text_field=\"tgt_text\",\n",
    "    img_path_field=\"tgt_img_path\",\n",
    "    mod_instruction=POS_MOD_DICT.get(data_args.subset_name[0], None) if data_args.tgt_prefix_mod else None\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ccfd02c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('<image>\\nFind a Wikipedia image that answers this question: What water-related object is sitting in front of the Torre del Reloj?\\n',\n",
       " None)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_qry_dataset[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d278d46e",
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_qry_loader = DataLoader(\n",
    "    eval_qry_dataset,\n",
    "    batch_size=training_args.per_device_eval_batch_size,\n",
    "    collate_fn=eval_collator,\n",
    "    shuffle=False,\n",
    "    drop_last=False,\n",
    "    num_workers=0,\n",
    ")\n",
    "eval_tgt_loader = DataLoader(\n",
    "    eval_tgt_dataset,\n",
    "    batch_size=training_args.per_device_eval_batch_size,\n",
    "    collate_fn=eval_collator,\n",
    "    shuffle=False,\n",
    "    drop_last=False,\n",
    "    num_workers=0,\n",
    ")\n",
    "\n",
    "def batch_to_device(batch, device):\n",
    "    _batch = {}\n",
    "    for key, value in batch.items():\n",
    "        if isinstance(value, torch.Tensor):\n",
    "            _batch[key] = value.to(device)\n",
    "        else:\n",
    "            _batch[key] = value\n",
    "    return _batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "021f1414",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch.utils.data.dataloader.DataLoader at 0x7fd681919fd0>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_qry_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "567d1e4a",
   "metadata": {},
   "outputs": [
    {
     "ename": "AcceleratorError",
     "evalue": "CUDA error: device-side assert triggered\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAcceleratorError\u001b[39m                          Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.conda/envs/vlm2vec/lib/python3.11/site-packages/IPython/core/formatters.py:770\u001b[39m, in \u001b[36mPlainTextFormatter.__call__\u001b[39m\u001b[34m(self, obj)\u001b[39m\n\u001b[32m    763\u001b[39m stream = StringIO()\n\u001b[32m    764\u001b[39m printer = pretty.RepresentationPrinter(stream, \u001b[38;5;28mself\u001b[39m.verbose,\n\u001b[32m    765\u001b[39m     \u001b[38;5;28mself\u001b[39m.max_width, \u001b[38;5;28mself\u001b[39m.newline,\n\u001b[32m    766\u001b[39m     max_seq_length=\u001b[38;5;28mself\u001b[39m.max_seq_length,\n\u001b[32m    767\u001b[39m     singleton_pprinters=\u001b[38;5;28mself\u001b[39m.singleton_printers,\n\u001b[32m    768\u001b[39m     type_pprinters=\u001b[38;5;28mself\u001b[39m.type_printers,\n\u001b[32m    769\u001b[39m     deferred_pprinters=\u001b[38;5;28mself\u001b[39m.deferred_printers)\n\u001b[32m--> \u001b[39m\u001b[32m770\u001b[39m \u001b[43mprinter\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpretty\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    771\u001b[39m printer.flush()\n\u001b[32m    772\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m stream.getvalue()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.conda/envs/vlm2vec/lib/python3.11/site-packages/IPython/lib/pretty.py:411\u001b[39m, in \u001b[36mRepresentationPrinter.pretty\u001b[39m\u001b[34m(self, obj)\u001b[39m\n\u001b[32m    400\u001b[39m                         \u001b[38;5;28;01mreturn\u001b[39;00m meth(obj, \u001b[38;5;28mself\u001b[39m, cycle)\n\u001b[32m    401\u001b[39m                 \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[32m    402\u001b[39m                     \u001b[38;5;28mcls\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mobject\u001b[39m\n\u001b[32m    403\u001b[39m                     \u001b[38;5;66;03m# check if cls defines __repr__\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    409\u001b[39m                     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mcallable\u001b[39m(_safe_getattr(\u001b[38;5;28mcls\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33m__repr__\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[32m    410\u001b[39m                 ):\n\u001b[32m--> \u001b[39m\u001b[32m411\u001b[39m                     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_repr_pprint\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcycle\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    413\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m _default_pprint(obj, \u001b[38;5;28mself\u001b[39m, cycle)\n\u001b[32m    414\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.conda/envs/vlm2vec/lib/python3.11/site-packages/IPython/lib/pretty.py:786\u001b[39m, in \u001b[36m_repr_pprint\u001b[39m\u001b[34m(obj, p, cycle)\u001b[39m\n\u001b[32m    784\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"A pprint that just redirects to the normal repr function.\"\"\"\u001b[39;00m\n\u001b[32m    785\u001b[39m \u001b[38;5;66;03m# Find newlines and replace them with p.break_()\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m786\u001b[39m output = \u001b[38;5;28;43mrepr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    787\u001b[39m lines = output.splitlines()\n\u001b[32m    788\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m p.group():\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.conda/envs/vlm2vec/lib/python3.11/site-packages/torch/_tensor.py:590\u001b[39m, in \u001b[36mTensor.__repr__\u001b[39m\u001b[34m(self, tensor_contents)\u001b[39m\n\u001b[32m    586\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[32m    587\u001b[39m         Tensor.\u001b[34m__repr__\u001b[39m, (\u001b[38;5;28mself\u001b[39m,), \u001b[38;5;28mself\u001b[39m, tensor_contents=tensor_contents\n\u001b[32m    588\u001b[39m     )\n\u001b[32m    589\u001b[39m \u001b[38;5;66;03m# All strings are unicode in Python 3.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m590\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_tensor_str\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_str\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtensor_contents\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtensor_contents\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.conda/envs/vlm2vec/lib/python3.11/site-packages/torch/_tensor_str.py:726\u001b[39m, in \u001b[36m_str\u001b[39m\u001b[34m(self, tensor_contents)\u001b[39m\n\u001b[32m    724\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m torch.no_grad(), torch.utils._python_dispatch._disable_current_modes():\n\u001b[32m    725\u001b[39m     guard = torch._C._DisableFuncTorch()  \u001b[38;5;66;03m# noqa: F841\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m726\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_str_intern\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtensor_contents\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtensor_contents\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.conda/envs/vlm2vec/lib/python3.11/site-packages/torch/_tensor_str.py:647\u001b[39m, in \u001b[36m_str_intern\u001b[39m\u001b[34m(inp, tensor_contents)\u001b[39m\n\u001b[32m    645\u001b[39m                     tensor_str = _tensor_str(\u001b[38;5;28mself\u001b[39m.to_dense(), indent)\n\u001b[32m    646\u001b[39m                 \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m647\u001b[39m                     tensor_str = \u001b[43m_tensor_str\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindent\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    649\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.layout != torch.strided:\n\u001b[32m    650\u001b[39m     suffixes.append(\u001b[33m\"\u001b[39m\u001b[33mlayout=\u001b[39m\u001b[33m\"\u001b[39m + \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mself\u001b[39m.layout))\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.conda/envs/vlm2vec/lib/python3.11/site-packages/torch/_tensor_str.py:379\u001b[39m, in \u001b[36m_tensor_str\u001b[39m\u001b[34m(self, indent)\u001b[39m\n\u001b[32m    375\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m _tensor_str_with_formatter(\n\u001b[32m    376\u001b[39m         \u001b[38;5;28mself\u001b[39m, indent, summarize, real_formatter, imag_formatter\n\u001b[32m    377\u001b[39m     )\n\u001b[32m    378\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m379\u001b[39m     formatter = \u001b[43m_Formatter\u001b[49m\u001b[43m(\u001b[49m\u001b[43mget_summarized_data\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43msummarize\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m    380\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m _tensor_str_with_formatter(\u001b[38;5;28mself\u001b[39m, indent, summarize, formatter)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.conda/envs/vlm2vec/lib/python3.11/site-packages/torch/_tensor_str.py:142\u001b[39m, in \u001b[36m_Formatter.__init__\u001b[39m\u001b[34m(self, tensor)\u001b[39m\n\u001b[32m    140\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m.floating_dtype:\n\u001b[32m    141\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m value \u001b[38;5;129;01min\u001b[39;00m tensor_view:\n\u001b[32m--> \u001b[39m\u001b[32m142\u001b[39m         value_str = \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mvalue\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    143\u001b[39m         \u001b[38;5;28mself\u001b[39m.max_width = \u001b[38;5;28mmax\u001b[39m(\u001b[38;5;28mself\u001b[39m.max_width, \u001b[38;5;28mlen\u001b[39m(value_str))\n\u001b[32m    145\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.conda/envs/vlm2vec/lib/python3.11/site-packages/torch/_tensor.py:1129\u001b[39m, in \u001b[36mTensor.__format__\u001b[39m\u001b[34m(self, format_spec)\u001b[39m\n\u001b[32m   1125\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(Tensor.\u001b[34m__format__\u001b[39m, (\u001b[38;5;28mself\u001b[39m,), \u001b[38;5;28mself\u001b[39m, format_spec)\n\u001b[32m   1126\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.dim() == \u001b[32m0\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m.is_meta \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;129;01mis\u001b[39;00m Tensor:\n\u001b[32m   1127\u001b[39m     \u001b[38;5;66;03m# Use detach() here to avoid the warning when converting a scalar Tensor that\u001b[39;00m\n\u001b[32m   1128\u001b[39m     \u001b[38;5;66;03m# requires gradients to a python number. It is ok for formatting.\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1129\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdetach\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mitem\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m.\u001b[34m__format__\u001b[39m(format_spec)\n\u001b[32m   1130\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mobject\u001b[39m.\u001b[34m__format__\u001b[39m(\u001b[38;5;28mself\u001b[39m, format_spec)\n",
      "\u001b[31mAcceleratorError\u001b[39m: CUDA error: device-side assert triggered\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n"
     ]
    }
   ],
   "source": [
    "batch['input_ids'].to('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "438338c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/pytorch/aten/src/ATen/native/cuda/IndexKernelUtils.cu:16: vectorized_gather_kernel: block: [30,0,0], thread: [0,0,0] Assertion `ind >=0 && ind < ind_dim_size && \"vectorized gather kernel index out of bounds\"` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/IndexKernelUtils.cu:16: vectorized_gather_kernel: block: [30,0,0], thread: [1,0,0] Assertion `ind >=0 && ind < ind_dim_size && \"vectorized gather kernel index out of bounds\"` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/IndexKernelUtils.cu:16: vectorized_gather_kernel: block: [30,0,0], thread: [2,0,0] Assertion `ind >=0 && ind < ind_dim_size && \"vectorized gather kernel index out of bounds\"` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/IndexKernelUtils.cu:16: vectorized_gather_kernel: block: [30,0,0], thread: [3,0,0] Assertion `ind >=0 && ind < ind_dim_size && \"vectorized gather kernel index out of bounds\"` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/IndexKernelUtils.cu:16: vectorized_gather_kernel: block: [30,0,0], thread: [4,0,0] Assertion `ind >=0 && ind < ind_dim_size && \"vectorized gather kernel index out of bounds\"` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/IndexKernelUtils.cu:16: vectorized_gather_kernel: block: [30,0,0], thread: [5,0,0] Assertion `ind >=0 && ind < ind_dim_size && \"vectorized gather kernel index out of bounds\"` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/IndexKernelUtils.cu:16: vectorized_gather_kernel: block: [30,0,0], thread: [6,0,0] Assertion `ind >=0 && ind < ind_dim_size && \"vectorized gather kernel index out of bounds\"` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/IndexKernelUtils.cu:16: vectorized_gather_kernel: block: [30,0,0], thread: [7,0,0] Assertion `ind >=0 && ind < ind_dim_size && \"vectorized gather kernel index out of bounds\"` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/IndexKernelUtils.cu:16: vectorized_gather_kernel: block: [30,0,0], thread: [8,0,0] Assertion `ind >=0 && ind < ind_dim_size && \"vectorized gather kernel index out of bounds\"` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/IndexKernelUtils.cu:16: vectorized_gather_kernel: block: [30,0,0], thread: [9,0,0] Assertion `ind >=0 && ind < ind_dim_size && \"vectorized gather kernel index out of bounds\"` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/IndexKernelUtils.cu:16: vectorized_gather_kernel: block: [30,0,0], thread: [10,0,0] Assertion `ind >=0 && ind < ind_dim_size && \"vectorized gather kernel index out of bounds\"` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/IndexKernelUtils.cu:16: vectorized_gather_kernel: block: [30,0,0], thread: [11,0,0] Assertion `ind >=0 && ind < ind_dim_size && \"vectorized gather kernel index out of bounds\"` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/IndexKernelUtils.cu:16: vectorized_gather_kernel: block: [30,0,0], thread: [12,0,0] Assertion `ind >=0 && ind < ind_dim_size && \"vectorized gather kernel index out of bounds\"` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/IndexKernelUtils.cu:16: vectorized_gather_kernel: block: [30,0,0], thread: [13,0,0] Assertion `ind >=0 && ind < ind_dim_size && \"vectorized gather kernel index out of bounds\"` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/IndexKernelUtils.cu:16: vectorized_gather_kernel: block: [30,0,0], thread: [14,0,0] Assertion `ind >=0 && ind < ind_dim_size && \"vectorized gather kernel index out of bounds\"` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/IndexKernelUtils.cu:16: vectorized_gather_kernel: block: [30,0,0], thread: [15,0,0] Assertion `ind >=0 && ind < ind_dim_size && \"vectorized gather kernel index out of bounds\"` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/IndexKernelUtils.cu:16: vectorized_gather_kernel: block: [30,0,0], thread: [16,0,0] Assertion `ind >=0 && ind < ind_dim_size && \"vectorized gather kernel index out of bounds\"` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/IndexKernelUtils.cu:16: vectorized_gather_kernel: block: [30,0,0], thread: [17,0,0] Assertion `ind >=0 && ind < ind_dim_size && \"vectorized gather kernel index out of bounds\"` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/IndexKernelUtils.cu:16: vectorized_gather_kernel: block: [30,0,0], thread: [18,0,0] Assertion `ind >=0 && ind < ind_dim_size && \"vectorized gather kernel index out of bounds\"` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/IndexKernelUtils.cu:16: vectorized_gather_kernel: block: [30,0,0], thread: [19,0,0] Assertion `ind >=0 && ind < ind_dim_size && \"vectorized gather kernel index out of bounds\"` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/IndexKernelUtils.cu:16: vectorized_gather_kernel: block: [30,0,0], thread: [20,0,0] Assertion `ind >=0 && ind < ind_dim_size && \"vectorized gather kernel index out of bounds\"` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/IndexKernelUtils.cu:16: vectorized_gather_kernel: block: [30,0,0], thread: [21,0,0] Assertion `ind >=0 && ind < ind_dim_size && \"vectorized gather kernel index out of bounds\"` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/IndexKernelUtils.cu:16: vectorized_gather_kernel: block: [30,0,0], thread: [22,0,0] Assertion `ind >=0 && ind < ind_dim_size && \"vectorized gather kernel index out of bounds\"` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/IndexKernelUtils.cu:16: vectorized_gather_kernel: block: [30,0,0], thread: [23,0,0] Assertion `ind >=0 && ind < ind_dim_size && \"vectorized gather kernel index out of bounds\"` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/IndexKernelUtils.cu:16: vectorized_gather_kernel: block: [30,0,0], thread: [24,0,0] Assertion `ind >=0 && ind < ind_dim_size && \"vectorized gather kernel index out of bounds\"` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/IndexKernelUtils.cu:16: vectorized_gather_kernel: block: [30,0,0], thread: [25,0,0] Assertion `ind >=0 && ind < ind_dim_size && \"vectorized gather kernel index out of bounds\"` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/IndexKernelUtils.cu:16: vectorized_gather_kernel: block: [30,0,0], thread: [26,0,0] Assertion `ind >=0 && ind < ind_dim_size && \"vectorized gather kernel index out of bounds\"` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/IndexKernelUtils.cu:16: vectorized_gather_kernel: block: [30,0,0], thread: [27,0,0] Assertion `ind >=0 && ind < ind_dim_size && \"vectorized gather kernel index out of bounds\"` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/IndexKernelUtils.cu:16: vectorized_gather_kernel: block: [30,0,0], thread: [28,0,0] Assertion `ind >=0 && ind < ind_dim_size && \"vectorized gather kernel index out of bounds\"` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/IndexKernelUtils.cu:16: vectorized_gather_kernel: block: [30,0,0], thread: [29,0,0] Assertion `ind >=0 && ind < ind_dim_size && \"vectorized gather kernel index out of bounds\"` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/IndexKernelUtils.cu:16: vectorized_gather_kernel: block: [30,0,0], thread: [30,0,0] Assertion `ind >=0 && ind < ind_dim_size && \"vectorized gather kernel index out of bounds\"` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/IndexKernelUtils.cu:16: vectorized_gather_kernel: block: [30,0,0], thread: [31,0,0] Assertion `ind >=0 && ind < ind_dim_size && \"vectorized gather kernel index out of bounds\"` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/IndexKernelUtils.cu:16: vectorized_gather_kernel: block: [30,0,0], thread: [64,0,0] Assertion `ind >=0 && ind < ind_dim_size && \"vectorized gather kernel index out of bounds\"` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/IndexKernelUtils.cu:16: vectorized_gather_kernel: block: [30,0,0], thread: [65,0,0] Assertion `ind >=0 && ind < ind_dim_size && \"vectorized gather kernel index out of bounds\"` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/IndexKernelUtils.cu:16: vectorized_gather_kernel: block: [30,0,0], thread: [66,0,0] Assertion `ind >=0 && ind < ind_dim_size && \"vectorized gather kernel index out of bounds\"` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/IndexKernelUtils.cu:16: vectorized_gather_kernel: block: [30,0,0], thread: [67,0,0] Assertion `ind >=0 && ind < ind_dim_size && \"vectorized gather kernel index out of bounds\"` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/IndexKernelUtils.cu:16: vectorized_gather_kernel: block: [30,0,0], thread: [68,0,0] Assertion `ind >=0 && ind < ind_dim_size && \"vectorized gather kernel index out of bounds\"` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/IndexKernelUtils.cu:16: vectorized_gather_kernel: block: [30,0,0], thread: [69,0,0] Assertion `ind >=0 && ind < ind_dim_size && \"vectorized gather kernel index out of bounds\"` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/IndexKernelUtils.cu:16: vectorized_gather_kernel: block: [30,0,0], thread: [70,0,0] Assertion `ind >=0 && ind < ind_dim_size && \"vectorized gather kernel index out of bounds\"` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/IndexKernelUtils.cu:16: vectorized_gather_kernel: block: [30,0,0], thread: [71,0,0] Assertion `ind >=0 && ind < ind_dim_size && \"vectorized gather kernel index out of bounds\"` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/IndexKernelUtils.cu:16: vectorized_gather_kernel: block: [30,0,0], thread: [72,0,0] Assertion `ind >=0 && ind < ind_dim_size && \"vectorized gather kernel index out of bounds\"` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/IndexKernelUtils.cu:16: vectorized_gather_kernel: block: [30,0,0], thread: [73,0,0] Assertion `ind >=0 && ind < ind_dim_size && \"vectorized gather kernel index out of bounds\"` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/IndexKernelUtils.cu:16: vectorized_gather_kernel: block: [30,0,0], thread: [74,0,0] Assertion `ind >=0 && ind < ind_dim_size && \"vectorized gather kernel index out of bounds\"` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/IndexKernelUtils.cu:16: vectorized_gather_kernel: block: [30,0,0], thread: [75,0,0] Assertion `ind >=0 && ind < ind_dim_size && \"vectorized gather kernel index out of bounds\"` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/IndexKernelUtils.cu:16: vectorized_gather_kernel: block: [30,0,0], thread: [76,0,0] Assertion `ind >=0 && ind < ind_dim_size && \"vectorized gather kernel index out of bounds\"` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/IndexKernelUtils.cu:16: vectorized_gather_kernel: block: [30,0,0], thread: [77,0,0] Assertion `ind >=0 && ind < ind_dim_size && \"vectorized gather kernel index out of bounds\"` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/IndexKernelUtils.cu:16: vectorized_gather_kernel: block: [30,0,0], thread: [78,0,0] Assertion `ind >=0 && ind < ind_dim_size && \"vectorized gather kernel index out of bounds\"` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/IndexKernelUtils.cu:16: vectorized_gather_kernel: block: [30,0,0], thread: [79,0,0] Assertion `ind >=0 && ind < ind_dim_size && \"vectorized gather kernel index out of bounds\"` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/IndexKernelUtils.cu:16: vectorized_gather_kernel: block: [30,0,0], thread: [80,0,0] Assertion `ind >=0 && ind < ind_dim_size && \"vectorized gather kernel index out of bounds\"` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/IndexKernelUtils.cu:16: vectorized_gather_kernel: block: [30,0,0], thread: [81,0,0] Assertion `ind >=0 && ind < ind_dim_size && \"vectorized gather kernel index out of bounds\"` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/IndexKernelUtils.cu:16: vectorized_gather_kernel: block: [30,0,0], thread: [82,0,0] Assertion `ind >=0 && ind < ind_dim_size && \"vectorized gather kernel index out of bounds\"` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/IndexKernelUtils.cu:16: vectorized_gather_kernel: block: [30,0,0], thread: [83,0,0] Assertion `ind >=0 && ind < ind_dim_size && \"vectorized gather kernel index out of bounds\"` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/IndexKernelUtils.cu:16: vectorized_gather_kernel: block: [30,0,0], thread: [84,0,0] Assertion `ind >=0 && ind < ind_dim_size && \"vectorized gather kernel index out of bounds\"` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/IndexKernelUtils.cu:16: vectorized_gather_kernel: block: [30,0,0], thread: [85,0,0] Assertion `ind >=0 && ind < ind_dim_size && \"vectorized gather kernel index out of bounds\"` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/IndexKernelUtils.cu:16: vectorized_gather_kernel: block: [30,0,0], thread: [86,0,0] Assertion `ind >=0 && ind < ind_dim_size && \"vectorized gather kernel index out of bounds\"` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/IndexKernelUtils.cu:16: vectorized_gather_kernel: block: [30,0,0], thread: [87,0,0] Assertion `ind >=0 && ind < ind_dim_size && \"vectorized gather kernel index out of bounds\"` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/IndexKernelUtils.cu:16: vectorized_gather_kernel: block: [30,0,0], thread: [88,0,0] Assertion `ind >=0 && ind < ind_dim_size && \"vectorized gather kernel index out of bounds\"` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/IndexKernelUtils.cu:16: vectorized_gather_kernel: block: [30,0,0], thread: [89,0,0] Assertion `ind >=0 && ind < ind_dim_size && \"vectorized gather kernel index out of bounds\"` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/IndexKernelUtils.cu:16: vectorized_gather_kernel: block: [30,0,0], thread: [90,0,0] Assertion `ind >=0 && ind < ind_dim_size && \"vectorized gather kernel index out of bounds\"` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/IndexKernelUtils.cu:16: vectorized_gather_kernel: block: [30,0,0], thread: [91,0,0] Assertion `ind >=0 && ind < ind_dim_size && \"vectorized gather kernel index out of bounds\"` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/IndexKernelUtils.cu:16: vectorized_gather_kernel: block: [30,0,0], thread: [92,0,0] Assertion `ind >=0 && ind < ind_dim_size && \"vectorized gather kernel index out of bounds\"` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/IndexKernelUtils.cu:16: vectorized_gather_kernel: block: [30,0,0], thread: [93,0,0] Assertion `ind >=0 && ind < ind_dim_size && \"vectorized gather kernel index out of bounds\"` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/IndexKernelUtils.cu:16: vectorized_gather_kernel: block: [30,0,0], thread: [94,0,0] Assertion `ind >=0 && ind < ind_dim_size && \"vectorized gather kernel index out of bounds\"` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/IndexKernelUtils.cu:16: vectorized_gather_kernel: block: [30,0,0], thread: [95,0,0] Assertion `ind >=0 && ind < ind_dim_size && \"vectorized gather kernel index out of bounds\"` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/IndexKernelUtils.cu:16: vectorized_gather_kernel: block: [30,0,0], thread: [32,0,0] Assertion `ind >=0 && ind < ind_dim_size && \"vectorized gather kernel index out of bounds\"` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/IndexKernelUtils.cu:16: vectorized_gather_kernel: block: [30,0,0], thread: [33,0,0] Assertion `ind >=0 && ind < ind_dim_size && \"vectorized gather kernel index out of bounds\"` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/IndexKernelUtils.cu:16: vectorized_gather_kernel: block: [30,0,0], thread: [34,0,0] Assertion `ind >=0 && ind < ind_dim_size && \"vectorized gather kernel index out of bounds\"` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/IndexKernelUtils.cu:16: vectorized_gather_kernel: block: [30,0,0], thread: [35,0,0] Assertion `ind >=0 && ind < ind_dim_size && \"vectorized gather kernel index out of bounds\"` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/IndexKernelUtils.cu:16: vectorized_gather_kernel: block: [30,0,0], thread: [36,0,0] Assertion `ind >=0 && ind < ind_dim_size && \"vectorized gather kernel index out of bounds\"` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/IndexKernelUtils.cu:16: vectorized_gather_kernel: block: [30,0,0], thread: [37,0,0] Assertion `ind >=0 && ind < ind_dim_size && \"vectorized gather kernel index out of bounds\"` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/IndexKernelUtils.cu:16: vectorized_gather_kernel: block: [30,0,0], thread: [38,0,0] Assertion `ind >=0 && ind < ind_dim_size && \"vectorized gather kernel index out of bounds\"` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/IndexKernelUtils.cu:16: vectorized_gather_kernel: block: [30,0,0], thread: [39,0,0] Assertion `ind >=0 && ind < ind_dim_size && \"vectorized gather kernel index out of bounds\"` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/IndexKernelUtils.cu:16: vectorized_gather_kernel: block: [30,0,0], thread: [40,0,0] Assertion `ind >=0 && ind < ind_dim_size && \"vectorized gather kernel index out of bounds\"` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/IndexKernelUtils.cu:16: vectorized_gather_kernel: block: [30,0,0], thread: [41,0,0] Assertion `ind >=0 && ind < ind_dim_size && \"vectorized gather kernel index out of bounds\"` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/IndexKernelUtils.cu:16: vectorized_gather_kernel: block: [30,0,0], thread: [42,0,0] Assertion `ind >=0 && ind < ind_dim_size && \"vectorized gather kernel index out of bounds\"` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/IndexKernelUtils.cu:16: vectorized_gather_kernel: block: [30,0,0], thread: [43,0,0] Assertion `ind >=0 && ind < ind_dim_size && \"vectorized gather kernel index out of bounds\"` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/IndexKernelUtils.cu:16: vectorized_gather_kernel: block: [30,0,0], thread: [44,0,0] Assertion `ind >=0 && ind < ind_dim_size && \"vectorized gather kernel index out of bounds\"` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/IndexKernelUtils.cu:16: vectorized_gather_kernel: block: [30,0,0], thread: [45,0,0] Assertion `ind >=0 && ind < ind_dim_size && \"vectorized gather kernel index out of bounds\"` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/IndexKernelUtils.cu:16: vectorized_gather_kernel: block: [30,0,0], thread: [46,0,0] Assertion `ind >=0 && ind < ind_dim_size && \"vectorized gather kernel index out of bounds\"` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/IndexKernelUtils.cu:16: vectorized_gather_kernel: block: [30,0,0], thread: [47,0,0] Assertion `ind >=0 && ind < ind_dim_size && \"vectorized gather kernel index out of bounds\"` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/IndexKernelUtils.cu:16: vectorized_gather_kernel: block: [30,0,0], thread: [48,0,0] Assertion `ind >=0 && ind < ind_dim_size && \"vectorized gather kernel index out of bounds\"` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/IndexKernelUtils.cu:16: vectorized_gather_kernel: block: [30,0,0], thread: [49,0,0] Assertion `ind >=0 && ind < ind_dim_size && \"vectorized gather kernel index out of bounds\"` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/IndexKernelUtils.cu:16: vectorized_gather_kernel: block: [30,0,0], thread: [50,0,0] Assertion `ind >=0 && ind < ind_dim_size && \"vectorized gather kernel index out of bounds\"` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/IndexKernelUtils.cu:16: vectorized_gather_kernel: block: [30,0,0], thread: [51,0,0] Assertion `ind >=0 && ind < ind_dim_size && \"vectorized gather kernel index out of bounds\"` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/IndexKernelUtils.cu:16: vectorized_gather_kernel: block: [30,0,0], thread: [52,0,0] Assertion `ind >=0 && ind < ind_dim_size && \"vectorized gather kernel index out of bounds\"` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/IndexKernelUtils.cu:16: vectorized_gather_kernel: block: [30,0,0], thread: [53,0,0] Assertion `ind >=0 && ind < ind_dim_size && \"vectorized gather kernel index out of bounds\"` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/IndexKernelUtils.cu:16: vectorized_gather_kernel: block: [30,0,0], thread: [54,0,0] Assertion `ind >=0 && ind < ind_dim_size && \"vectorized gather kernel index out of bounds\"` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/IndexKernelUtils.cu:16: vectorized_gather_kernel: block: [30,0,0], thread: [55,0,0] Assertion `ind >=0 && ind < ind_dim_size && \"vectorized gather kernel index out of bounds\"` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/IndexKernelUtils.cu:16: vectorized_gather_kernel: block: [30,0,0], thread: [56,0,0] Assertion `ind >=0 && ind < ind_dim_size && \"vectorized gather kernel index out of bounds\"` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/IndexKernelUtils.cu:16: vectorized_gather_kernel: block: [30,0,0], thread: [57,0,0] Assertion `ind >=0 && ind < ind_dim_size && \"vectorized gather kernel index out of bounds\"` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/IndexKernelUtils.cu:16: vectorized_gather_kernel: block: [30,0,0], thread: [58,0,0] Assertion `ind >=0 && ind < ind_dim_size && \"vectorized gather kernel index out of bounds\"` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/IndexKernelUtils.cu:16: vectorized_gather_kernel: block: [30,0,0], thread: [59,0,0] Assertion `ind >=0 && ind < ind_dim_size && \"vectorized gather kernel index out of bounds\"` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/IndexKernelUtils.cu:16: vectorized_gather_kernel: block: [30,0,0], thread: [60,0,0] Assertion `ind >=0 && ind < ind_dim_size && \"vectorized gather kernel index out of bounds\"` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/IndexKernelUtils.cu:16: vectorized_gather_kernel: block: [30,0,0], thread: [61,0,0] Assertion `ind >=0 && ind < ind_dim_size && \"vectorized gather kernel index out of bounds\"` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/IndexKernelUtils.cu:16: vectorized_gather_kernel: block: [30,0,0], thread: [62,0,0] Assertion `ind >=0 && ind < ind_dim_size && \"vectorized gather kernel index out of bounds\"` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/IndexKernelUtils.cu:16: vectorized_gather_kernel: block: [30,0,0], thread: [63,0,0] Assertion `ind >=0 && ind < ind_dim_size && \"vectorized gather kernel index out of bounds\"` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/IndexKernelUtils.cu:16: vectorized_gather_kernel: block: [30,0,0], thread: [96,0,0] Assertion `ind >=0 && ind < ind_dim_size && \"vectorized gather kernel index out of bounds\"` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/IndexKernelUtils.cu:16: vectorized_gather_kernel: block: [30,0,0], thread: [97,0,0] Assertion `ind >=0 && ind < ind_dim_size && \"vectorized gather kernel index out of bounds\"` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/IndexKernelUtils.cu:16: vectorized_gather_kernel: block: [30,0,0], thread: [98,0,0] Assertion `ind >=0 && ind < ind_dim_size && \"vectorized gather kernel index out of bounds\"` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/IndexKernelUtils.cu:16: vectorized_gather_kernel: block: [30,0,0], thread: [99,0,0] Assertion `ind >=0 && ind < ind_dim_size && \"vectorized gather kernel index out of bounds\"` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/IndexKernelUtils.cu:16: vectorized_gather_kernel: block: [30,0,0], thread: [100,0,0] Assertion `ind >=0 && ind < ind_dim_size && \"vectorized gather kernel index out of bounds\"` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/IndexKernelUtils.cu:16: vectorized_gather_kernel: block: [30,0,0], thread: [101,0,0] Assertion `ind >=0 && ind < ind_dim_size && \"vectorized gather kernel index out of bounds\"` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/IndexKernelUtils.cu:16: vectorized_gather_kernel: block: [30,0,0], thread: [102,0,0] Assertion `ind >=0 && ind < ind_dim_size && \"vectorized gather kernel index out of bounds\"` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/IndexKernelUtils.cu:16: vectorized_gather_kernel: block: [30,0,0], thread: [103,0,0] Assertion `ind >=0 && ind < ind_dim_size && \"vectorized gather kernel index out of bounds\"` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/IndexKernelUtils.cu:16: vectorized_gather_kernel: block: [30,0,0], thread: [104,0,0] Assertion `ind >=0 && ind < ind_dim_size && \"vectorized gather kernel index out of bounds\"` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/IndexKernelUtils.cu:16: vectorized_gather_kernel: block: [30,0,0], thread: [105,0,0] Assertion `ind >=0 && ind < ind_dim_size && \"vectorized gather kernel index out of bounds\"` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/IndexKernelUtils.cu:16: vectorized_gather_kernel: block: [30,0,0], thread: [106,0,0] Assertion `ind >=0 && ind < ind_dim_size && \"vectorized gather kernel index out of bounds\"` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/IndexKernelUtils.cu:16: vectorized_gather_kernel: block: [30,0,0], thread: [107,0,0] Assertion `ind >=0 && ind < ind_dim_size && \"vectorized gather kernel index out of bounds\"` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/IndexKernelUtils.cu:16: vectorized_gather_kernel: block: [30,0,0], thread: [108,0,0] Assertion `ind >=0 && ind < ind_dim_size && \"vectorized gather kernel index out of bounds\"` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/IndexKernelUtils.cu:16: vectorized_gather_kernel: block: [30,0,0], thread: [109,0,0] Assertion `ind >=0 && ind < ind_dim_size && \"vectorized gather kernel index out of bounds\"` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/IndexKernelUtils.cu:16: vectorized_gather_kernel: block: [30,0,0], thread: [110,0,0] Assertion `ind >=0 && ind < ind_dim_size && \"vectorized gather kernel index out of bounds\"` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/IndexKernelUtils.cu:16: vectorized_gather_kernel: block: [30,0,0], thread: [111,0,0] Assertion `ind >=0 && ind < ind_dim_size && \"vectorized gather kernel index out of bounds\"` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/IndexKernelUtils.cu:16: vectorized_gather_kernel: block: [30,0,0], thread: [112,0,0] Assertion `ind >=0 && ind < ind_dim_size && \"vectorized gather kernel index out of bounds\"` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/IndexKernelUtils.cu:16: vectorized_gather_kernel: block: [30,0,0], thread: [113,0,0] Assertion `ind >=0 && ind < ind_dim_size && \"vectorized gather kernel index out of bounds\"` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/IndexKernelUtils.cu:16: vectorized_gather_kernel: block: [30,0,0], thread: [114,0,0] Assertion `ind >=0 && ind < ind_dim_size && \"vectorized gather kernel index out of bounds\"` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/IndexKernelUtils.cu:16: vectorized_gather_kernel: block: [30,0,0], thread: [115,0,0] Assertion `ind >=0 && ind < ind_dim_size && \"vectorized gather kernel index out of bounds\"` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/IndexKernelUtils.cu:16: vectorized_gather_kernel: block: [30,0,0], thread: [116,0,0] Assertion `ind >=0 && ind < ind_dim_size && \"vectorized gather kernel index out of bounds\"` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/IndexKernelUtils.cu:16: vectorized_gather_kernel: block: [30,0,0], thread: [117,0,0] Assertion `ind >=0 && ind < ind_dim_size && \"vectorized gather kernel index out of bounds\"` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/IndexKernelUtils.cu:16: vectorized_gather_kernel: block: [30,0,0], thread: [118,0,0] Assertion `ind >=0 && ind < ind_dim_size && \"vectorized gather kernel index out of bounds\"` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/IndexKernelUtils.cu:16: vectorized_gather_kernel: block: [30,0,0], thread: [119,0,0] Assertion `ind >=0 && ind < ind_dim_size && \"vectorized gather kernel index out of bounds\"` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/IndexKernelUtils.cu:16: vectorized_gather_kernel: block: [30,0,0], thread: [120,0,0] Assertion `ind >=0 && ind < ind_dim_size && \"vectorized gather kernel index out of bounds\"` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/IndexKernelUtils.cu:16: vectorized_gather_kernel: block: [30,0,0], thread: [121,0,0] Assertion `ind >=0 && ind < ind_dim_size && \"vectorized gather kernel index out of bounds\"` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/IndexKernelUtils.cu:16: vectorized_gather_kernel: block: [30,0,0], thread: [122,0,0] Assertion `ind >=0 && ind < ind_dim_size && \"vectorized gather kernel index out of bounds\"` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/IndexKernelUtils.cu:16: vectorized_gather_kernel: block: [30,0,0], thread: [123,0,0] Assertion `ind >=0 && ind < ind_dim_size && \"vectorized gather kernel index out of bounds\"` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/IndexKernelUtils.cu:16: vectorized_gather_kernel: block: [30,0,0], thread: [124,0,0] Assertion `ind >=0 && ind < ind_dim_size && \"vectorized gather kernel index out of bounds\"` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/IndexKernelUtils.cu:16: vectorized_gather_kernel: block: [30,0,0], thread: [125,0,0] Assertion `ind >=0 && ind < ind_dim_size && \"vectorized gather kernel index out of bounds\"` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/IndexKernelUtils.cu:16: vectorized_gather_kernel: block: [30,0,0], thread: [126,0,0] Assertion `ind >=0 && ind < ind_dim_size && \"vectorized gather kernel index out of bounds\"` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/IndexKernelUtils.cu:16: vectorized_gather_kernel: block: [30,0,0], thread: [127,0,0] Assertion `ind >=0 && ind < ind_dim_size && \"vectorized gather kernel index out of bounds\"` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/IndexKernelUtils.cu:16: vectorized_gather_kernel: block: [0,0,0], thread: [96,0,0] Assertion `ind >=0 && ind < ind_dim_size && \"vectorized gather kernel index out of bounds\"` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/IndexKernelUtils.cu:16: vectorized_gather_kernel: block: [0,0,0], thread: [97,0,0] Assertion `ind >=0 && ind < ind_dim_size && \"vectorized gather kernel index out of bounds\"` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/IndexKernelUtils.cu:16: vectorized_gather_kernel: block: [0,0,0], thread: [98,0,0] Assertion `ind >=0 && ind < ind_dim_size && \"vectorized gather kernel index out of bounds\"` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/IndexKernelUtils.cu:16: vectorized_gather_kernel: block: [0,0,0], thread: [99,0,0] Assertion `ind >=0 && ind < ind_dim_size && \"vectorized gather kernel index out of bounds\"` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/IndexKernelUtils.cu:16: vectorized_gather_kernel: block: [0,0,0], thread: [100,0,0] Assertion `ind >=0 && ind < ind_dim_size && \"vectorized gather kernel index out of bounds\"` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/IndexKernelUtils.cu:16: vectorized_gather_kernel: block: [0,0,0], thread: [101,0,0] Assertion `ind >=0 && ind < ind_dim_size && \"vectorized gather kernel index out of bounds\"` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/IndexKernelUtils.cu:16: vectorized_gather_kernel: block: [0,0,0], thread: [102,0,0] Assertion `ind >=0 && ind < ind_dim_size && \"vectorized gather kernel index out of bounds\"` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/IndexKernelUtils.cu:16: vectorized_gather_kernel: block: [0,0,0], thread: [103,0,0] Assertion `ind >=0 && ind < ind_dim_size && \"vectorized gather kernel index out of bounds\"` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/IndexKernelUtils.cu:16: vectorized_gather_kernel: block: [0,0,0], thread: [104,0,0] Assertion `ind >=0 && ind < ind_dim_size && \"vectorized gather kernel index out of bounds\"` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/IndexKernelUtils.cu:16: vectorized_gather_kernel: block: [0,0,0], thread: [105,0,0] Assertion `ind >=0 && ind < ind_dim_size && \"vectorized gather kernel index out of bounds\"` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/IndexKernelUtils.cu:16: vectorized_gather_kernel: block: [0,0,0], thread: [106,0,0] Assertion `ind >=0 && ind < ind_dim_size && \"vectorized gather kernel index out of bounds\"` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/IndexKernelUtils.cu:16: vectorized_gather_kernel: block: [0,0,0], thread: [107,0,0] Assertion `ind >=0 && ind < ind_dim_size && \"vectorized gather kernel index out of bounds\"` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/IndexKernelUtils.cu:16: vectorized_gather_kernel: block: [0,0,0], thread: [108,0,0] Assertion `ind >=0 && ind < ind_dim_size && \"vectorized gather kernel index out of bounds\"` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/IndexKernelUtils.cu:16: vectorized_gather_kernel: block: [0,0,0], thread: [109,0,0] Assertion `ind >=0 && ind < ind_dim_size && \"vectorized gather kernel index out of bounds\"` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/IndexKernelUtils.cu:16: vectorized_gather_kernel: block: [0,0,0], thread: [110,0,0] Assertion `ind >=0 && ind < ind_dim_size && \"vectorized gather kernel index out of bounds\"` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/IndexKernelUtils.cu:16: vectorized_gather_kernel: block: [0,0,0], thread: [111,0,0] Assertion `ind >=0 && ind < ind_dim_size && \"vectorized gather kernel index out of bounds\"` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/IndexKernelUtils.cu:16: vectorized_gather_kernel: block: [0,0,0], thread: [112,0,0] Assertion `ind >=0 && ind < ind_dim_size && \"vectorized gather kernel index out of bounds\"` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/IndexKernelUtils.cu:16: vectorized_gather_kernel: block: [0,0,0], thread: [113,0,0] Assertion `ind >=0 && ind < ind_dim_size && \"vectorized gather kernel index out of bounds\"` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/IndexKernelUtils.cu:16: vectorized_gather_kernel: block: [0,0,0], thread: [114,0,0] Assertion `ind >=0 && ind < ind_dim_size && \"vectorized gather kernel index out of bounds\"` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/IndexKernelUtils.cu:16: vectorized_gather_kernel: block: [0,0,0], thread: [115,0,0] Assertion `ind >=0 && ind < ind_dim_size && \"vectorized gather kernel index out of bounds\"` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/IndexKernelUtils.cu:16: vectorized_gather_kernel: block: [0,0,0], thread: [116,0,0] Assertion `ind >=0 && ind < ind_dim_size && \"vectorized gather kernel index out of bounds\"` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/IndexKernelUtils.cu:16: vectorized_gather_kernel: block: [0,0,0], thread: [117,0,0] Assertion `ind >=0 && ind < ind_dim_size && \"vectorized gather kernel index out of bounds\"` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/IndexKernelUtils.cu:16: vectorized_gather_kernel: block: [0,0,0], thread: [118,0,0] Assertion `ind >=0 && ind < ind_dim_size && \"vectorized gather kernel index out of bounds\"` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/IndexKernelUtils.cu:16: vectorized_gather_kernel: block: [0,0,0], thread: [119,0,0] Assertion `ind >=0 && ind < ind_dim_size && \"vectorized gather kernel index out of bounds\"` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/IndexKernelUtils.cu:16: vectorized_gather_kernel: block: [0,0,0], thread: [120,0,0] Assertion `ind >=0 && ind < ind_dim_size && \"vectorized gather kernel index out of bounds\"` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/IndexKernelUtils.cu:16: vectorized_gather_kernel: block: [0,0,0], thread: [121,0,0] Assertion `ind >=0 && ind < ind_dim_size && \"vectorized gather kernel index out of bounds\"` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/IndexKernelUtils.cu:16: vectorized_gather_kernel: block: [0,0,0], thread: [122,0,0] Assertion `ind >=0 && ind < ind_dim_size && \"vectorized gather kernel index out of bounds\"` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/IndexKernelUtils.cu:16: vectorized_gather_kernel: block: [0,0,0], thread: [123,0,0] Assertion `ind >=0 && ind < ind_dim_size && \"vectorized gather kernel index out of bounds\"` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/IndexKernelUtils.cu:16: vectorized_gather_kernel: block: [0,0,0], thread: [124,0,0] Assertion `ind >=0 && ind < ind_dim_size && \"vectorized gather kernel index out of bounds\"` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/IndexKernelUtils.cu:16: vectorized_gather_kernel: block: [0,0,0], thread: [125,0,0] Assertion `ind >=0 && ind < ind_dim_size && \"vectorized gather kernel index out of bounds\"` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/IndexKernelUtils.cu:16: vectorized_gather_kernel: block: [0,0,0], thread: [126,0,0] Assertion `ind >=0 && ind < ind_dim_size && \"vectorized gather kernel index out of bounds\"` failed.\n",
      "/pytorch/aten/src/ATen/native/cuda/IndexKernelUtils.cu:16: vectorized_gather_kernel: block: [0,0,0], thread: [127,0,0] Assertion `ind >=0 && ind < ind_dim_size && \"vectorized gather kernel index out of bounds\"` failed.\n"
     ]
    },
    {
     "ename": "AcceleratorError",
     "evalue": "CUDA error: device-side assert triggered\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAcceleratorError\u001b[39m                          Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[5]\u001b[39m\u001b[32m, line 6\u001b[39m\n\u001b[32m      2\u001b[39m batch = batch_to_device(batch, \u001b[33m\"\u001b[39m\u001b[33mcuda\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m      3\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m torch.autocast(enabled=\u001b[38;5;28;01mTrue\u001b[39;00m, dtype=torch.bfloat16, device_type=\u001b[33m\"\u001b[39m\u001b[33mcuda\u001b[39m\u001b[33m\"\u001b[39m):\n\u001b[32m      4\u001b[39m \u001b[38;5;66;03m# batch[\"pixel_values\"] = batch[\"pixel_values\"].to(torch.bfloat16)\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m6\u001b[39m     pooled_output, hidden_states, image_features, all_layers_embeds, attention_matrix = \u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mencode_input\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/dangnh/VLM_Embed/src/model/model.py:131\u001b[39m, in \u001b[36mMMEBModel.encode_input\u001b[39m\u001b[34m(self, input)\u001b[39m\n\u001b[32m    128\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m pooled_output, image_features, attention_matrix\n\u001b[32m    129\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mmodel_backbone\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;129;01min\u001b[39;00m [LLAVA_QWEN2, QWEN2_VL]:\n\u001b[32m    130\u001b[39m     \u001b[38;5;66;03m# print(\"Encoding input for FastVLM model backbone\")\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m131\u001b[39m     hidden_states = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mencoder\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m    132\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(hidden_states, \u001b[33m'\u001b[39m\u001b[33mbatch_image_embeds\u001b[39m\u001b[33m'\u001b[39m):\n\u001b[32m    133\u001b[39m         image_features = hidden_states.batch_image_embeds\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.conda/envs/vlm2vec/lib/python3.11/site-packages/torch/nn/modules/module.py:1773\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1771\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1772\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1773\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.conda/envs/vlm2vec/lib/python3.11/site-packages/torch/nn/modules/module.py:1784\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1779\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1780\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1781\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1782\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1783\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1784\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1786\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1787\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/dangnh/VLM_Embed/src/model/llava/model/language_model/llava_qwen.py:109\u001b[39m, in \u001b[36mLlavaQwen2ForCausalLM.forward\u001b[39m\u001b[34m(self, input_ids, attention_mask, position_ids, past_key_values, inputs_embeds, labels, use_cache, output_attentions, output_hidden_states, images, image_sizes, return_dict, cache_position)\u001b[39m\n\u001b[32m     88\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m inputs_embeds \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m     89\u001b[39m     \u001b[38;5;66;03m# print(\"Preparing inputs for multimodal forward pass.\")\u001b[39;00m\n\u001b[32m     90\u001b[39m     \u001b[38;5;66;03m# print(f\"Batch size of input_ids: {input_ids.shape[0]}\")\u001b[39;00m\n\u001b[32m     91\u001b[39m     (\n\u001b[32m     92\u001b[39m         input_ids,\n\u001b[32m     93\u001b[39m         position_ids,\n\u001b[32m   (...)\u001b[39m\u001b[32m    106\u001b[39m         image_sizes\n\u001b[32m    107\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m109\u001b[39m output = \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    110\u001b[39m \u001b[43m    \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m=\u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    111\u001b[39m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    112\u001b[39m \u001b[43m    \u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[43m=\u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    113\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    114\u001b[39m \u001b[43m    \u001b[49m\u001b[43minputs_embeds\u001b[49m\u001b[43m=\u001b[49m\u001b[43minputs_embeds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    115\u001b[39m \u001b[43m    \u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    116\u001b[39m \u001b[43m    \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[43m=\u001b[49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    117\u001b[39m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m=\u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    118\u001b[39m \u001b[43m    \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m=\u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    119\u001b[39m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[43m=\u001b[49m\u001b[43mreturn_dict\u001b[49m\n\u001b[32m    120\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    121\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m LlavaQwen2OutputWithPast(\n\u001b[32m    122\u001b[39m     loss=output.loss,\n\u001b[32m    123\u001b[39m     logits=output.logits,\n\u001b[32m   (...)\u001b[39m\u001b[32m    127\u001b[39m     batch_image_embeds=image_features\n\u001b[32m    128\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.conda/envs/vlm2vec/lib/python3.11/site-packages/transformers/utils/generic.py:940\u001b[39m, in \u001b[36mcan_return_tuple.<locals>.wrapper\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m    938\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m return_dict_passed \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    939\u001b[39m     return_dict = return_dict_passed\n\u001b[32m--> \u001b[39m\u001b[32m940\u001b[39m output = \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    941\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m return_dict \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(output, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[32m    942\u001b[39m     output = output.to_tuple()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/dangnh/VLM_Embed/src/model/llava/model/language_model/modeling_qwen2.py:449\u001b[39m, in \u001b[36mQwen2ForCausalLM.forward\u001b[39m\u001b[34m(self, input_ids, attention_mask, position_ids, past_key_values, inputs_embeds, labels, use_cache, cache_position, logits_to_keep, **kwargs)\u001b[39m\n\u001b[32m    417\u001b[39m \u001b[38;5;129m@can_return_tuple\u001b[39m\n\u001b[32m    418\u001b[39m \u001b[38;5;129m@auto_docstring\u001b[39m\n\u001b[32m    419\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\n\u001b[32m   (...)\u001b[39m\u001b[32m    430\u001b[39m     **kwargs: Unpack[TransformersKwargs],\n\u001b[32m    431\u001b[39m ) -> CausalLMOutputWithPast:\n\u001b[32m    432\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33mr\u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    433\u001b[39m \u001b[33;03m    Example:\u001b[39;00m\n\u001b[32m    434\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m    447\u001b[39m \u001b[33;03m    \"Hey, are you conscious? Can you talk to me?\\nI'm not conscious, but I can talk to you.\"\u001b[39;00m\n\u001b[32m    448\u001b[39m \u001b[33;03m    ```\"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m449\u001b[39m     outputs: BaseModelOutputWithPast = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    450\u001b[39m \u001b[43m        \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m=\u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    451\u001b[39m \u001b[43m        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    452\u001b[39m \u001b[43m        \u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[43m=\u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    453\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    454\u001b[39m \u001b[43m        \u001b[49m\u001b[43minputs_embeds\u001b[49m\u001b[43m=\u001b[49m\u001b[43minputs_embeds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    455\u001b[39m \u001b[43m        \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[43m=\u001b[49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    456\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcache_position\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcache_position\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    457\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    458\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    460\u001b[39m     hidden_states = outputs.last_hidden_state\n\u001b[32m    461\u001b[39m     \u001b[38;5;66;03m# Only compute necessary logits, and do not upcast them to float if we are not computing the loss\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.conda/envs/vlm2vec/lib/python3.11/site-packages/torch/nn/modules/module.py:1773\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1771\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1772\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1773\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.conda/envs/vlm2vec/lib/python3.11/site-packages/torch/nn/modules/module.py:1784\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1779\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1780\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1781\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1782\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1783\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1784\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1786\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1787\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.conda/envs/vlm2vec/lib/python3.11/site-packages/transformers/utils/generic.py:1064\u001b[39m, in \u001b[36mcheck_model_inputs.<locals>.wrapper\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1061\u001b[39m                 module.forward = make_capture_wrapper(module, original_forward, key, specs.index)\n\u001b[32m   1062\u001b[39m                 monkey_patched_layers.append((module, original_forward))\n\u001b[32m-> \u001b[39m\u001b[32m1064\u001b[39m outputs = \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1065\u001b[39m \u001b[38;5;66;03m# Restore original forward methods\u001b[39;00m\n\u001b[32m   1066\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m module, original_forward \u001b[38;5;129;01min\u001b[39;00m monkey_patched_layers:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/dangnh/VLM_Embed/src/model/llava/model/language_model/modeling_qwen2.py:352\u001b[39m, in \u001b[36mQwen2Model.forward\u001b[39m\u001b[34m(self, input_ids, attention_mask, position_ids, past_key_values, inputs_embeds, use_cache, cache_position, **kwargs)\u001b[39m\n\u001b[32m    350\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m cache_position \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    351\u001b[39m     past_seen_tokens = past_key_values.get_seq_length() \u001b[38;5;28;01mif\u001b[39;00m past_key_values \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[32m0\u001b[39m\n\u001b[32m--> \u001b[39m\u001b[32m352\u001b[39m     cache_position = \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43marange\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    353\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpast_seen_tokens\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpast_seen_tokens\u001b[49m\u001b[43m \u001b[49m\u001b[43m+\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs_embeds\u001b[49m\u001b[43m.\u001b[49m\u001b[43mshape\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m=\u001b[49m\u001b[43minputs_embeds\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdevice\u001b[49m\n\u001b[32m    354\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    356\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m position_ids \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    357\u001b[39m     position_ids = cache_position.unsqueeze(\u001b[32m0\u001b[39m)\n",
      "\u001b[31mAcceleratorError\u001b[39m: CUDA error: device-side assert triggered\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n"
     ]
    }
   ],
   "source": [
    "for batch in eval_qry_loader:\n",
    "    batch = batch_to_device(batch, \"cuda\")\n",
    "    with torch.autocast(enabled=True, dtype=torch.bfloat16, device_type=\"cuda\"):\n",
    "    # batch[\"pixel_values\"] = batch[\"pixel_values\"].to(torch.bfloat16)\n",
    "    \n",
    "        pooled_output, hidden_states, image_features, all_layers_embeds, attention_matrix = model.encode_input(batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89c123ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(\"test\", \"output_t_qry.pkl\"), \"wb\") as f:\n",
    "    pickle.dump({\n",
    "        \"pooled_output\": pooled_output,\n",
    "        \"hidden_states\": hidden_states,\n",
    "        \"image_features\": image_features,\n",
    "        \"all_layers_embeds\": all_layers_embeds,\n",
    "        \"attention_matrix\": attention_matrix,\n",
    "        \"input_data\": batch,\n",
    "    }, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d31685f2",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'os' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(\u001b[43mos\u001b[49m.path.join(\u001b[33m\"\u001b[39m\u001b[33mtest\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33moutput_s_qry.pkl\u001b[39m\u001b[33m\"\u001b[39m), \u001b[33m\"\u001b[39m\u001b[33mrb\u001b[39m\u001b[33m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[32m      2\u001b[39m     x = pickle.load(f)\n",
      "\u001b[31mNameError\u001b[39m: name 'os' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "with open(os.path.join(\"test\", \"output_s_qry.pkl\"), \"rb\") as f:\n",
    "    x = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e79ac91",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(\"test\", \"output_t_qry.pkl\"), \"rb\") as f:\n",
    "    y = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0ac4f99",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 12, 278, 278])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y['attention_matrix'][0].size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "891c8f26",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(x['image_features'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f58f5f7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(\"test\", \"output_s_qry.pkl\"), \"wb\") as f:\n",
    "    pickle.dump({\n",
    "        \"pooled_output\": pooled_output,\n",
    "        \"hidden_states\": hidden_states,\n",
    "        \"image_features\": image_features,\n",
    "        \"all_layers_embeds\": all_layers_embeds,\n",
    "        \"attention_matrix\": attention_matrix,\n",
    "        \"input_data\": batch,\n",
    "    }, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ddb1c89",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf33f71a",
   "metadata": {},
   "outputs": [],
   "source": [
    "!export CUDA_LAUNCH_BLOCKING=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d8e41ae",
   "metadata": {},
   "outputs": [
    {
     "ename": "AcceleratorError",
     "evalue": "CUDA error: device-side assert triggered\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAcceleratorError\u001b[39m                          Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[20]\u001b[39m\u001b[32m, line 12\u001b[39m\n\u001b[32m      9\u001b[39m             \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[32m     11\u001b[39m gc.collect()\n\u001b[32m---> \u001b[39m\u001b[32m12\u001b[39m \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcuda\u001b[49m\u001b[43m.\u001b[49m\u001b[43mempty_cache\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     13\u001b[39m torch.cuda.synchronize()\n\u001b[32m     15\u001b[39m \u001b[38;5;66;03m# optional: reset tracking and print status\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.conda/envs/vlm2vec/lib/python3.11/site-packages/torch/cuda/memory.py:224\u001b[39m, in \u001b[36mempty_cache\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m    213\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33mr\u001b[39m\u001b[33;03m\"\"\"Release all unoccupied cached memory currently held by the caching\u001b[39;00m\n\u001b[32m    214\u001b[39m \u001b[33;03mallocator so that those can be used in other GPU application and visible in\u001b[39;00m\n\u001b[32m    215\u001b[39m \u001b[33;03m`nvidia-smi`.\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    221\u001b[39m \u001b[33;03m    more details about GPU memory management.\u001b[39;00m\n\u001b[32m    222\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    223\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m is_initialized():\n\u001b[32m--> \u001b[39m\u001b[32m224\u001b[39m     \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_C\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_cuda_emptyCache\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mAcceleratorError\u001b[39m: CUDA error: device-side assert triggered\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n"
     ]
    }
   ],
   "source": [
    "import gc, torch\n",
    "\n",
    "# delete references to large tensors/models you created\n",
    "for name in (\"batch\", \"pooled_output\", \"image_features\", \"attention_matrix\", \"model\"):\n",
    "    if name in globals():\n",
    "        try:\n",
    "            del globals()[name]\n",
    "        except Exception:\n",
    "            pass\n",
    "\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()\n",
    "torch.cuda.synchronize()\n",
    "\n",
    "# optional: reset tracking and print status\n",
    "for i in range(torch.cuda.device_count()):\n",
    "    torch.cuda.reset_peak_memory_stats(i)\n",
    "print(\"allocated:\", torch.cuda.memory_allocated(), \"cached:\", torch.cuda.memory_reserved())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb4bcb57",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"/home/user2/dangnh/VLM_Embed/test/output_t_qry.pkl\", 'rb') as file:\n",
    "    # Use pickle.load() to read the byte stream and deserialize the object\n",
    "    loaded_object = pickle.load(file)\n",
    "    # load to cuda\n",
    "    loaded_object = {k: v.to(\"cuda\") if isinstance(v, torch.Tensor) else v for k, v in loaded_object.items()}\n",
    "    t_qry_reps, t_qry_hidden_states, t_qry_img_feats, t_qry_layers_embeds, t_qry_attention, t_qry_input_data = \\\n",
    "                                                                                loaded_object.values()\n",
    "    t_pos_reps, t_pos_hidden_states, t_pos_img_feats, t_pos_layers_embeds, t_pos_attention, t_pos_input_data = \\\n",
    "                                                                                loaded_object.values()\n",
    "    \n",
    "with open(\"/home/user2/dangnh/VLM_Embed/test/output_s_qry.pkl\", 'rb') as file:\n",
    "    # Use pickle.load() to read the byte stream and deserialize the object\n",
    "    loaded_object = pickle.load(file)\n",
    "    loaded_object = {k: v.to(\"cuda\") if isinstance(v, torch.Tensor) else v for k, v in loaded_object.items()}\n",
    "\n",
    "    s_qry_reps, s_qry_hidden_states, s_qry_img_feats, s_qry_layers_embeds, s_qry_attention, s_qry_input_data = \\\n",
    "                                                                loaded_object.values()\n",
    "    s_pos_reps, s_pos_hidden_states, s_pos_img_feats, s_pos_layers_embeds, s_pos_attention, s_pos_input_data = \\\n",
    "                                                                loaded_object.values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1de947de",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[106]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43mmodel\u001b[49m\n",
      "\u001b[31mNameError\u001b[39m: name 'model' is not defined"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8ad7532a",
   "metadata": {},
   "source": [
    "# Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f3c2f13f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn \n",
    "import torch.distributed as dist\n",
    "import torch.nn.functional as F\n",
    "from src.criterions.soft_DTW import SoftDTW\n",
    "import ot\n",
    "# ot.backend.get_backend('pytorch')\n",
    "\n",
    "def create_semi_orthogonal_matrix(tensor):\n",
    "    rows, cols = tensor.shape\n",
    "    if rows >= cols:\n",
    "        # QR trực tiếp\n",
    "        a = torch.randn(rows, cols, device=tensor.device, dtype=tensor.dtype)\n",
    "        q, _ = torch.linalg.qr(a, mode='reduced')\n",
    "        tensor.data[:] = q[:, :cols]\n",
    "    else:\n",
    "        # QR trên ma trận transpose để đảm bảo W W^T = I\n",
    "        a = torch.randn(cols, rows, device=tensor.device, dtype=tensor.dtype)\n",
    "        q, _ = torch.linalg.qr(a, mode='reduced')\n",
    "        tensor.data[:] = q.T[:rows, :]\n",
    "    return tensor\n",
    "\n",
    "class Distiller(nn.Module):\n",
    "    def __init__(self, model_args, training_args, device):\n",
    "        super(Distiller, self).__init__()\n",
    "        self.model_args = model_args\n",
    "        self.training_args = training_args\n",
    "        self.device = device\n",
    "\n",
    "        self.student_hidden_dim = 896\n",
    "        self.teacher_hidden_dim = 1536\n",
    "        self.temperature = 0.02\n",
    "        self.set_projector()\n",
    "        print(\"Projectors set.\")\n",
    "\n",
    "        self.t2s_img_align = nn.Sequential(\n",
    "            nn.Linear(self.teacher_hidden_dim, self.student_hidden_dim),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        self.t2s_img_align.to(device=\"cuda\")\n",
    "\n",
    "        # for simple kd\n",
    "        self.last_layer_projector = nn.Sequential(\n",
    "            nn.Linear(self.teacher_hidden_dim, self.student_hidden_dim),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        self.last_layer_projector.to(device=\"cuda\")\n",
    "\n",
    "        # for Soft-DTW\n",
    "        self.num_chosen_hidden_states = 3\n",
    "        self.t2s = nn.ModuleList([\n",
    "            nn.Sequential(\n",
    "                nn.Linear(self.teacher_hidden_dim, self.student_hidden_dim),\n",
    "                nn.ReLU()\n",
    "            )       \n",
    "        ] * self.num_chosen_hidden_states)\n",
    "\n",
    "        self.t2s.to(device=\"cuda\")\n",
    "        \n",
    "    def set_projector(self):\n",
    "        self.projectors = nn.ModuleDict()\n",
    "        projector_config = json.load(open(\"/home/user2/dangnh/VLM_Embed/config/projector_config.json\", 'r'))\n",
    "        \n",
    "        name_dict = {\n",
    "            \"s\": self.student_hidden_dim,\n",
    "            \"t\": self.teacher_hidden_dim,\n",
    "            \"relu\": nn.ReLU()\n",
    "        }\n",
    "        \n",
    "        for name, cfg in projector_config.items():\n",
    "            if not cfg.get(\"enabled\", False):\n",
    "                continue\n",
    "            seq = nn.Sequential()\n",
    "            parts = cfg[\"structure\"].split(\"-\")\n",
    "            parsed = []\n",
    "            \n",
    "            for p in parts:\n",
    "                if p == \"relu\":\n",
    "                    parsed.append(\"relu\")\n",
    "                else:\n",
    "                    coef = int(p[:-1]) if len(p) > 1 and p[:-1].isdigit() else 1\n",
    "                    parsed.append(coef * name_dict[p[-1]])\n",
    "            for i in range(len(parsed) -1):\n",
    "                a, b = parsed[i], parsed[i+1]\n",
    "                if isinstance(a, int) and isinstance(b, int):\n",
    "                    layer = nn.Linear(a, b)\n",
    "                    create_semi_orthogonal_matrix(layer.weight)\n",
    "                    seq.append(layer)\n",
    "                elif b == \"relu\":\n",
    "                    seq.append(name_dict[b])\n",
    "                elif a ==\"relu\" and isinstance(b, int):\n",
    "                    prev_out = parsed[i-1] if isinstance(parsed[i-1], int) else None\n",
    "                    layer = nn.Linear(prev_out, b)\n",
    "                    create_semi_orthogonal_matrix(layer.weight)\n",
    "                    seq.append(layer)\n",
    "            self.projectors[name] = seq\n",
    "            print(f\"Projector {name} created with structure: {seq}\")\n",
    "    \n",
    "    def add_optimizer_param_group(self, optimizer):\n",
    "        if hasattr(self, 'projectors'):\n",
    "            lr = 0.001\n",
    "            optimizer.add_param_group({\n",
    "                \"params\": [p for proj in self.projectors.values() for p in proj.parameters()],\n",
    "                \"lr\": lr\n",
    "            })\n",
    "        print(\"Projector parameters added to optimizer.\")\n",
    "        return optimizer\n",
    "\n",
    "class StrongerKD(nn.Module):\n",
    "    def __init__(self, args):\n",
    "        super(StrongerKD, self).__init__()\n",
    "        self.args = args\n",
    "        self.rkd_loss_weight = 0.5\n",
    "        self.simple_kd_weight = 0.5\n",
    "        self.intra_rkd_weight = 0.5\n",
    "        self.cross_modal_kd_weight = 0.01\n",
    "        self.ot_loss_weight = 0.5\n",
    "        self.num_chosen_hidden_states = 3\n",
    "\n",
    "        self.cross_entropy_loss = nn.CrossEntropyLoss()\n",
    "        self.img_align_loss_weight = 0.1\n",
    "        self.sdtw = SoftDTW(use_cuda=True, gamma=0.001)\n",
    "        self.mse_loss = nn.MSELoss(reduction=\"mean\")\n",
    "\n",
    "\n",
    "    def forward(self, distiller, input_data):\n",
    "        self.distiller = Distiller(model_args, training_args, \"cuda\")\n",
    "        # student_model = distiller.student\n",
    "        # teacher_model = distiller.teacher\n",
    "        \n",
    "        with open(\"/home/user2/dangnh/VLM_Embed/test/output_t_qry.pkl\", 'rb') as file:\n",
    "            # Use pickle.load() to read the byte stream and deserialize the object\n",
    "            loaded_object = pickle.load(file)\n",
    "            # load to cuda\n",
    "            loaded_object = {k: v.to(\"cuda\") if isinstance(v, torch.Tensor) else v for k, v in loaded_object.items()}\n",
    "            t_qry_reps, t_qry_hidden_states, t_qry_img_feats, t_qry_layers_embeds, t_qry_attention, t_qry_input_data = \\\n",
    "                                                                                        loaded_object.values()\n",
    "            t_pos_reps, t_pos_hidden_states, t_pos_img_feats, t_pos_layers_embeds, t_pos_attention, t_pos_input_data = \\\n",
    "                                                                                        loaded_object.values()\n",
    "            \n",
    "            # t_qry_hidden_states, t_qry_img_feats = torch.stack(t_qry_hidden_states, dim=0), torch.stack(t_qry_img_feats, dim=0)\n",
    "            # t_pos_hidden_states, t_pos_img_feats = torch.stack(t_pos_hidden_states, dim=0), torch.stack(t_pos_img_feats, dim=0)\n",
    "        with open(\"/home/user2/dangnh/VLM_Embed/test/output_s_qry.pkl\", 'rb') as file:\n",
    "            # Use pickle.load() to read the byte stream and deserialize the object\n",
    "            loaded_object = pickle.load(file)\n",
    "            loaded_object = {k: v.to(\"cuda\") if isinstance(v, torch.Tensor) else v for k, v in loaded_object.items()}\n",
    "\n",
    "            s_qry_reps, s_qry_hidden_states, s_qry_img_feats, s_qry_layers_embeds, s_qry_attention, s_qry_input_data = \\\n",
    "                                                                        loaded_object.values()\n",
    "            s_pos_reps, s_pos_hidden_states, s_pos_img_feats, s_pos_layers_embeds, s_pos_attention, s_pos_input_data = \\\n",
    "                                                                        loaded_object.values()\n",
    "            # s_qry_hidden_states, s_qry_img_feats = torch.stack(s_qry_hidden_states, dim=0), torch.stack(s_qry_img_feats, dim=0)\n",
    "            # s_pos_hidden_states, s_pos_img_feats = torch.stack(s_pos_hidden_states, dim=0), torch.stack(s_pos_img_feats, dim=0)\n",
    "\n",
    "        ## contrastive\n",
    "        # scores = student_model.compute_similarity(s_qry_reps, s_pos_reps)\n",
    "        # scores = scores.view(s_qry_reps.size(0), -1)\n",
    "        # target = torch.arange(scores.size(0), device=scores.device, dtype=torch.long)\n",
    "        # target = target * (s_qry_reps.size(0) // s_pos_reps.size(0))\n",
    "        # contrastive_loss = self.cross_entropy_loss(scores / self.distiller.temperature, target)\n",
    "        contrastive_loss = torch.tensor(0.0).to(\"cuda\")\n",
    "        ## image alignments\n",
    "        img_align_loss = 0.0\n",
    "        cur_idx_qry_img = 0\n",
    "        cur_idx_pos_img = 0\n",
    "        batch_size = s_qry_reps.size(0)\n",
    "\n",
    "        for i in range(batch_size):\n",
    "            if s_qry_img_feats is not None and t_qry_img_feats is not None:\n",
    "                if cur_idx_qry_img < len(s_qry_img_feats) and cur_idx_qry_img < len(t_qry_img_feats):\n",
    "                    tmp_s_qry_img_feats = F.normalize(s_qry_img_feats[i], p=2, dim=-1)\n",
    "                    tmp_t_qry_img_feats = self.distiller.t2s_img_align(t_qry_img_feats[i])\n",
    "\n",
    "                    tmp_t_qry_image_features = F.normalize(tmp_t_qry_img_feats, p=2, dim=-1)\n",
    "\n",
    "                    img_align_loss += self.alignment_loss_mmd(tmp_t_qry_image_features, tmp_s_qry_img_feats)\n",
    "                    cur_idx_qry_img += 1\n",
    "\n",
    "            if s_pos_img_feats is not None and t_pos_img_feats is not None:\n",
    "                if cur_idx_pos_img < len(s_pos_img_feats) and cur_idx_pos_img < len(t_pos_img_feats):\n",
    "                    tmp_s_pos_img_feats = F.normalize(s_pos_img_feats[i], p=2, dim=-1)\n",
    "                    tmp_t_pos_img_feats = self.distiller.t2s_img_align(t_pos_img_feats[i])\n",
    "                    \n",
    "                    tmp_t_pos_image_features = F.normalize(tmp_t_pos_img_feats, p=2, dim=-1)\n",
    "\n",
    "                    img_align_loss += self.alignment_loss_mmd(tmp_t_pos_image_features, tmp_s_pos_img_feats)\n",
    "                    cur_idx_pos_img += 1\n",
    "\n",
    "        img_align_loss = img_align_loss / batch_size\n",
    "\n",
    "        ## data-points rkd \n",
    "        # s_qry_reps = F.normalize(s_qry_reps, p=2, dim=-1)\n",
    "        # s_pos_reps = F.normalize(s_pos_reps, p=2, dim=-1)\n",
    "        # t_qry_reps = F.normalize(t_qry_reps, p=2, dim=-1)\n",
    "        # t_pos_reps = F.normalize(t_pos_reps, p=2, dim=-1)\n",
    "\n",
    "        # qry_distance_loss = self.compute_distance_loss(s_qry_reps, t_qry_reps)\n",
    "        # pos_distance_loss = self.compute_distance_loss(s_pos_reps, t_pos_reps)\n",
    "        # distance_loss = 0.5 * qry_distance_loss + 0.5 * pos_distance_loss\n",
    "\n",
    "        # qry_angle_loss = self.compute_angle_loss(s_qry_reps, t_qry_reps)\n",
    "        # pos_angle_loss = self.compute_angle_loss(s_pos_reps, t_pos_reps)\n",
    "        # angle_loss = 0.5 * qry_angle_loss + 0.5 * pos_angle_loss\n",
    "\n",
    "        # rkd_loss = (0.5 * distance_loss + 0.5 * angle_loss)\n",
    "        rkd_loss = torch.tensor(0.0)\n",
    "\n",
    "        ## simple kd\n",
    "        simple_kd_loss = self.simple_kd_logit_loss(s_qry_reps, s_pos_reps, t_qry_reps, t_pos_reps)\n",
    "\n",
    "        ## intra rkd\n",
    "        intra_rkd_loss = self.intra_rkd(t_qry_layers_embeds, t_pos_layers_embeds,\n",
    "                                        s_qry_layers_embeds, s_pos_layers_embeds)\n",
    "        \n",
    "        ## cross modal kd\n",
    "        # num_s_img_tokens, num_t_img_tokens = s_qry_img_feats.size(1), t_qry_img_feats.size(1)\n",
    "        qry_cross_modal_kd_loss = self.cross_modal_kd_loss(s_qry_hidden_states,\n",
    "                                                       t_qry_hidden_states,\n",
    "                                                       s_qry_img_feats,\n",
    "                                                       t_qry_img_feats)\n",
    "\n",
    "        # num_s_img_tokens, num_t_img_tokens = s_pos_img_feats.size(1), t_pos_img_feats.size(1)\n",
    "        pos_cross_modal_kd_loss = self.cross_modal_kd_loss(s_pos_hidden_states,\n",
    "                                                       t_pos_hidden_states,\n",
    "                                                       s_pos_img_feats,\n",
    "                                                       t_pos_img_feats)\n",
    "        \n",
    "        cross_modal_kd_loss = 0.5 * qry_cross_modal_kd_loss + 0.5 * pos_cross_modal_kd_loss\n",
    "\n",
    "        ## optimal transport loss\n",
    "        ot_loss = self.compute_ot(s_qry_hidden_states, s_qry_attention,\n",
    "                                  t_qry_hidden_states, t_qry_attention)\n",
    "        ot_loss += self.compute_ot(s_pos_hidden_states, s_pos_attention,\n",
    "                                  t_pos_hidden_states, t_pos_attention)\n",
    "        ot_loss = ot_loss / 2.0\n",
    "\n",
    "        total_loss = contrastive_loss + \\\n",
    "                     self.rkd_loss_weight * rkd_loss + \\\n",
    "                     self.simple_kd_weight * simple_kd_loss + \\\n",
    "                     self.intra_rkd_weight * intra_rkd_loss + \\\n",
    "                     self.cross_modal_kd_weight * cross_modal_kd_loss + \\\n",
    "                     self.ot_loss_weight * ot_loss + \\\n",
    "                     self.img_align_loss_weight * img_align_loss\n",
    "        \n",
    "        return {\n",
    "            \"total_loss\": total_loss,\n",
    "            \"contrastive_loss\": contrastive_loss,\n",
    "            \"rkd_loss\": rkd_loss,\n",
    "            \"simple_kd_loss\": simple_kd_loss,\n",
    "            \"intra_rkd_loss\": intra_rkd_loss,\n",
    "            \"cross_modal_kd_loss\": cross_modal_kd_loss,\n",
    "            \"ot_loss\": ot_loss,\n",
    "            \"img_align_loss\": img_align_loss\n",
    "        }\n",
    "\n",
    "    def gaussian_kernel(self, x, y, sigma=2.0):\n",
    "        \"\"\"\n",
    "        Computes the RBF (Gaussian) kernel between two sets of vectors.\n",
    "        k(x, y) = exp(-||x - y||^2 / (2 * sigma^2))\n",
    "        \n",
    "        Args:\n",
    "            x (torch.Tensor): Shape (n, dim)\n",
    "            y (torch.Tensor): Shape (m, dim)\n",
    "            sigma (float): Kernel bandwidth.\n",
    "        \"\"\"\n",
    "        beta = 1.0 / (2.0 * (sigma ** 2))\n",
    "        # (n, m) matrix of squared pairwise distances\n",
    "        dist_sq = torch.cdist(x.unsqueeze(0), y.unsqueeze(0), p=2).pow(2)\n",
    "        return torch.exp(-beta * dist_sq)\n",
    "\n",
    "    def alignment_loss_mmd(self, t_feats, s_feats, sigma=2.0):\n",
    "        \"\"\"\n",
    "        Computes the Maximum Mean Discrepancy (MMD) loss using a Gaussian kernel.\n",
    "\n",
    "        Args:\n",
    "            x_teacher (torch.Tensor): Teacher features, shape (n, dim)\n",
    "            x_student (torch.Tensor): Student features, shape (m, dim)\n",
    "            sigma (float): Kernel bandwidth.\n",
    "        \"\"\"\n",
    "        \n",
    "        # Compute kernel matrices\n",
    "        k_tt = self.gaussian_kernel(t_feats, t_feats, sigma) # (n, n)\n",
    "        k_ss = self.gaussian_kernel(s_feats, s_feats, sigma) # (m, m)\n",
    "        k_ts = self.gaussian_kernel(t_feats, s_feats, sigma) # (n, m)\n",
    "        \n",
    "        # This is the (biased) MMD^2 statistic\n",
    "        # E[k(t, t')] + E[k(s, s')] - 2 * E[k(t, s)]\n",
    "        mmd_loss = k_tt.mean() + k_ss.mean() - 2 * k_ts.mean()\n",
    "        \n",
    "        return mmd_loss\n",
    "    \n",
    "    def compute_ot(self, s_hidden_states, s_attn, t_hidden_states, t_attn):\n",
    "        \n",
    "        loss = 0.0\n",
    "        num_student_layers = len(s_hidden_states)\n",
    "        num_teacher_layers = len(t_hidden_states)\n",
    "        scale = num_teacher_layers // num_student_layers\n",
    "        start_layer = num_student_layers - self.distiller.num_chosen_hidden_states\n",
    "\n",
    "        for l in range(start_layer, num_student_layers):\n",
    "            s_dist = F.softmax(s_attn[l - 1].mean(dim=1)[:, -1], dim=-1) # (b, n)\n",
    "            t_dist = F.softmax(t_attn[l - 1].mean(dim=1)[:, -1], dim=-1) # (b, m)\n",
    "\n",
    "            s_hidden_state = s_hidden_states[l] # (b, n, emb_dim)\n",
    "            proj_t_hidden_state = self.distiller.t2s[l - start_layer](t_hidden_states[scale * l]) # (b, m, emb_dim)\n",
    "\n",
    "            for b in range(s_dist.size(0)):\n",
    "                cost_matrix = 1 - torch.matmul(s_hidden_state[b], proj_t_hidden_state[b].T) # (n, m)\n",
    "                \n",
    "                cost_matrix = cost_matrix / cost_matrix.mean()\n",
    "\n",
    "                transport = self.sinkhorn(s_dist[b], t_dist[b], cost_matrix) \n",
    "                loss += torch.sum(transport * cost_matrix)\n",
    "\n",
    "        return loss\n",
    "    \n",
    "    def sinkhorn(self, a, b, cost_matrix, reg=0.1, num_iters=100, eps=1e-9, stopThr = 1e-7):\n",
    "        \"\"\"\n",
    "        a: (m,) or (m,1) torch tensor (source weights)\n",
    "        b: (n,) or (n,1) torch tensor (target weights)\n",
    "        cost_matrix: (m, n) torch tensor\n",
    "        reg: regularization (>=0) -- larger reg -> smoother K = exp(-C/reg)\n",
    "        num_iters: number of Sinkhorn iterations\n",
    "        \"\"\"\n",
    "        device = cost_matrix.device\n",
    "        dtype = cost_matrix.dtype\n",
    "\n",
    "        a = a.view(-1, 1)\n",
    "        b = b.view(-1, 1)\n",
    "        C = cost_matrix\n",
    "\n",
    "        m, n = C.shape\n",
    "        if m == 0 or n == 0:\n",
    "            return torch.zeros((m, n), device=device, dtype=dtype)\n",
    "\n",
    "        # ensure shapes\n",
    "        if a.shape[0] != m:\n",
    "            a = torch.ones((m, 1), device=device, dtype=dtype) / m\n",
    "        if b.shape[0] != n:\n",
    "            b = torch.ones((n, 1), device=device, dtype=dtype) / n\n",
    "\n",
    "        suma = a.sum()\n",
    "        sumb = b.sum()\n",
    "        if suma <= eps or sumb <= eps:\n",
    "            a = torch.ones((m, 1), device=device, dtype=dtype) / m\n",
    "            b = torch.ones((n, 1), device=device, dtype=dtype) / n\n",
    "        else:\n",
    "            a = a / suma\n",
    "            b = b / sumb\n",
    "\n",
    "        K = torch.exp(-C / (reg + 1e-12))\n",
    "\n",
    "        u = torch.ones((m, 1), device=device, dtype=dtype)\n",
    "        v = torch.ones((n, 1), device=device, dtype=dtype)\n",
    "\n",
    "        for i in range(num_iters):\n",
    "            u_prev = u.clone()\n",
    "            KTv = (K.t() @ u)  # shape (n,1)\n",
    "            v = b / (KTv + eps)\n",
    "            Kv = (K @ v)       # shape (m,1)\n",
    "            u = a / (Kv + eps)\n",
    "\n",
    "            err = torch.max(torch.abs(u - u_prev))\n",
    "            if err.item() < stopThr:\n",
    "                break\n",
    "\n",
    "        # transport plan\n",
    "        U = torch.diag_embed(u.squeeze())   # (m,m) diag(u)\n",
    "        V = torch.diag_embed(v.squeeze())   # (n,n) diag(v)\n",
    "        P = U @ K @ V                       # (m,n)\n",
    "        return P\n",
    "    \n",
    "    def cross_modal_kd_loss(self, s_hidden_states, t_hidden_states, s_img_feats, t_img_feats):\n",
    "        \"\"\"\n",
    "            hidden_states: list of (n_layers, b, n, dim)\n",
    "            img_feats: (b, n_img_tokens, dim)\n",
    "        \"\"\"\n",
    "\n",
    "        loss = 0.0\n",
    "        cur_idx_img = 0\n",
    "        num_student_layers = len(s_hidden_states)\n",
    "        num_teacher_layers = len(t_hidden_states)\n",
    "        scale = num_teacher_layers // num_student_layers\n",
    "        batch_size = s_hidden_states[0].size(0)\n",
    "        start_layer = num_student_layers - self.distiller.num_chosen_hidden_states\n",
    "\n",
    "        if s_img_feats is None or t_img_feats is None:\n",
    "            return loss\n",
    "        \n",
    "        if s_img_feats is not None and t_img_feats is not None:\n",
    "            for b in range(batch_size):\n",
    "                if cur_idx_img < len(s_img_feats) and cur_idx_img < len(t_img_feats):\n",
    "                    for l in range(start_layer, num_student_layers):\n",
    "\n",
    "                        num_s_img_tokens = s_img_feats[b].size(0)\n",
    "                        num_t_img_tokens = t_img_feats[b].size(0)\n",
    "\n",
    "                        s_img_hidden_states = F.normalize(s_hidden_states[l][b][:num_s_img_tokens]).to(torch.float32)\n",
    "                        s_text_hidden_states = F.normalize(s_hidden_states[l][b][num_s_img_tokens:]).to(torch.float32)\n",
    "\n",
    "                        proj_t_img_hidden_states = F.normalize(self.distiller.t2s[l - start_layer](t_hidden_states[scale * l][b][:num_t_img_tokens])).to(torch.float32)\n",
    "                        proj_t_text_hidden_states = F.normalize(self.distiller.t2s[l - start_layer](t_hidden_states[scale * l][b][num_t_img_tokens:])).to(torch.float32)\n",
    "                        \n",
    "                        \n",
    "                        loss += 0.5 * self.sdtw(s_img_hidden_states.unsqueeze(0), proj_t_text_hidden_states.unsqueeze(0)).mean()\n",
    "                        loss += 0.5 * self.sdtw(s_text_hidden_states.unsqueeze(0), proj_t_img_hidden_states.unsqueeze(0)).mean()\n",
    "                    cur_idx_img += 1\n",
    "        loss = loss.to(torch.bfloat16)\n",
    "        return loss / batch_size\n",
    "    \n",
    "    def simple_kd_logit_loss(self, student_qry_reps, student_pos_reps, teacher_qry_reps, teacher_pos_reps):\n",
    "            projector_teacher_qry_reps = self.distiller.last_layer_projector(teacher_qry_reps)\n",
    "            projector_teacher_pos_reps = self.distiller.last_layer_projector(teacher_pos_reps)\n",
    "\n",
    "            loss = (\n",
    "                    self.mse_loss(student_qry_reps, projector_teacher_qry_reps) +  \n",
    "                    self.mse_loss(student_pos_reps, projector_teacher_pos_reps)\n",
    "                   ) / 2.0\n",
    "            return loss\n",
    "    \n",
    "    def intra_rkd(self, \n",
    "                  teacher_qry_layers_embeds, # (b, n_layers, dim), \n",
    "                  teacher_pos_layers_embeds,\n",
    "                  student_qry_layers_embeds,\n",
    "                  student_pos_layers_embeds):\n",
    "        \n",
    "        loss = 0.0\n",
    "        batch_size = student_pos_layers_embeds.size(0)\n",
    "\n",
    "        for b in range(batch_size):\n",
    "\n",
    "            qry_dist_loss = self.compute_distance_loss(student_qry_layers_embeds[b], teacher_qry_layers_embeds[b])\n",
    "            pos_dist_loss = self.compute_distance_loss(student_pos_layers_embeds[b], teacher_pos_layers_embeds[b])\n",
    "            dist_loss = 0.5 * qry_dist_loss + 0.5 * pos_dist_loss\n",
    "            \n",
    "            qry_angle_loss = self.compute_angle_loss(student_qry_layers_embeds[b], teacher_qry_layers_embeds[b])\n",
    "            pos_angle_loss = self.compute_angle_loss(student_pos_layers_embeds[b], teacher_pos_layers_embeds[b])\n",
    "            angle_loss = 0.5 * qry_angle_loss + 0.5 * pos_angle_loss\n",
    "\n",
    "            loss += 0.5 * dist_loss + 0.5 * angle_loss\n",
    "\n",
    "        return loss / batch_size\n",
    "\n",
    "    def pairwise_distance(self, x):\n",
    "        norm = (x**2).sum(dim=1, keepdim=True)\n",
    "        dist = norm + norm.t() - 2.0 * torch.mm(x, x.t())\n",
    "        return dist\n",
    "    \n",
    "    def compute_distance_loss(self, student_repr, teacher_repr):\n",
    "        \n",
    "        num_student_layers = student_repr.size(0)\n",
    "        num_teacher_layers = teacher_repr.size(0)\n",
    "        scale = num_teacher_layers // num_student_layers\n",
    "\n",
    "        teacher_repr = teacher_repr[\n",
    "            torch.tensor([i * scale for i in range(num_student_layers)], device=teacher_repr.device)\n",
    "        ]\n",
    "\n",
    "        dist_student = self.pairwise_distance(student_repr)\n",
    "        dist_teacher = self.pairwise_distance(teacher_repr)\n",
    "        \n",
    "        mask = torch.triu(torch.ones_like(dist_student), diagonal=1).bool()\n",
    "        dist_student = dist_student[mask]\n",
    "        dist_teacher = dist_teacher[mask]\n",
    "        \n",
    "        mean_td = dist_teacher.mean().detach() + 1e-8\n",
    "        mean_sd = dist_student.mean().detach() + 1e-8\n",
    "        \n",
    "        dist_student = dist_student / mean_sd\n",
    "        dist_teacher = dist_teacher / mean_td\n",
    "        \n",
    "        diff = dist_student - dist_teacher\n",
    "        abs_diff = torch.abs(diff)\n",
    "        quadratic = 0.5 * (abs_diff ** 2)\n",
    "        linear = abs_diff - 0.5\n",
    "        \n",
    "        loss = torch.where(abs_diff < 1.0, quadratic, linear)\n",
    "        loss = loss.mean()\n",
    "        return loss\n",
    "    \n",
    "    def angle_potentials(self, x):\n",
    "        n = x.size(0)\n",
    "        diffs = x.unsqueeze(0) - x.unsqueeze(1)\n",
    "        norms = torch.norm(diffs, dim=-1, keepdim=True) + 1e-8\n",
    "        e = diffs / norms\n",
    "        \n",
    "        cos_angles = torch.einsum('ijd,kjd->ijk', e, e)\n",
    "        return cos_angles\n",
    "    \n",
    "    def compute_angle_loss(self, student_repr, teacher_repr):\n",
    "        \n",
    "        num_student_layers = student_repr.size(0)\n",
    "        num_teacher_layers = teacher_repr.size(0)\n",
    "        scale = num_teacher_layers // num_student_layers\n",
    "\n",
    "        teacher_repr = teacher_repr[\n",
    "            torch.tensor([i * scale for i in range(num_student_layers)], device=teacher_repr.device)\n",
    "        ]\n",
    "\n",
    "        psi_student = self.angle_potentials(student_repr)\n",
    "        psi_teacher = self.angle_potentials(teacher_repr)\n",
    "        \n",
    "        n = psi_student.size(0)\n",
    "        mask = torch.ones((n, n, n), dtype=torch.bool, device=psi_student.device)\n",
    "        idx = torch.arange(n, device=psi_student.device)\n",
    "        mask[idx, idx, :] = 0\n",
    "        mask[idx, :, idx] = 0\n",
    "        mask[:, idx, idx] = 0\n",
    "        \n",
    "        psi_teacher = psi_teacher[mask]\n",
    "        psi_student = psi_student[mask]\n",
    "        \n",
    "        diff = psi_student - psi_teacher\n",
    "        abs_diff = torch.abs(diff)\n",
    "        quadratic = 0.5 * (abs_diff ** 2)\n",
    "        linear = abs_diff - 0.5\n",
    "        loss = torch.where(abs_diff < 1.0, quadratic, linear)\n",
    "        loss = loss.mean()\n",
    "        return loss\n",
    "             "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "fbe499be",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = StrongerKD(training_args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "63f09590",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Projector t2s_img created with structure: Sequential(\n",
      "  (0): Linear(in_features=1536, out_features=896, bias=True)\n",
      ")\n",
      "Projector t2s_txt created with structure: Sequential(\n",
      "  (0): Linear(in_features=1536, out_features=896, bias=True)\n",
      ")\n",
      "Projectors set.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2025-11-08 10:34:22,863] DEBUG [numba.cuda.cudadrv.driver:325] call driver api: cuCtxGetCurrent\n",
      "[2025-11-08 10:34:22,864] DEBUG [numba.cuda.cudadrv.driver:325] call driver api: cuCtxGetDevice\n",
      "[2025-11-08 10:34:22,865] DEBUG [numba.cuda.cudadrv.driver:325] call driver api: cuPointerGetAttribute\n",
      "[2025-11-08 10:34:22,866] DEBUG [numba.cuda.cudadrv.driver:325] call driver api: cuCtxGetCurrent\n",
      "[2025-11-08 10:34:22,866] DEBUG [numba.cuda.cudadrv.driver:325] call driver api: cuCtxGetDevice\n",
      "[2025-11-08 10:34:22,867] DEBUG [numba.cuda.cudadrv.driver:325] call driver api: cuPointerGetAttribute\n",
      "[2025-11-08 10:34:22,868] DEBUG [numba.cuda.cudadrv.driver:325] call driver api: cuCtxGetCurrent\n",
      "[2025-11-08 10:34:22,868] DEBUG [numba.cuda.cudadrv.driver:325] call driver api: cuCtxGetDevice\n",
      "[2025-11-08 10:34:22,869] DEBUG [numba.cuda.cudadrv.driver:325] call driver api: cuLaunchKernel\n",
      "[2025-11-08 10:34:22,872] DEBUG [numba.cuda.cudadrv.driver:325] call driver api: cuCtxGetCurrent\n",
      "[2025-11-08 10:34:22,872] DEBUG [numba.cuda.cudadrv.driver:325] call driver api: cuCtxGetDevice\n",
      "[2025-11-08 10:34:22,873] DEBUG [numba.cuda.cudadrv.driver:325] call driver api: cuPointerGetAttribute\n",
      "[2025-11-08 10:34:22,874] DEBUG [numba.cuda.cudadrv.driver:325] call driver api: cuCtxGetCurrent\n",
      "[2025-11-08 10:34:22,874] DEBUG [numba.cuda.cudadrv.driver:325] call driver api: cuCtxGetDevice\n",
      "[2025-11-08 10:34:22,875] DEBUG [numba.cuda.cudadrv.driver:325] call driver api: cuPointerGetAttribute\n",
      "[2025-11-08 10:34:22,876] DEBUG [numba.cuda.cudadrv.driver:325] call driver api: cuCtxGetCurrent\n",
      "[2025-11-08 10:34:22,876] DEBUG [numba.cuda.cudadrv.driver:325] call driver api: cuCtxGetDevice\n",
      "[2025-11-08 10:34:22,877] DEBUG [numba.cuda.cudadrv.driver:325] call driver api: cuLaunchKernel\n",
      "[2025-11-08 10:34:22,881] DEBUG [numba.cuda.cudadrv.driver:325] call driver api: cuCtxGetCurrent\n",
      "[2025-11-08 10:34:22,882] DEBUG [numba.cuda.cudadrv.driver:325] call driver api: cuCtxGetDevice\n",
      "[2025-11-08 10:34:22,882] DEBUG [numba.cuda.cudadrv.driver:325] call driver api: cuPointerGetAttribute\n",
      "[2025-11-08 10:34:22,884] DEBUG [numba.cuda.cudadrv.driver:325] call driver api: cuCtxGetCurrent\n",
      "[2025-11-08 10:34:22,884] DEBUG [numba.cuda.cudadrv.driver:325] call driver api: cuCtxGetDevice\n",
      "[2025-11-08 10:34:22,885] DEBUG [numba.cuda.cudadrv.driver:325] call driver api: cuPointerGetAttribute\n",
      "[2025-11-08 10:34:22,886] DEBUG [numba.cuda.cudadrv.driver:325] call driver api: cuCtxGetCurrent\n",
      "[2025-11-08 10:34:22,886] DEBUG [numba.cuda.cudadrv.driver:325] call driver api: cuCtxGetDevice\n",
      "[2025-11-08 10:34:22,887] DEBUG [numba.cuda.cudadrv.driver:325] call driver api: cuLaunchKernel\n",
      "[2025-11-08 10:34:22,889] DEBUG [numba.cuda.cudadrv.driver:325] call driver api: cuCtxGetCurrent\n",
      "[2025-11-08 10:34:22,890] DEBUG [numba.cuda.cudadrv.driver:325] call driver api: cuCtxGetDevice\n",
      "[2025-11-08 10:34:22,890] DEBUG [numba.cuda.cudadrv.driver:325] call driver api: cuPointerGetAttribute\n",
      "[2025-11-08 10:34:22,891] DEBUG [numba.cuda.cudadrv.driver:325] call driver api: cuCtxGetCurrent\n",
      "[2025-11-08 10:34:22,892] DEBUG [numba.cuda.cudadrv.driver:325] call driver api: cuCtxGetDevice\n",
      "[2025-11-08 10:34:22,892] DEBUG [numba.cuda.cudadrv.driver:325] call driver api: cuPointerGetAttribute\n",
      "[2025-11-08 10:34:22,893] DEBUG [numba.cuda.cudadrv.driver:325] call driver api: cuCtxGetCurrent\n",
      "[2025-11-08 10:34:22,893] DEBUG [numba.cuda.cudadrv.driver:325] call driver api: cuCtxGetDevice\n",
      "[2025-11-08 10:34:22,894] DEBUG [numba.cuda.cudadrv.driver:325] call driver api: cuLaunchKernel\n",
      "[2025-11-08 10:34:22,897] DEBUG [numba.cuda.cudadrv.driver:325] call driver api: cuCtxGetCurrent\n",
      "[2025-11-08 10:34:22,898] DEBUG [numba.cuda.cudadrv.driver:325] call driver api: cuCtxGetDevice\n",
      "[2025-11-08 10:34:22,898] DEBUG [numba.cuda.cudadrv.driver:325] call driver api: cuPointerGetAttribute\n",
      "[2025-11-08 10:34:22,899] DEBUG [numba.cuda.cudadrv.driver:325] call driver api: cuCtxGetCurrent\n",
      "[2025-11-08 10:34:22,900] DEBUG [numba.cuda.cudadrv.driver:325] call driver api: cuCtxGetDevice\n",
      "[2025-11-08 10:34:22,900] DEBUG [numba.cuda.cudadrv.driver:325] call driver api: cuPointerGetAttribute\n",
      "[2025-11-08 10:34:22,901] DEBUG [numba.cuda.cudadrv.driver:325] call driver api: cuCtxGetCurrent\n",
      "[2025-11-08 10:34:22,901] DEBUG [numba.cuda.cudadrv.driver:325] call driver api: cuCtxGetDevice\n",
      "[2025-11-08 10:34:22,902] DEBUG [numba.cuda.cudadrv.driver:325] call driver api: cuLaunchKernel\n",
      "[2025-11-08 10:34:22,904] DEBUG [numba.cuda.cudadrv.driver:325] call driver api: cuCtxGetCurrent\n",
      "[2025-11-08 10:34:22,904] DEBUG [numba.cuda.cudadrv.driver:325] call driver api: cuCtxGetDevice\n",
      "[2025-11-08 10:34:22,905] DEBUG [numba.cuda.cudadrv.driver:325] call driver api: cuPointerGetAttribute\n",
      "[2025-11-08 10:34:22,906] DEBUG [numba.cuda.cudadrv.driver:325] call driver api: cuCtxGetCurrent\n",
      "[2025-11-08 10:34:22,906] DEBUG [numba.cuda.cudadrv.driver:325] call driver api: cuCtxGetDevice\n",
      "[2025-11-08 10:34:22,907] DEBUG [numba.cuda.cudadrv.driver:325] call driver api: cuPointerGetAttribute\n",
      "[2025-11-08 10:34:22,908] DEBUG [numba.cuda.cudadrv.driver:325] call driver api: cuCtxGetCurrent\n",
      "[2025-11-08 10:34:22,908] DEBUG [numba.cuda.cudadrv.driver:325] call driver api: cuCtxGetDevice\n",
      "[2025-11-08 10:34:22,909] DEBUG [numba.cuda.cudadrv.driver:325] call driver api: cuLaunchKernel\n",
      "[2025-11-08 10:34:22,912] DEBUG [numba.cuda.cudadrv.driver:325] call driver api: cuCtxGetCurrent\n",
      "[2025-11-08 10:34:22,913] DEBUG [numba.cuda.cudadrv.driver:325] call driver api: cuCtxGetDevice\n",
      "[2025-11-08 10:34:22,913] DEBUG [numba.cuda.cudadrv.driver:325] call driver api: cuPointerGetAttribute\n",
      "[2025-11-08 10:34:22,914] DEBUG [numba.cuda.cudadrv.driver:325] call driver api: cuCtxGetCurrent\n",
      "[2025-11-08 10:34:22,915] DEBUG [numba.cuda.cudadrv.driver:325] call driver api: cuCtxGetDevice\n",
      "[2025-11-08 10:34:22,915] DEBUG [numba.cuda.cudadrv.driver:325] call driver api: cuPointerGetAttribute\n",
      "[2025-11-08 10:34:22,916] DEBUG [numba.cuda.cudadrv.driver:325] call driver api: cuCtxGetCurrent\n",
      "[2025-11-08 10:34:22,916] DEBUG [numba.cuda.cudadrv.driver:325] call driver api: cuCtxGetDevice\n",
      "[2025-11-08 10:34:22,917] DEBUG [numba.cuda.cudadrv.driver:325] call driver api: cuLaunchKernel\n",
      "[2025-11-08 10:34:22,919] DEBUG [numba.cuda.cudadrv.driver:325] call driver api: cuCtxGetCurrent\n",
      "[2025-11-08 10:34:22,920] DEBUG [numba.cuda.cudadrv.driver:325] call driver api: cuCtxGetDevice\n",
      "[2025-11-08 10:34:22,921] DEBUG [numba.cuda.cudadrv.driver:325] call driver api: cuPointerGetAttribute\n",
      "[2025-11-08 10:34:22,922] DEBUG [numba.cuda.cudadrv.driver:325] call driver api: cuCtxGetCurrent\n",
      "[2025-11-08 10:34:22,922] DEBUG [numba.cuda.cudadrv.driver:325] call driver api: cuCtxGetDevice\n",
      "[2025-11-08 10:34:22,923] DEBUG [numba.cuda.cudadrv.driver:325] call driver api: cuPointerGetAttribute\n",
      "[2025-11-08 10:34:22,923] DEBUG [numba.cuda.cudadrv.driver:325] call driver api: cuCtxGetCurrent\n",
      "[2025-11-08 10:34:22,924] DEBUG [numba.cuda.cudadrv.driver:325] call driver api: cuCtxGetDevice\n",
      "[2025-11-08 10:34:22,925] DEBUG [numba.cuda.cudadrv.driver:325] call driver api: cuLaunchKernel\n",
      "[2025-11-08 10:34:22,928] DEBUG [numba.cuda.cudadrv.driver:325] call driver api: cuCtxGetCurrent\n",
      "[2025-11-08 10:34:22,929] DEBUG [numba.cuda.cudadrv.driver:325] call driver api: cuCtxGetDevice\n",
      "[2025-11-08 10:34:22,929] DEBUG [numba.cuda.cudadrv.driver:325] call driver api: cuPointerGetAttribute\n",
      "[2025-11-08 10:34:22,930] DEBUG [numba.cuda.cudadrv.driver:325] call driver api: cuCtxGetCurrent\n",
      "[2025-11-08 10:34:22,931] DEBUG [numba.cuda.cudadrv.driver:325] call driver api: cuCtxGetDevice\n",
      "[2025-11-08 10:34:22,932] DEBUG [numba.cuda.cudadrv.driver:325] call driver api: cuPointerGetAttribute\n",
      "[2025-11-08 10:34:22,932] DEBUG [numba.cuda.cudadrv.driver:325] call driver api: cuCtxGetCurrent\n",
      "[2025-11-08 10:34:22,933] DEBUG [numba.cuda.cudadrv.driver:325] call driver api: cuCtxGetDevice\n",
      "[2025-11-08 10:34:22,933] DEBUG [numba.cuda.cudadrv.driver:325] call driver api: cuLaunchKernel\n",
      "[2025-11-08 10:34:22,936] DEBUG [numba.cuda.cudadrv.driver:325] call driver api: cuCtxGetCurrent\n",
      "[2025-11-08 10:34:22,936] DEBUG [numba.cuda.cudadrv.driver:325] call driver api: cuCtxGetDevice\n",
      "[2025-11-08 10:34:22,937] DEBUG [numba.cuda.cudadrv.driver:325] call driver api: cuPointerGetAttribute\n",
      "[2025-11-08 10:34:22,938] DEBUG [numba.cuda.cudadrv.driver:325] call driver api: cuCtxGetCurrent\n",
      "[2025-11-08 10:34:22,939] DEBUG [numba.cuda.cudadrv.driver:325] call driver api: cuCtxGetDevice\n",
      "[2025-11-08 10:34:22,940] DEBUG [numba.cuda.cudadrv.driver:325] call driver api: cuPointerGetAttribute\n",
      "[2025-11-08 10:34:22,940] DEBUG [numba.cuda.cudadrv.driver:325] call driver api: cuCtxGetCurrent\n",
      "[2025-11-08 10:34:22,941] DEBUG [numba.cuda.cudadrv.driver:325] call driver api: cuCtxGetDevice\n",
      "[2025-11-08 10:34:22,942] DEBUG [numba.cuda.cudadrv.driver:325] call driver api: cuLaunchKernel\n",
      "[2025-11-08 10:34:22,946] DEBUG [numba.cuda.cudadrv.driver:325] call driver api: cuCtxGetCurrent\n",
      "[2025-11-08 10:34:22,946] DEBUG [numba.cuda.cudadrv.driver:325] call driver api: cuCtxGetDevice\n",
      "[2025-11-08 10:34:22,947] DEBUG [numba.cuda.cudadrv.driver:325] call driver api: cuPointerGetAttribute\n",
      "[2025-11-08 10:34:22,948] DEBUG [numba.cuda.cudadrv.driver:325] call driver api: cuCtxGetCurrent\n",
      "[2025-11-08 10:34:22,949] DEBUG [numba.cuda.cudadrv.driver:325] call driver api: cuCtxGetDevice\n",
      "[2025-11-08 10:34:22,950] DEBUG [numba.cuda.cudadrv.driver:325] call driver api: cuPointerGetAttribute\n",
      "[2025-11-08 10:34:22,950] DEBUG [numba.cuda.cudadrv.driver:325] call driver api: cuCtxGetCurrent\n",
      "[2025-11-08 10:34:22,952] DEBUG [numba.cuda.cudadrv.driver:325] call driver api: cuCtxGetDevice\n",
      "[2025-11-08 10:34:22,952] DEBUG [numba.cuda.cudadrv.driver:325] call driver api: cuLaunchKernel\n",
      "[2025-11-08 10:34:22,955] DEBUG [numba.cuda.cudadrv.driver:325] call driver api: cuCtxGetCurrent\n",
      "[2025-11-08 10:34:22,955] DEBUG [numba.cuda.cudadrv.driver:325] call driver api: cuCtxGetDevice\n",
      "[2025-11-08 10:34:22,956] DEBUG [numba.cuda.cudadrv.driver:325] call driver api: cuPointerGetAttribute\n",
      "[2025-11-08 10:34:22,958] DEBUG [numba.cuda.cudadrv.driver:325] call driver api: cuCtxGetCurrent\n",
      "[2025-11-08 10:34:22,958] DEBUG [numba.cuda.cudadrv.driver:325] call driver api: cuCtxGetDevice\n",
      "[2025-11-08 10:34:22,959] DEBUG [numba.cuda.cudadrv.driver:325] call driver api: cuPointerGetAttribute\n",
      "[2025-11-08 10:34:22,960] DEBUG [numba.cuda.cudadrv.driver:325] call driver api: cuCtxGetCurrent\n",
      "[2025-11-08 10:34:22,960] DEBUG [numba.cuda.cudadrv.driver:325] call driver api: cuCtxGetDevice\n",
      "[2025-11-08 10:34:22,961] DEBUG [numba.cuda.cudadrv.driver:325] call driver api: cuLaunchKernel\n",
      "[2025-11-08 10:34:22,966] DEBUG [numba.cuda.cudadrv.driver:325] call driver api: cuCtxGetCurrent\n",
      "[2025-11-08 10:34:22,967] DEBUG [numba.cuda.cudadrv.driver:325] call driver api: cuCtxGetDevice\n",
      "[2025-11-08 10:34:22,967] DEBUG [numba.cuda.cudadrv.driver:325] call driver api: cuPointerGetAttribute\n",
      "[2025-11-08 10:34:22,969] DEBUG [numba.cuda.cudadrv.driver:325] call driver api: cuCtxGetCurrent\n",
      "[2025-11-08 10:34:22,970] DEBUG [numba.cuda.cudadrv.driver:325] call driver api: cuCtxGetDevice\n",
      "[2025-11-08 10:34:22,970] DEBUG [numba.cuda.cudadrv.driver:325] call driver api: cuPointerGetAttribute\n",
      "[2025-11-08 10:34:22,971] DEBUG [numba.cuda.cudadrv.driver:325] call driver api: cuCtxGetCurrent\n",
      "[2025-11-08 10:34:22,972] DEBUG [numba.cuda.cudadrv.driver:325] call driver api: cuCtxGetDevice\n",
      "[2025-11-08 10:34:22,973] DEBUG [numba.cuda.cudadrv.driver:325] call driver api: cuLaunchKernel\n",
      "[2025-11-08 10:34:22,976] DEBUG [numba.cuda.cudadrv.driver:325] call driver api: cuCtxGetCurrent\n",
      "[2025-11-08 10:34:22,977] DEBUG [numba.cuda.cudadrv.driver:325] call driver api: cuCtxGetDevice\n",
      "[2025-11-08 10:34:22,978] DEBUG [numba.cuda.cudadrv.driver:325] call driver api: cuPointerGetAttribute\n",
      "[2025-11-08 10:34:22,979] DEBUG [numba.cuda.cudadrv.driver:325] call driver api: cuCtxGetCurrent\n",
      "[2025-11-08 10:34:22,980] DEBUG [numba.cuda.cudadrv.driver:325] call driver api: cuCtxGetDevice\n",
      "[2025-11-08 10:34:22,981] DEBUG [numba.cuda.cudadrv.driver:325] call driver api: cuPointerGetAttribute\n",
      "[2025-11-08 10:34:22,982] DEBUG [numba.cuda.cudadrv.driver:325] call driver api: cuCtxGetCurrent\n",
      "[2025-11-08 10:34:22,983] DEBUG [numba.cuda.cudadrv.driver:325] call driver api: cuCtxGetDevice\n",
      "[2025-11-08 10:34:22,984] DEBUG [numba.cuda.cudadrv.driver:325] call driver api: cuLaunchKernel\n",
      "[2025-11-08 10:34:22,989] DEBUG [numba.cuda.cudadrv.driver:325] call driver api: cuCtxGetCurrent\n",
      "[2025-11-08 10:34:22,990] DEBUG [numba.cuda.cudadrv.driver:325] call driver api: cuCtxGetDevice\n",
      "[2025-11-08 10:34:22,990] DEBUG [numba.cuda.cudadrv.driver:325] call driver api: cuPointerGetAttribute\n",
      "[2025-11-08 10:34:22,992] DEBUG [numba.cuda.cudadrv.driver:325] call driver api: cuCtxGetCurrent\n",
      "[2025-11-08 10:34:22,993] DEBUG [numba.cuda.cudadrv.driver:325] call driver api: cuCtxGetDevice\n",
      "[2025-11-08 10:34:22,993] DEBUG [numba.cuda.cudadrv.driver:325] call driver api: cuPointerGetAttribute\n",
      "[2025-11-08 10:34:22,994] DEBUG [numba.cuda.cudadrv.driver:325] call driver api: cuCtxGetCurrent\n",
      "[2025-11-08 10:34:22,995] DEBUG [numba.cuda.cudadrv.driver:325] call driver api: cuCtxGetDevice\n",
      "[2025-11-08 10:34:22,996] DEBUG [numba.cuda.cudadrv.driver:325] call driver api: cuLaunchKernel\n",
      "[2025-11-08 10:34:22,999] DEBUG [numba.cuda.cudadrv.driver:325] call driver api: cuCtxGetCurrent\n",
      "[2025-11-08 10:34:23,000] DEBUG [numba.cuda.cudadrv.driver:325] call driver api: cuCtxGetDevice\n",
      "[2025-11-08 10:34:23,001] DEBUG [numba.cuda.cudadrv.driver:325] call driver api: cuPointerGetAttribute\n",
      "[2025-11-08 10:34:23,002] DEBUG [numba.cuda.cudadrv.driver:325] call driver api: cuCtxGetCurrent\n",
      "[2025-11-08 10:34:23,003] DEBUG [numba.cuda.cudadrv.driver:325] call driver api: cuCtxGetDevice\n",
      "[2025-11-08 10:34:23,004] DEBUG [numba.cuda.cudadrv.driver:325] call driver api: cuPointerGetAttribute\n",
      "[2025-11-08 10:34:23,005] DEBUG [numba.cuda.cudadrv.driver:325] call driver api: cuCtxGetCurrent\n",
      "[2025-11-08 10:34:23,005] DEBUG [numba.cuda.cudadrv.driver:325] call driver api: cuCtxGetDevice\n",
      "[2025-11-08 10:34:23,006] DEBUG [numba.cuda.cudadrv.driver:325] call driver api: cuLaunchKernel\n",
      "[2025-11-08 10:34:23,011] DEBUG [numba.cuda.cudadrv.driver:325] call driver api: cuCtxGetCurrent\n",
      "[2025-11-08 10:34:23,012] DEBUG [numba.cuda.cudadrv.driver:325] call driver api: cuCtxGetDevice\n",
      "[2025-11-08 10:34:23,013] DEBUG [numba.cuda.cudadrv.driver:325] call driver api: cuPointerGetAttribute\n",
      "[2025-11-08 10:34:23,014] DEBUG [numba.cuda.cudadrv.driver:325] call driver api: cuCtxGetCurrent\n",
      "[2025-11-08 10:34:23,015] DEBUG [numba.cuda.cudadrv.driver:325] call driver api: cuCtxGetDevice\n",
      "[2025-11-08 10:34:23,016] DEBUG [numba.cuda.cudadrv.driver:325] call driver api: cuPointerGetAttribute\n",
      "[2025-11-08 10:34:23,017] DEBUG [numba.cuda.cudadrv.driver:325] call driver api: cuCtxGetCurrent\n",
      "[2025-11-08 10:34:23,018] DEBUG [numba.cuda.cudadrv.driver:325] call driver api: cuCtxGetDevice\n",
      "[2025-11-08 10:34:23,019] DEBUG [numba.cuda.cudadrv.driver:325] call driver api: cuLaunchKernel\n",
      "[2025-11-08 10:34:23,023] DEBUG [numba.cuda.cudadrv.driver:325] call driver api: cuCtxGetCurrent\n",
      "[2025-11-08 10:34:23,024] DEBUG [numba.cuda.cudadrv.driver:325] call driver api: cuCtxGetDevice\n",
      "[2025-11-08 10:34:23,024] DEBUG [numba.cuda.cudadrv.driver:325] call driver api: cuPointerGetAttribute\n",
      "[2025-11-08 10:34:23,026] DEBUG [numba.cuda.cudadrv.driver:325] call driver api: cuCtxGetCurrent\n",
      "[2025-11-08 10:34:23,027] DEBUG [numba.cuda.cudadrv.driver:325] call driver api: cuCtxGetDevice\n",
      "[2025-11-08 10:34:23,028] DEBUG [numba.cuda.cudadrv.driver:325] call driver api: cuPointerGetAttribute\n",
      "[2025-11-08 10:34:23,029] DEBUG [numba.cuda.cudadrv.driver:325] call driver api: cuCtxGetCurrent\n",
      "[2025-11-08 10:34:23,029] DEBUG [numba.cuda.cudadrv.driver:325] call driver api: cuCtxGetDevice\n",
      "[2025-11-08 10:34:23,030] DEBUG [numba.cuda.cudadrv.driver:325] call driver api: cuLaunchKernel\n",
      "[2025-11-08 10:34:23,036] DEBUG [numba.cuda.cudadrv.driver:325] call driver api: cuCtxGetCurrent\n",
      "[2025-11-08 10:34:23,037] DEBUG [numba.cuda.cudadrv.driver:325] call driver api: cuCtxGetDevice\n",
      "[2025-11-08 10:34:23,038] DEBUG [numba.cuda.cudadrv.driver:325] call driver api: cuPointerGetAttribute\n",
      "[2025-11-08 10:34:23,039] DEBUG [numba.cuda.cudadrv.driver:325] call driver api: cuCtxGetCurrent\n",
      "[2025-11-08 10:34:23,040] DEBUG [numba.cuda.cudadrv.driver:325] call driver api: cuCtxGetDevice\n",
      "[2025-11-08 10:34:23,041] DEBUG [numba.cuda.cudadrv.driver:325] call driver api: cuPointerGetAttribute\n",
      "[2025-11-08 10:34:23,042] DEBUG [numba.cuda.cudadrv.driver:325] call driver api: cuCtxGetCurrent\n",
      "[2025-11-08 10:34:23,043] DEBUG [numba.cuda.cudadrv.driver:325] call driver api: cuCtxGetDevice\n",
      "[2025-11-08 10:34:23,044] DEBUG [numba.cuda.cudadrv.driver:325] call driver api: cuLaunchKernel\n",
      "[2025-11-08 10:34:23,048] DEBUG [numba.cuda.cudadrv.driver:325] call driver api: cuCtxGetCurrent\n",
      "[2025-11-08 10:34:23,048] DEBUG [numba.cuda.cudadrv.driver:325] call driver api: cuCtxGetDevice\n",
      "[2025-11-08 10:34:23,049] DEBUG [numba.cuda.cudadrv.driver:325] call driver api: cuPointerGetAttribute\n",
      "[2025-11-08 10:34:23,051] DEBUG [numba.cuda.cudadrv.driver:325] call driver api: cuCtxGetCurrent\n",
      "[2025-11-08 10:34:23,051] DEBUG [numba.cuda.cudadrv.driver:325] call driver api: cuCtxGetDevice\n",
      "[2025-11-08 10:34:23,052] DEBUG [numba.cuda.cudadrv.driver:325] call driver api: cuPointerGetAttribute\n",
      "[2025-11-08 10:34:23,053] DEBUG [numba.cuda.cudadrv.driver:325] call driver api: cuCtxGetCurrent\n",
      "[2025-11-08 10:34:23,054] DEBUG [numba.cuda.cudadrv.driver:325] call driver api: cuCtxGetDevice\n",
      "[2025-11-08 10:34:23,055] DEBUG [numba.cuda.cudadrv.driver:325] call driver api: cuLaunchKernel\n",
      "[2025-11-08 10:34:23,060] DEBUG [numba.cuda.cudadrv.driver:325] call driver api: cuCtxGetCurrent\n",
      "[2025-11-08 10:34:23,060] DEBUG [numba.cuda.cudadrv.driver:325] call driver api: cuCtxGetDevice\n",
      "[2025-11-08 10:34:23,061] DEBUG [numba.cuda.cudadrv.driver:325] call driver api: cuPointerGetAttribute\n",
      "[2025-11-08 10:34:23,063] DEBUG [numba.cuda.cudadrv.driver:325] call driver api: cuCtxGetCurrent\n",
      "[2025-11-08 10:34:23,064] DEBUG [numba.cuda.cudadrv.driver:325] call driver api: cuCtxGetDevice\n",
      "[2025-11-08 10:34:23,065] DEBUG [numba.cuda.cudadrv.driver:325] call driver api: cuPointerGetAttribute\n",
      "[2025-11-08 10:34:23,066] DEBUG [numba.cuda.cudadrv.driver:325] call driver api: cuCtxGetCurrent\n",
      "[2025-11-08 10:34:23,067] DEBUG [numba.cuda.cudadrv.driver:325] call driver api: cuCtxGetDevice\n",
      "[2025-11-08 10:34:23,068] DEBUG [numba.cuda.cudadrv.driver:325] call driver api: cuLaunchKernel\n",
      "[2025-11-08 10:34:23,070] DEBUG [numba.cuda.cudadrv.driver:325] call driver api: cuCtxGetCurrent\n",
      "[2025-11-08 10:34:23,071] DEBUG [numba.cuda.cudadrv.driver:325] call driver api: cuCtxGetDevice\n",
      "[2025-11-08 10:34:23,072] DEBUG [numba.cuda.cudadrv.driver:325] call driver api: cuPointerGetAttribute\n",
      "[2025-11-08 10:34:23,074] DEBUG [numba.cuda.cudadrv.driver:325] call driver api: cuCtxGetCurrent\n",
      "[2025-11-08 10:34:23,074] DEBUG [numba.cuda.cudadrv.driver:325] call driver api: cuCtxGetDevice\n",
      "[2025-11-08 10:34:23,075] DEBUG [numba.cuda.cudadrv.driver:325] call driver api: cuPointerGetAttribute\n",
      "[2025-11-08 10:34:23,076] DEBUG [numba.cuda.cudadrv.driver:325] call driver api: cuCtxGetCurrent\n",
      "[2025-11-08 10:34:23,076] DEBUG [numba.cuda.cudadrv.driver:325] call driver api: cuCtxGetDevice\n",
      "[2025-11-08 10:34:23,077] DEBUG [numba.cuda.cudadrv.driver:325] call driver api: cuLaunchKernel\n",
      "[2025-11-08 10:34:23,083] DEBUG [numba.cuda.cudadrv.driver:325] call driver api: cuCtxGetCurrent\n",
      "[2025-11-08 10:34:23,084] DEBUG [numba.cuda.cudadrv.driver:325] call driver api: cuCtxGetDevice\n",
      "[2025-11-08 10:34:23,085] DEBUG [numba.cuda.cudadrv.driver:325] call driver api: cuPointerGetAttribute\n",
      "[2025-11-08 10:34:23,086] DEBUG [numba.cuda.cudadrv.driver:325] call driver api: cuCtxGetCurrent\n",
      "[2025-11-08 10:34:23,087] DEBUG [numba.cuda.cudadrv.driver:325] call driver api: cuCtxGetDevice\n",
      "[2025-11-08 10:34:23,088] DEBUG [numba.cuda.cudadrv.driver:325] call driver api: cuPointerGetAttribute\n",
      "[2025-11-08 10:34:23,089] DEBUG [numba.cuda.cudadrv.driver:325] call driver api: cuCtxGetCurrent\n",
      "[2025-11-08 10:34:23,090] DEBUG [numba.cuda.cudadrv.driver:325] call driver api: cuCtxGetDevice\n",
      "[2025-11-08 10:34:23,091] DEBUG [numba.cuda.cudadrv.driver:325] call driver api: cuLaunchKernel\n",
      "[2025-11-08 10:34:23,094] DEBUG [numba.cuda.cudadrv.driver:325] call driver api: cuCtxGetCurrent\n",
      "[2025-11-08 10:34:23,095] DEBUG [numba.cuda.cudadrv.driver:325] call driver api: cuCtxGetDevice\n",
      "[2025-11-08 10:34:23,096] DEBUG [numba.cuda.cudadrv.driver:325] call driver api: cuPointerGetAttribute\n",
      "[2025-11-08 10:34:23,098] DEBUG [numba.cuda.cudadrv.driver:325] call driver api: cuCtxGetCurrent\n",
      "[2025-11-08 10:34:23,099] DEBUG [numba.cuda.cudadrv.driver:325] call driver api: cuCtxGetDevice\n",
      "[2025-11-08 10:34:23,100] DEBUG [numba.cuda.cudadrv.driver:325] call driver api: cuPointerGetAttribute\n",
      "[2025-11-08 10:34:23,101] DEBUG [numba.cuda.cudadrv.driver:325] call driver api: cuCtxGetCurrent\n",
      "[2025-11-08 10:34:23,101] DEBUG [numba.cuda.cudadrv.driver:325] call driver api: cuCtxGetDevice\n",
      "[2025-11-08 10:34:23,103] DEBUG [numba.cuda.cudadrv.driver:325] call driver api: cuLaunchKernel\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'total_loss': tensor(nan, device='cuda:0', grad_fn=<AddBackward0>),\n",
       " 'contrastive_loss': tensor(0., device='cuda:0'),\n",
       " 'rkd_loss': tensor(0.),\n",
       " 'simple_kd_loss': tensor(0.0013, device='cuda:0', grad_fn=<DivBackward0>),\n",
       " 'intra_rkd_loss': tensor(0.0345, device='cuda:0', grad_fn=<DivBackward0>),\n",
       " 'cross_modal_kd_loss': tensor(1464., device='cuda:0', dtype=torch.bfloat16, grad_fn=<AddBackward0>),\n",
       " 'ot_loss': tensor(nan, device='cuda:0', grad_fn=<DivBackward0>),\n",
       " 'img_align_loss': tensor(0.3848, device='cuda:0', grad_fn=<DivBackward0>)}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with torch.autocast(enabled=True, dtype=torch.bfloat16, device_type=\"cuda\"):\n",
    "    loss = criterion.forward(None, None)\n",
    "\n",
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d9159d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pairwise_distance(x):\n",
    "        norm = (x**2).sum(dim=1, keepdim=True)\n",
    "        dist = norm + norm.t() - 2.0 * torch.mm(x, x.t())\n",
    "        return dist\n",
    "    \n",
    "def compute_distance_loss(student_qry, student_pos, teacher_qry, teacher_pos):\n",
    "    \n",
    "    num_student_layers = student_qry.size(0)\n",
    "    num_teacher_layers = teacher_qry.size(0)\n",
    "    scale = num_teacher_layers // num_student_layers\n",
    "\n",
    "    student_repr = torch.cat([student_qry, student_pos], dim=1)\n",
    "    teacher_repr = torch.cat([teacher_qry, teacher_pos], dim=1)[\n",
    "        torch.tensor([i * scale for i in range(num_student_layers)], device=teacher_qry.device)\n",
    "    ]\n",
    "\n",
    "    dist_student = pairwise_distance(student_repr)\n",
    "    dist_teacher = pairwise_distance(teacher_repr)\n",
    "    \n",
    "    mask = torch.triu(torch.ones_like(dist_student), diagonal=1).bool()\n",
    "    dist_student = dist_student[mask]\n",
    "    dist_teacher = dist_teacher[mask]\n",
    "    \n",
    "    mean_td = dist_teacher.mean().detach() + 1e-8\n",
    "    mean_sd = dist_student.mean().detach() + 1e-8\n",
    "    \n",
    "    dist_student = dist_student / mean_sd\n",
    "    dist_teacher = dist_teacher / mean_td\n",
    "    \n",
    "    diff = dist_student - dist_teacher\n",
    "    abs_diff = torch.abs(diff)\n",
    "    quadratic = 0.5 * (abs_diff ** 2)\n",
    "    linear = abs_diff - 0.5\n",
    "    \n",
    "    loss = torch.where(abs_diff < 1.0, quadratic, linear)\n",
    "    loss = loss.mean()\n",
    "    return loss\n",
    "\n",
    "def angle_potentials(x):\n",
    "    x = torch.clamp(x, min=-1e10, max=1e10)\n",
    "\n",
    "    n = x.size(0)\n",
    "    diffs = x.unsqueeze(0) - x.unsqueeze(1)\n",
    "    norms = torch.norm(diffs, dim=-1, keepdim=True) + 1e-8\n",
    "\n",
    "    bfloat16_max_safe = 1e38 \n",
    "    \n",
    "    safe_norms = torch.where(torch.isinf(norms), \n",
    "                             torch.tensor(bfloat16_max_safe, dtype=x.dtype, device=x.device), \n",
    "                             norms)\n",
    "    e = diffs / safe_norms\n",
    "    \n",
    "    cos_angles = torch.einsum('ijd,kjd->ijk', e, e)\n",
    "    return cos_angles\n",
    "\n",
    "def compute_angle_loss(student_qry, student_pos, teacher_qry, teacher_pos):\n",
    "    \n",
    "    num_student_layers = student_qry.size(0)\n",
    "    num_teacher_layers = teacher_qry.size(0)\n",
    "    scale = num_teacher_layers // num_student_layers\n",
    "\n",
    "    student_repr = torch.cat([student_qry, student_pos], dim=1)\n",
    "    teacher_repr = torch.cat([teacher_qry, teacher_pos], dim=1)[\n",
    "        torch.tensor([i * scale for i in range(num_student_layers)], device=teacher_qry.device)\n",
    "    ]\n",
    "\n",
    "    psi_student = angle_potentials(student_repr)\n",
    "    psi_teacher = angle_potentials(teacher_repr)\n",
    "    \n",
    "    n = psi_student.size(0)\n",
    "    mask = torch.ones((n, n, n), dtype=torch.bool, device=psi_student.device)\n",
    "    idx = torch.arange(n, device=psi_student.device)\n",
    "    mask[idx, idx, :] = 0\n",
    "    mask[idx, :, idx] = 0\n",
    "    mask[:, idx, idx] = 0\n",
    "    \n",
    "    psi_teacher = psi_teacher[mask]\n",
    "    psi_student = psi_student[mask]\n",
    "    \n",
    "    diff = psi_student - psi_teacher\n",
    "    abs_diff = torch.abs(diff)\n",
    "    quadratic = 0.5 * (abs_diff ** 2)\n",
    "    linear = abs_diff - 0.5\n",
    "    loss = torch.where(abs_diff < 1.0, quadratic, linear)\n",
    "    loss = loss.mean()\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "c42d8a1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Projector t2s_img created with structure: Sequential(\n",
      "  (0): Linear(in_features=1536, out_features=896, bias=True)\n",
      ")\n",
      "Projector t2s_txt created with structure: Sequential(\n",
      "  (0): Linear(in_features=1536, out_features=896, bias=True)\n",
      ")\n",
      "Projectors set.\n"
     ]
    }
   ],
   "source": [
    "distiller  = Distiller(model_args, training_args, \"cuda\")\n",
    "\n",
    "def compute_ot(s_hidden_states, s_attn, t_hidden_states, t_attn):\n",
    "    \n",
    "    loss = 0.0\n",
    "    num_student_layers = len(s_hidden_states)\n",
    "    num_teacher_layers = len(t_hidden_states)\n",
    "    scale = num_teacher_layers // num_student_layers\n",
    "    start_layer = num_student_layers - 3\n",
    "\n",
    "    for l in range(start_layer, num_student_layers):\n",
    "        s_dist = F.softmax(s_attn[l - 1].mean(dim=1)[:, -1], dim=-1) # (b, n)\n",
    "        t_dist = F.softmax(t_attn[l - 1].mean(dim=1)[:, -1], dim=-1) # (b, m)\n",
    "\n",
    "        s_hidden_state = s_hidden_states[l] # (b, n, emb_dim)\n",
    "        proj_t_hidden_state = distiller.t2s[l - start_layer](t_hidden_states[scale * l]) # (b, m, emb_dim)\n",
    "\n",
    "        for b in range(s_dist.size(0)):\n",
    "            norm_s_hs = torch.norm(s_hidden_state[b], dim=-1, keepdim=True) + 1e-8\n",
    "            norm_t_hs = torch.norm(proj_t_hidden_state[b], dim=-1, keepdim=True) + 1e-8\n",
    "\n",
    "            cost_matrix = torch.cdist(norm_s_hs.unsqueeze(0), \n",
    "                                      norm_t_hs.unsqueeze(0)).squeeze(0)\n",
    "            cost_matrix /= cost_matrix.mean().item()\n",
    "\n",
    "            transport = sinkhorn(s_dist[b], t_dist[b], cost_matrix) \n",
    "            print(transport)\n",
    "            loss += torch.sum(transport * cost_matrix)\n",
    "\n",
    "            print(\"Cost mean:\", cost_matrix.mean().item())\n",
    "            print(\"s_dist sum:\", s_dist[b].sum().item())\n",
    "            print(\"t_dist sum:\", t_dist[b].sum().item())\n",
    "            print(\"Transport mean:\", transport.mean())\n",
    "            print(\"OT cost:\", torch.sum(transport * cost_matrix).item())\n",
    "    return loss / s_dist.size(0), cost_matrix\n",
    "\n",
    "epsilon = 1e-9\n",
    "stopThr = 1e-7\n",
    "sinkhorn_alpha = 0.1\n",
    "\n",
    "def sinkhorn(a, b, cost_matrix, reg=10, num_iters=100, eps=1e-9):\n",
    "    \"\"\"\n",
    "    a: (m,) or (m,1) torch tensor (source weights)\n",
    "    b: (n,) or (n,1) torch tensor (target weights)\n",
    "    cost_matrix: (m, n) torch tensor\n",
    "    reg: regularization (>=0) -- larger reg -> smoother K = exp(-C/reg)\n",
    "    num_iters: number of Sinkhorn iterations\n",
    "    \"\"\"\n",
    "    device = cost_matrix.device\n",
    "    # use float32 for numeric stability\n",
    "    dtype = torch.float32\n",
    "    a = a.detach().to(device=device, dtype=dtype).view(-1, 1)\n",
    "    b = b.detach().to(device=device, dtype=dtype).view(-1, 1)\n",
    "    C = cost_matrix.detach().to(device=device, dtype=dtype)\n",
    "\n",
    "    m, n = C.shape\n",
    "    if m == 0 or n == 0:\n",
    "        return torch.zeros((m, n), device=device, dtype=dtype)\n",
    "\n",
    "    # ensure shapes\n",
    "    if a.shape[0] != m:\n",
    "        a = torch.ones((m, 1), device=device, dtype=dtype) / m\n",
    "    if b.shape[0] != n:\n",
    "        b = torch.ones((n, 1), device=device, dtype=dtype) / n\n",
    "\n",
    "    suma = a.sum()\n",
    "    sumb = b.sum()\n",
    "    if suma <= eps or sumb <= eps:\n",
    "        a = torch.ones((m, 1), device=device, dtype=dtype) / m\n",
    "        b = torch.ones((n, 1), device=device, dtype=dtype) / n\n",
    "    else:\n",
    "        a = a / suma\n",
    "        b = b / sumb\n",
    "\n",
    "    K = torch.exp(-C / (reg + 1e-12))\n",
    "    K = torch.clamp(K, min=1e-10)\n",
    "\n",
    "    u = torch.ones((m, 1), device=device, dtype=dtype)\n",
    "    v = torch.ones((n, 1), device=device, dtype=dtype)\n",
    "\n",
    "    for i in range(num_iters):\n",
    "        u_prev = u.clone()\n",
    "        KTv = (K.t() @ u)  # shape (n,1)\n",
    "        v = b / (KTv + eps)\n",
    "        Kv = (K @ v)       # shape (m,1)\n",
    "        u = a / (Kv + eps)\n",
    "\n",
    "        err = torch.max(torch.abs(u - u_prev))\n",
    "        if err.item() < stopThr:\n",
    "            break\n",
    "\n",
    "    # transport plan\n",
    "    U = torch.diag_embed(u.squeeze())   # (m,m) diag(u)\n",
    "    V = torch.diag_embed(v.squeeze())   # (n,n) diag(v)\n",
    "    P = U @ K @ V                       # (m,n)\n",
    "    return P"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "42b55ea2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[2.1100e-05, 2.1100e-05, 2.1815e-05,  ..., 2.1100e-05, 2.2292e-05,\n",
      "         2.4676e-05],\n",
      "        [1.3292e-05, 1.3232e-05, 1.3828e-05,  ..., 1.3292e-05, 1.4067e-05,\n",
      "         1.5497e-05],\n",
      "        [1.3232e-05, 1.3232e-05, 1.3769e-05,  ..., 1.3232e-05, 1.4007e-05,\n",
      "         1.5497e-05],\n",
      "        ...,\n",
      "        [1.3292e-05, 1.3292e-05, 1.3769e-05,  ..., 1.3292e-05, 1.4007e-05,\n",
      "         1.5497e-05],\n",
      "        [1.3232e-05, 1.3232e-05, 1.3828e-05,  ..., 1.3292e-05, 1.4067e-05,\n",
      "         1.5497e-05],\n",
      "        [1.4186e-05, 1.4126e-05, 1.4663e-05,  ..., 1.4186e-05, 1.4901e-05,\n",
      "         1.6570e-05]], device='cuda:0', dtype=torch.bfloat16)\n",
      "Cost mean: 1.0\n",
      "s_dist sum: 0.9999999403953552\n",
      "t_dist sum: 1.0\n",
      "Transport mean: tensor(1.3113e-05, device='cuda:0', dtype=torch.bfloat16)\n",
      "OT cost: 1.0381078720092773\n",
      "tensor([[2.2411e-05, 2.2411e-05, 2.2173e-05,  ..., 2.2531e-05, 2.3246e-05,\n",
      "         2.6584e-05],\n",
      "        [1.3292e-05, 1.3232e-05, 1.3053e-05,  ..., 1.3292e-05, 1.3709e-05,\n",
      "         1.5616e-05],\n",
      "        [1.3113e-05, 1.3053e-05, 1.2934e-05,  ..., 1.3173e-05, 1.3590e-05,\n",
      "         1.5497e-05],\n",
      "        ...,\n",
      "        [1.3292e-05, 1.3232e-05, 1.3113e-05,  ..., 1.3351e-05, 1.3769e-05,\n",
      "         1.5736e-05],\n",
      "        [1.3292e-05, 1.3232e-05, 1.3113e-05,  ..., 1.3351e-05, 1.3769e-05,\n",
      "         1.5616e-05],\n",
      "        [1.3828e-05, 1.3769e-05, 1.3649e-05,  ..., 1.3888e-05, 1.4305e-05,\n",
      "         1.6332e-05]], device='cuda:0', dtype=torch.bfloat16)\n",
      "Cost mean: 1.0\n",
      "s_dist sum: 0.9999999403953552\n",
      "t_dist sum: 0.9999999403953552\n",
      "Transport mean: tensor(1.3113e-05, device='cuda:0', dtype=torch.bfloat16)\n",
      "OT cost: 1.0412834882736206\n",
      "tensor([[1.8597e-05, 1.8597e-05, 1.8716e-05,  ..., 1.8835e-05, 1.9431e-05,\n",
      "         1.9073e-05],\n",
      "        [1.3232e-05, 1.3292e-05, 1.3411e-05,  ..., 1.3471e-05, 1.3947e-05,\n",
      "         1.3649e-05],\n",
      "        [1.3173e-05, 1.3232e-05, 1.3351e-05,  ..., 1.3411e-05, 1.3888e-05,\n",
      "         1.3590e-05],\n",
      "        ...,\n",
      "        [1.3411e-05, 1.3471e-05, 1.3649e-05,  ..., 1.3649e-05, 1.4126e-05,\n",
      "         1.3828e-05],\n",
      "        [1.3471e-05, 1.3530e-05, 1.3649e-05,  ..., 1.3709e-05, 1.4186e-05,\n",
      "         1.3888e-05],\n",
      "        [1.4782e-05, 1.4842e-05, 1.4961e-05,  ..., 1.5020e-05, 1.5497e-05,\n",
      "         1.5199e-05]], device='cuda:0', dtype=torch.bfloat16)\n",
      "Cost mean: 1.0\n",
      "s_dist sum: 0.9999999403953552\n",
      "t_dist sum: 0.9999999403953552\n",
      "Transport mean: tensor(1.3113e-05, device='cuda:0', dtype=torch.bfloat16)\n",
      "OT cost: 1.0156306028366089\n",
      "tensor([[1.8835e-05, 1.8716e-05, 1.8477e-05,  ..., 1.8597e-05, 1.8835e-05,\n",
      "         1.8954e-05],\n",
      "        [1.3351e-05, 1.3351e-05, 1.3173e-05,  ..., 1.3351e-05, 1.3471e-05,\n",
      "         1.3530e-05],\n",
      "        [1.3292e-05, 1.3232e-05, 1.3113e-05,  ..., 1.3232e-05, 1.3411e-05,\n",
      "         1.3471e-05],\n",
      "        ...,\n",
      "        [1.3530e-05, 1.3530e-05, 1.3351e-05,  ..., 1.3530e-05, 1.3649e-05,\n",
      "         1.3709e-05],\n",
      "        [1.3530e-05, 1.3530e-05, 1.3351e-05,  ..., 1.3530e-05, 1.3649e-05,\n",
      "         1.3709e-05],\n",
      "        [1.4842e-05, 1.4722e-05, 1.4544e-05,  ..., 1.4722e-05, 1.4901e-05,\n",
      "         1.4961e-05]], device='cuda:0', dtype=torch.bfloat16)\n",
      "Cost mean: 1.0\n",
      "s_dist sum: 1.0\n",
      "t_dist sum: 0.9999998807907104\n",
      "Transport mean: tensor(1.3113e-05, device='cuda:0', dtype=torch.bfloat16)\n",
      "OT cost: 1.0148656368255615\n",
      "tensor([[1.3649e-05, 1.3590e-05, 1.3709e-05,  ..., 1.3769e-05, 1.4424e-05,\n",
      "         1.4603e-05],\n",
      "        [1.3471e-05, 1.3411e-05, 1.3530e-05,  ..., 1.3590e-05, 1.4186e-05,\n",
      "         1.4424e-05],\n",
      "        [1.3351e-05, 1.3292e-05, 1.3351e-05,  ..., 1.3471e-05, 1.4007e-05,\n",
      "         1.4305e-05],\n",
      "        ...,\n",
      "        [1.3888e-05, 1.3828e-05, 1.3888e-05,  ..., 1.3947e-05, 1.4544e-05,\n",
      "         1.4782e-05],\n",
      "        [1.4067e-05, 1.4007e-05, 1.4126e-05,  ..., 1.4246e-05, 1.4901e-05,\n",
      "         1.5199e-05],\n",
      "        [1.5974e-05, 1.5855e-05, 1.6093e-05,  ..., 1.6212e-05, 1.6928e-05,\n",
      "         1.7166e-05]], device='cuda:0', dtype=torch.bfloat16)\n",
      "Cost mean: 0.9999999403953552\n",
      "s_dist sum: 1.0\n",
      "t_dist sum: 0.9999999403953552\n",
      "Transport mean: tensor(1.3113e-05, device='cuda:0', dtype=torch.bfloat16)\n",
      "OT cost: 0.9993240833282471\n",
      "tensor([[1.3411e-05, 1.3292e-05, 1.3351e-05,  ..., 1.3590e-05, 1.3709e-05,\n",
      "         1.4365e-05],\n",
      "        [1.3232e-05, 1.3113e-05, 1.3173e-05,  ..., 1.3411e-05, 1.3590e-05,\n",
      "         1.4186e-05],\n",
      "        [1.3232e-05, 1.3113e-05, 1.3173e-05,  ..., 1.3471e-05, 1.3590e-05,\n",
      "         1.4246e-05],\n",
      "        ...,\n",
      "        [1.3769e-05, 1.3649e-05, 1.3709e-05,  ..., 1.3947e-05, 1.4126e-05,\n",
      "         1.4782e-05],\n",
      "        [1.3769e-05, 1.3649e-05, 1.3709e-05,  ..., 1.3947e-05, 1.4126e-05,\n",
      "         1.4842e-05],\n",
      "        [1.6570e-05, 1.6451e-05, 1.6570e-05,  ..., 1.6809e-05, 1.7047e-05,\n",
      "         1.7881e-05]], device='cuda:0', dtype=torch.bfloat16)\n",
      "Cost mean: 1.0\n",
      "s_dist sum: 1.0\n",
      "t_dist sum: 1.0\n",
      "Transport mean: tensor(1.3113e-05, device='cuda:0', dtype=torch.bfloat16)\n",
      "OT cost: 0.9992185831069946\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(tensor(3.0542, device='cuda:0', grad_fn=<DivBackward0>),\n",
       " tensor([[0.7022, 0.7447, 0.9193,  ..., 0.8969, 0.9255, 0.9026],\n",
       "         [0.9866, 1.0291, 1.2037,  ..., 1.1813, 1.2100, 1.1871],\n",
       "         [0.9766, 1.0191, 1.1937,  ..., 1.1713, 1.1999, 1.1770],\n",
       "         ...,\n",
       "         [1.0242, 1.0667, 1.2413,  ..., 1.2189, 1.2476, 1.2247],\n",
       "         [0.7187, 0.7611, 0.9358,  ..., 0.9134, 0.9420, 0.9191],\n",
       "         [1.3639, 1.4064, 1.5810,  ..., 1.5586, 1.5873, 1.5644]],\n",
       "        device='cuda:0', grad_fn=<AsStridedBackward0>))"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with torch.autocast(enabled=True, dtype=torch.bfloat16, device_type=\"cuda\"):\n",
    "    x = compute_ot(s_qry_hidden_states, s_qry_attention,\n",
    "                t_qry_hidden_states, t_qry_attention)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "74869b45",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 12, 278, 278])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s_qry_hidden_states[0].size()\n",
    "t_qry_hidden_states[0].size()\n",
    "s_qry_attention[0].size()\n",
    "t_qry_attention[0].size()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "vlm2vec",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
